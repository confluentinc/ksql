# KLIP 6: KSQL Testing Tool

Author: hjafarpour

Release target: 5.3

Status: In Discussion

Discussion: _link to the design discussion PR_

## tl;dr

Provide a testing tool to evaluate the generated results from a set of KSQL statements without requiring the full fledge KSQL/Kafka environment.


## Motivation and background

This KLIP proposed a new testing tool for KSQL that can be used to evaluate the generated results for a set of KSQL statements. Currently, if users want to evaluate the result of KSQL statements, they should bring up a full fledged KSQL environment including Kafka cluster, KSQL cluster, KSQL client (e.g., KSQL CLI) and possibly Schema Registry if the test data is in Avro format.
With the proposed testing tool, users can provide a set of KSQL statements along with specific configurations, data formats, the input data and the expected output data. The testing tool will execute the statements with the provided input data and assert that the output data is produced by the statements.
The testing tool also enables users to easily share their test files without any dependency on the execution environment. Therefore, it will be much easier to collaborate and design streaming pipelines with KSQL!


## What is in scope

The testing tool will be a self sufficient command line tool where users can pass JSON files describing test settings and configuration and evaluate the generated results.

## What is not in scope

N/A

## Value/Return

The proposed tool provides a new way of testing KSQL statements. It also is self sufficient and does not need any running environment such as Kafka or KSQL cluster.


## Public APIS

### Test File

The test file is a JSON file that describes the test settings and test data. The following is an example test file:

```JSON
{
 "comments": [
   "Any comments on this test file!"
 ],
 "tests": [
   {
     "name": "Sample test",
     "statements": [
       "CREATE STREAM TEST (ID bigint, NAME varchar, VALUE double) WITH (kafka_topic='test_topic', value_format='DELIMITED', key='ID');",
       "CREATE STREAM S1 as SELECT name FROM test where id > 100;"
     ],
     "inputs": [
       {"topic": "test_topic", "key": 0, "value": "0,zero,0.0"},
       {"topic": "test_topic", "key": 100, "value": "100,100,0.0"},
       {"topic": "test_topic", "key": 101, "value": "101,101,0.0"}
     ],
     "outputs": [
       {"topic": "S1", "key": 101, "value": "101"}
     ]
   }
 ]
}
```

Each test file can include multiple tests. Each test can have the following attributes (these descriptions are the same as the ones described ([here](https://github.com/confluentinc/ksql/blob/master/ksql-engine/src/test/resources/query-validation-tests/README.md))):

- _name_ (required): The name of the test case.
description (optional): A description of what the test case is testing.
- _format_ (optional): An array of multiple different formats to run the test case as, e.g. AVRO, JSON, DELIMITED.
- _statements_ (required): The list of statements to execute as this test case.
- _properties_ (optional): A map of property name to value. Can contain any valid Ksql config. The config is passed to the engine when executing the statements in the test case
- _topics_ (optional): An array of the topics this test case needs. Allows more information about the topic to be supplied, e.g. an existing Avro schema.
- _inputs_ (required if `expectedException` not supplied): The set of input messages to be produced to Kafka topic(s).
- _outputs_ (required if `expectedException` not supplied) The set of output messages expected in the output topic(s).
- _expectedException_ (required if `inputs` and `outputs` not supplied) The exception that should be thrown when executing the supplied statements.


For more details on the test file format click ([here](https://github.com/confluentinc/ksql/blob/master/ksql-engine/src/test/resources/query-validation-tests/README.md)).


### Testing Tool

The testing tool will be a command line tool called ksql-testing-tool that accepts a test file as input parameter. The following is the way we can use the tool:

```shell
$ ksql-testing-tool /path/to/the/testfile.json
```
The tool will run the tests from the test file and if all the tests pass will terminate successfully printing the success message in the terminal! If any of the tests fail the tool will print out the reason for the failure in the terminal. The following is an example of successful test:

```shell
$ ksql-testing-tool /path/to/correct_test.json
All tests passed!
$
```
The following is a sample output of the tool when a test fails:

```shell
$ ksql-testing-tool /path/to/correct_test.json
Exception in thread "main" java.lang.AssertionError: TestCase name: project-filter - project and filter in file: /path/to/correct_test.json failed while processing output row 0 topic: S1 due to: Expected <1010, 101> with timestamp=0 but was <101, 101> with timestamp=0
  at io.confluent.ksql.test.commons.TestCase.verifyOutput(TestCase.java:190)
  at io.confluent.ksql.testingtool.TestRunner.shouldBuildAndExecuteQuery(TestRunner.java:134)
  at io.confluent.ksql.testingtool.TestRunner.main(TestRunner.java:96)
Caused by: java.lang.AssertionError: Expected <1010, 101> with timestamp=0 but was <101, 101> with timestamp=0
  at org.apache.kafka.streams.test.OutputVerifier.compareKeyValueTimestamp(OutputVerifier.java:208)
  at io.confluent.ksql.test.commons.TestCase.verifyOutput(TestCase.java:177)
  ... 2 more
$
```

As you can see, the error message will include the failure reason.


## Design

This is an independent command line tool for testing KSQL statement by evaluating the generated results for a given input data. Test settings along with the input data and expected output are passed to the tool through a test file in JSON format.
The tool is based on the internal testing framework we have for KSQL engine module, Query Translation Test. This required some refactoring of the code to make the Query Translation Test functionality available in a new module. We will refactor the common code into a new module that will be used by both Query Translation Test in the engine module and the new Ksql testing tool module.


## Test plan

Unit tests and integration tests will be added to the KSQL testing tool module. This will cover both happy path and failure paths.

## Documentation Updates

There will be a new section in the documentation describing the testing tool and itâ€™s usage. It will include samples along with description on the test file structure and attributes.

# Compatibility implications

No compatibility implications since this is an independent tool.


## Performance implications

No performance implications since this is an independent tool.

## Security Implications

No security implications since this is an independent tool.
