{
  "tests": [
    {
      "name": "validate without elements FAILS",
      "format": ["DELIMITED", "KAFKA"],
      "statements": [
        "CREATE STREAM INPUT WITH (kafka_topic='input', value_format='{FORMAT}');"
      ],
      "topics": [
        {
          "name": "input",
          "schema": {"name": "blah", "type": "record", "fields": [{"name": "c1", "type": "int"}]},
          "format": "AVRO"
        }
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "The statement does not define any columns."
      }
    },
    {
      "name": "validate without elements OK - AVRO",
      "statements": [
        "CREATE STREAM INPUT WITH (kafka_topic='input', value_format='AvRo');",
        "CREATE STREAM OUTPUT WITH(PARTITIONS = 4) as SELECT * FROM input;"
      ],
      "topics": [
        {
          "name": "input",
          "schema": {"name": "blah", "type": "record", "fields": [{"name": "c1", "type": "int"}]},
          "format": "AVRO"
        },
        {
          "name": "OUTPUT",
          "format": "AVRO",
          "partitions": 4
        }
      ],
      "inputs": [{"topic": "input", "value": {"c1": 4}}],
      "outputs": [{"topic": "OUTPUT", "value": {"C1": 4}}]
    },
    {
      "name": "validate without elements OK - PROTOBUF",
      "statements": [
        "CREATE STREAM INPUT WITH (kafka_topic='input', value_format='PROTOBUF');",
        "CREATE STREAM OUTPUT WITH(PARTITIONS = 4) as SELECT * FROM input;"
      ],
      "topics": [
        {
          "name": "input",
          "schema": "syntax = \"proto3\"; message ConnectDefault1 { int32 c1 = 1; }",
          "format": "PROTOBUF"
        },
        {
          "name": "OUTPUT",
          "format": "PROTOBUF",
          "partitions": 4
        }
      ],
      "inputs": [{"topic": "input", "value": {"c1": 4}}],
      "outputs": [{"topic": "OUTPUT", "value": {"C1": 4}}]
    },
    {
      "name": "validate without elements OK - JSON_SR SCHEMA",
      "statements": [
        "CREATE STREAM INPUT WITH (kafka_topic='input', value_format='JSON_SR');",
        "CREATE STREAM OUTPUT WITH(PARTITIONS = 4) as SELECT * FROM input;"
      ],
      "topics": [
        {
          "name": "input",
          "schema": {"type": "object","properties": {"c1": {"type": "integer"}}},
          "format": "JSON"
        },
        {
          "name": "OUTPUT",
          "format": "JSON",
          "partitions": 4
        }
      ],
      "inputs": [{"topic": "input", "value": {"c1": 4}}],
      "outputs": [{"topic": "OUTPUT", "value": {"C1": 4}}]
    },
    {
      "name": "with invalid or reserved words in schema - JSON",
      "statements": [
        "CREATE STREAM INPUT (`@TIMESTAMP` BIGINT, `FROM` BIGINT) WITH (kafka_topic='input', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT * FROM input;"
      ],
      "topics": [
        {
          "name": "input",
          "format": "JSON"
        },
        {
          "name": "OUTPUT",
          "format": "JSON"
        }
      ],
      "inputs": [{"topic": "input", "value": {"@timestamp": 4, "from": 5}}],
      "outputs": [{"topic": "OUTPUT", "value": {"@TIMESTAMP": 4, "FROM": 5}}],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "`@TIMESTAMP` BIGINT, `FROM` BIGINT"}
        ]
      }
    },
    {
      "name": "validate without value elements OK - AVRO",
      "statements": [
        "CREATE STREAM INPUT (rowkey int key) WITH (kafka_topic='input', value_format='AvRo');",
        "CREATE STREAM OUTPUT AS SELECT * FROM input;"
      ],
      "topics": [
        {
          "name": "input",
          "schema": {"name": "blah", "type": "record", "fields": [{"name": "c1", "type": "int"}]},
          "format": "AVRO"
        },
        {
          "name": "OUTPUT",
          "format": "AVRO"
        }
      ],
      "inputs": [{"topic": "input", "key": 42, "value": {"c1": 4}}],
      "outputs": [{"topic": "OUTPUT", "key": 42, "value": {"C1": 4}}],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "ROWKEY INT KEY, `C1` INT"}
        ]
      }
    },
    {
      "name": "validate without value elements OK - PROTOBUF",
      "statements": [
        "CREATE STREAM INPUT (rowkey int key) WITH (kafka_topic='input', value_format='PROTOBUF');",
        "CREATE STREAM OUTPUT AS SELECT * FROM input;"
      ],
      "topics": [
        {
          "name": "input",
          "schema": "syntax = \"proto3\"; message ConnectDefault1 { int32 c1 = 1; }",
          "format": "PROTOBUF"
        },
        {
          "name": "OUTPUT",
          "format": "PROTOBUF"
        }
      ],
      "inputs": [{"topic": "input", "key": 42, "value": {"c1": 4}}],
      "outputs": [{"topic": "OUTPUT", "key": 42, "value": {"C1": 4}}],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "ROWKEY INT KEY, `C1` INT"}
        ]
      }
    },
    {
      "name": "validate without value elements OK - JSON_SR SCHEMA",
      "statements": [
        "CREATE STREAM INPUT (rowkey int key) WITH (kafka_topic='input', value_format='JSON_SR');",
        "CREATE STREAM OUTPUT AS SELECT * FROM input;"
      ],
      "topics": [
        {
          "name": "input",
          "schema": {"type": "object","properties": {"c1": {"type": "integer"}}},
          "format": "JSON"
        },
        {
          "name": "OUTPUT",
          "format": "JSON"
        }
      ],
      "inputs": [{"topic": "input", "key": 42, "value": {"c1": 4}}],
      "outputs": [{"topic": "OUTPUT", "key": 42, "value": {"C1": 4}}],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "ROWKEY INT KEY, `C1` BIGINT"}
        ]
      }
    },
    {
      "name": "validate without value elements OK - custom key name",
      "statements": [
        "CREATE STREAM INPUT (id int key) WITH (kafka_topic='input', value_format='JSON_SR');",
        "CREATE STREAM OUTPUT AS SELECT * FROM input;"
      ],
      "topics": [
        {
          "name": "input",
          "schema": {"type": "object", "properties": {"c1": {"type": "integer"}}},
          "format": "JSON"
        },
        {
          "name": "OUTPUT",
          "format": "JSON"
        }
      ],
      "inputs": [{"topic": "input", "key": 42, "value": {"c1": 4}}],
      "outputs": [{"topic": "OUTPUT", "key": 42, "value": {"C1": 4}}],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "ID INT KEY, C1 BIGINT"}
        ]
      }
    },
    {
      "name": "validate with elements OK",
      "format": ["JSON", "PROTOBUF"],
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, V0 INT) WITH (kafka_topic='input', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT AS SELECT * FROM INPUT;"
      ],
      "inputs": [{"topic": "input", "value": {"V0": 4}}],
      "outputs": [{"topic": "OUTPUT", "value": {"V0": 4}}]
    },
    {
      "name": "validate with elements OK - AVRO",
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, V0 INT) WITH (kafka_topic='input', value_format='AVRO');",
        "CREATE STREAM OUTPUT WITH(PARTITIONS = 4) as SELECT * FROM input;"
      ],
      "topics": [
        {
          "name": "input",
          "schema": {"name": "blah", "type": "record", "fields": [{"name": "v0", "type": "int"}]},
          "format": "AVRO"
        },
        {
          "name": "OUTPUT",
          "format": "AVRO",
          "partitions": 4
        }
      ],
      "inputs": [{"topic": "input", "value": {"v0": 4}}],
      "outputs": [{"topic": "OUTPUT", "value": {"V0": 4}}]
    },
    {
      "name": "validate multiple value elements in C* FAILS - KAFKA",
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, V0 INT, V1 STRING) WITH (kafka_topic='input', value_format='KafkA');"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "The 'KAFKA' format only supports a single field. Got: V0 INT, V1 VARCHAR"
      }
    },
    {
      "name": "validate multiple value elements in C*AS FAILS - KAFKA",
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, V0 INT, V1 STRING) WITH (kafka_topic='input', value_format='DELIMITED');",
        "CREATE STREAM OUTPUT WITH (value_format='kafka') AS SELECT * FROM INPUT;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "The 'KAFKA' format only supports a single field. Got: V0 INT, V1 VARCHAR"
      }
    },
    {
      "name": "validate boolean elements FAILS - KAFKA",
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, V0 BOOLEAN) WITH (kafka_topic='input', value_format='KAFKA');"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "The 'KAFKA' format does not support type 'BOOLEAN'"
      }
    },
    {
      "name": "validate boolean elements OK",
      "format": ["DELIMITED"],
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, V0 BOOLEAN) WITH (kafka_topic='input', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT AS SELECT * FROM INPUT;"
      ],
      "inputs": [{"topic": "input", "value": "true"}],
      "outputs": [{"topic": "OUTPUT", "value": "true"}]
    },
    {
      "name": "validate boolean elements OK",
      "format": ["JSON", "JSON_SR", "AVRO", "PROTOBUF"],
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, V0 BOOLEAN) WITH (kafka_topic='input', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT AS SELECT * FROM INPUT;"
      ],
      "inputs": [{"topic": "input", "value": {"V0": true}}],
      "outputs": [{"topic": "OUTPUT", "value": {"V0": true}}]
    },
    {
      "name": "validate int elements OK",
      "format": ["DELIMITED"],
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, V0 INT) WITH (kafka_topic='input', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT AS SELECT * FROM INPUT;"
      ],
      "inputs": [{"topic": "input", "value": "10"}],
      "outputs": [{"topic": "OUTPUT", "value": "10"}]
    },
    {
      "name": "validate int elements OK",
      "format": ["KAFKA"],
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, V0 INT) WITH (kafka_topic='input', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT AS SELECT * FROM INPUT;"
      ],
      "inputs": [{"topic": "input", "value": 10}],
      "outputs": [{"topic": "OUTPUT", "value": 10}]
    },
    {
      "name": "validate int elements OK",
      "format": ["JSON", "JSON_SR", "AVRO", "PROTOBUF"],
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, V0 INT) WITH (kafka_topic='input', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT AS SELECT * FROM INPUT;"
      ],
      "inputs": [{"topic": "input", "value": {"V0": 10}}],
      "outputs": [{"topic": "OUTPUT", "value": {"V0": 10}}]
    },
    {
      "name": "validate bigint elements OK",
      "format": ["DELIMITED"],
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, V0 BIGINT) WITH (kafka_topic='input', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT AS SELECT * FROM INPUT;"
      ],
      "inputs": [{"topic": "input", "value": "10000000000"}],
      "outputs": [{"topic": "OUTPUT", "value": "10000000000"}]
    },
    {
      "name": "validate bigint elements OK",
      "format": ["KAFKA"],
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, V0 BIGINT) WITH (kafka_topic='input', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT AS SELECT * FROM INPUT;"
      ],
      "inputs": [{"topic": "input", "value": 10000000000}],
      "outputs": [{"topic": "OUTPUT", "value": 10000000000}]
    },
    {
      "name": "validate bigint elements OK",
      "format": ["JSON", "JSON_SR", "AVRO", "PROTOBUF"],
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, V0 BIGINT) WITH (kafka_topic='input', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT AS SELECT * FROM INPUT;"
      ],
      "inputs": [{"topic": "input", "value": {"V0": 10000000000}}],
      "outputs": [{"topic": "OUTPUT", "value": {"V0": 10000000000}}]
    },
    {
      "name": "validate double elements OK",
      "format": ["DELIMITED"],
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, V0 DOUBLE) WITH (kafka_topic='input', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT AS SELECT * FROM INPUT;"
      ],
      "inputs": [{"topic": "input", "value": "10.1"}],
      "outputs": [{"topic": "OUTPUT", "value": "10.1"}]
    },
    {
      "name": "validate double elements OK",
      "format": ["KAFKA"],
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, V0 DOUBLE) WITH (kafka_topic='input', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT AS SELECT * FROM INPUT;"
      ],
      "inputs": [{"topic": "input", "value": 10.1}],
      "outputs": [{"topic": "OUTPUT", "value": 10.1}]
    },
    {
      "name": "validate double elements OK",
      "format": ["JSON", "JSON_SR", "AVRO", "PROTOBUF"],
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, V0 DOUBLE) WITH (kafka_topic='input', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT AS SELECT * FROM INPUT;"
      ],
      "inputs": [{"topic": "input", "value": {"V0": 10.1}}],
      "outputs": [{"topic": "OUTPUT", "value": {"V0": 10.1}}]
    },
    {
      "name": "validate decimal elements OK",
      "format": ["JSON", "JSON_SR"],
      "statements": [
        "CREATE STREAM INPUT (V0 DECIMAL(15,14)) WITH (kafka_topic='input', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT AS SELECT * FROM INPUT;"
      ],
      "inputs": [{"topic": "input", "value": {"V0": 1.12345678901234}}],
      "outputs": [{"topic": "OUTPUT", "value": {"V0": 1.12345678901234}}]
    },
    {
      "name": "validate string elements OK",
      "format": ["DELIMITED", "KAFKA"],
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, V0 STRING) WITH (kafka_topic='input', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT AS SELECT * FROM INPUT;"
      ],
      "inputs": [{"topic": "input", "value": "Hello"}],
      "outputs": [{"topic": "OUTPUT", "value": "Hello"}]
    },
    {
      "name": "validate string elements OK",
      "format": ["JSON", "JSON_SR", "AVRO", "PROTOBUF"],
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, V0 STRING) WITH (kafka_topic='input', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT AS SELECT * FROM INPUT;"
      ],
      "inputs": [{"topic": "input", "value": {"V0": "Hello"}}],
      "outputs": [{"topic": "OUTPUT", "value": {"V0": "Hello"}}]
    },
    {
      "name": "validate array element in C* FAILS",
      "format": ["DELIMITED", "KAFKA"],
      "statements": [
        "CREATE STREAM INPUT (V0 ARRAY<INT>) WITH (kafka_topic='input', value_format='{FORMAT}');"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "format does not support type 'ARRAY'"
      }
    },
    {
      "name": "validate array element in C*AS FAILS",
      "format": ["DELIMITED", "KAFKA"],
      "statements": [
        "CREATE STREAM INPUT (V0 ARRAY<INT>) WITH (kafka_topic='input', value_format='JSON');",
        "CREATE STREAM OUTPUT WITH (value_format='{FORMAT}') AS SELECT * FROM INPUT;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "format does not support type 'ARRAY'"
      }
    },
    {
      "name": "validate array element OK",
      "format": ["JSON", "JSON_SR", "AVRO", "PROTOBUF"],
      "statements": [
        "CREATE STREAM INPUT (V0 ARRAY<INT>) WITH (kafka_topic='input', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT AS SELECT * FROM INPUT;"
      ],
      "inputs": [{"topic": "input", "value": {"V0": [1]}}],
      "outputs": [{"topic": "OUTPUT", "value": {"V0": [1]}}]
    },
    {
      "name": "validate map element in C* FAILS",
      "format": ["DELIMITED", "KAFKA"],
      "statements": [
        "CREATE STREAM INPUT (V0 MAP<STRING, INT>) WITH (kafka_topic='input', value_format='{FORMAT}');"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "format does not support type 'MAP'"
      }
    },
    {
      "name": "validate map element in C*AS FAILS",
      "format": ["DELIMITED", "KAFKA"],
      "statements": [
        "CREATE STREAM INPUT (V0 MAP<STRING, INT>) WITH (kafka_topic='input', value_format='JSON');",
        "CREATE STREAM OUTPUT WITH(value_format='{FORMAT}') AS SELECT * FROM INPUT;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "format does not support type 'MAP'"
      }
    },
    {
      "name": "validate map element OK",
      "format": ["JSON", "AVRO", "PROTOBUF"],
      "statements": [
        "CREATE STREAM INPUT (V0 MAP<STRING, INT>) WITH (kafka_topic='input', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT AS SELECT * FROM INPUT;"
      ],
      "inputs": [{"topic": "input", "value": {"V0": {"k1": 1}}}],
      "outputs": [{"topic": "OUTPUT", "value": {"V0": {"k1": 1}}}]
    },
    {
      "name": "validate struct element in C* FAILS",
      "format": ["DELIMITED", "KAFKA"],
      "statements": [
        "CREATE STREAM INPUT (V0 STRUCT<F0 STRING>) WITH (kafka_topic='input', value_format='{FORMAT}');"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "format does not support type 'STRUCT'"
      }
    },
    {
      "name": "validate struct element in C*AS FAILS",
      "format": ["DELIMITED", "KAFKA"],
      "statements": [
        "CREATE STREAM INPUT (V0 STRUCT<F0 STRING>) WITH (kafka_topic='input', value_format='JSON');",
        "CREATE STREAM OUTPUT WITH(value_format='{FORMAT}') AS SELECT * FROM INPUT;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "format does not support type 'STRUCT'"
      }
    },
    {
      "name": "validate struct element OK",
      "format": ["JSON", "JSON_SR", "AVRO", "PROTOBUF"],
      "statements": [
        "CREATE STREAM INPUT (V0 STRUCT<F0 STRING, F1 INT>) WITH (kafka_topic='input', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT AS SELECT * FROM INPUT;"
      ],
      "inputs": [{"topic": "input", "value": {"V0": {"f0": "bob", "f1": 1}}}],
      "outputs": [{"topic": "OUTPUT", "value": {"V0": {"F0": "bob", "F1": 1}}}]
    },
    {
      "name": "validate AVRO uses null for unknown element",
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, c1 INT, unknown INT) WITH (kafka_topic='input', value_format='AVRO');",
        "CREATE STREAM S WITH(PARTITIONS = 4) as SELECT * FROM input;"
      ],
      "topics": [
        {
          "name": "input",
          "schema": {"name": "blah", "type": "record", "fields": [{"name": "c1", "type": "int"}]},
          "format": "AVRO"
        },
        {
          "name": "S",
          "format": "AVRO",
          "partitions": 4
        }
      ],
      "inputs": [{"topic": "input", "value": {"c1": 4}}],
      "outputs": [{"topic": "S", "value": {"UNKNOWN": null, "C1": 4}}]
    },
    {
      "name": "validate AVRO fails on incompatible schema evolution",
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, c1 INT) WITH (kafka_topic='input', value_format='AVRO');",
        "CREATE STREAM OUTPUT WITH(PARTITIONS = 4) as SELECT * FROM input;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlStatementException",
        "message": "Cannot register avro schema for OUTPUT as the schema is incompatible with the current schema version registered for the topic.\nKSQL schema: {\"type\":\"record\",\"name\":\"KsqlDataSourceSchema\",\"namespace\":\"io.confluent.ksql.avro_schemas\",\"fields\":[{\"name\":\"C1\",\"type\":[\"null\",\"int\"],\"default\":null}],\"connect.name\":\"io.confluent.ksql.avro_schemas.KsqlDataSourceSchema\"}\nRegistered schema: {\"type\":\"record\",\"name\":\"blah\",\"fields\":[{\"name\":\"C1\",\"type\":\"double\"}]}"
      },
      "topics": [
        {
          "name": "input",
          "schema": {"name": "blah", "type": "record", "fields": [{"name": "C1", "type": "int"}]},
          "format": "AVRO",
          "partitions": 4
        },
        {
          "name": "OUTPUT",
          "schema": {"name": "blah", "type": "record", "fields": [{"name": "C1", "type": "double"}]},
          "format": "AVRO",
          "partitions": 4
        }
      ]
    },
    {
      "name": "non-join should reject ROWTIME in projection",
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, F0 INT) WITH (kafka_topic='input', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT K, ROWTIME FROM INPUT;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "Reserved column name in select: `ROWTIME`. Please remove or alias the column."
      }
    },
    {
      "name": "non-join should reject WINDOWSTART in projection",
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, F0 INT) WITH (kafka_topic='input', value_format='JSON', window_type='session');",
        "CREATE STREAM OUTPUT AS SELECT K, WINDOWSTART FROM INPUT;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "Reserved column name in select: `WINDOWSTART`. Please remove or alias the column."
      }
    },
    {
      "name": "non-join should reject WINDOWEND in projection",
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, F0 INT) WITH (kafka_topic='input', value_format='JSON', window_type='session');",
        "CREATE STREAM OUTPUT AS SELECT K, WINDOWEND FROM INPUT;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "Reserved column name in select: `WINDOWEND`. Please remove or alias the column."
      }
    },
    {
      "name": "non-join leaves aliased system columns in output's value schema",
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, F0 INT) WITH (kafka_topic='input', value_format='JSON', window_type='session');",
        "CREATE STREAM OUTPUT AS SELECT K, F0, ROWTIME AS TIME, WINDOWSTART AS WSTART, WINDOWEND AS WEND FROM INPUT;"
      ],
      "inputs": [{"topic": "input", "key": "k", "value": {"F0": 4}, "timestamp": 1, "window": {"start": 12, "end": 465, "type": "session"}}],
      "outputs": [{"topic": "OUTPUT", "key": "k", "value": {"F0": 4, "TIME": 1, "WSTART": 12, "WEND": 465}, "timestamp": 1, "window": {"start": 12, "end": 465, "type": "session"}}]
    },
    {
      "name": "join should reject ROWTIME in projection",
      "statements": [
        "CREATE STREAM LEFT_STREAM (K STRING KEY, F0 INT) WITH (kafka_topic='left', value_format='JSON');",
        "CREATE STREAM RIGHT_STREAM (K STRING KEY, F1 INT) WITH (kafka_topic='right', value_format='JSON');",
        "CREATE STREAM OUTPUT as SELECT l.K, l.ROWTIME AS ROWTIME, f0, f1 FROM left_stream l join right_stream r WITHIN 1 seconds ON l.k = r.k;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "Reserved column name in select: `ROWTIME`. Please remove or alias the column."
      }
    },
    {
      "name": "join should reject WINDOWSTART in projection",
      "statements": [
        "CREATE STREAM LEFT_STREAM (K STRING KEY, F0 INT) WITH (kafka_topic='left', value_format='JSON', window_type='tumbling', window_size='1 second');",
        "CREATE STREAM RIGHT_STREAM (K STRING KEY, F1 INT) WITH (kafka_topic='right', value_format='JSON', window_type='tumbling', window_size='1 second');",
        "CREATE STREAM OUTPUT as SELECT l.K, l.WINDOWSTART AS WINDOWSTART, f0 FROM left_stream l join right_stream r WITHIN 1 seconds ON l.k = r.k;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "Reserved column name in select: `WINDOWSTART`. Please remove or alias the column."
      }
    },
    {
      "name": "join should reject WINDOWEND in projection",
      "statements": [
        "CREATE STREAM LEFT_STREAM (K STRING KEY, F0 INT) WITH (kafka_topic='left', value_format='JSON', window_type='tumbling', window_size='1 second');",
        "CREATE STREAM RIGHT_STREAM (K STRING KEY, F1 INT) WITH (kafka_topic='right', value_format='JSON', window_type='tumbling', window_size='1 second');",
        "CREATE STREAM OUTPUT as SELECT l.K, l.WINDOWEND AS WINDOWEND, f0 FROM left_stream l join right_stream r WITHIN 1 seconds ON l.k = r.k;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "Reserved column name in select: `WINDOWEND`. Please remove or alias the column."
      }
    },
    {
      "name": "join leaves aliased system columns in output's value schema",
      "statements": [
        "CREATE STREAM LEFT_STREAM (K STRING KEY, F0 INT) WITH (kafka_topic='left', value_format='JSON', window_type='tumbling', window_size='1 second');",
        "CREATE STREAM RIGHT_STREAM (K STRING KEY, F1 INT) WITH (kafka_topic='right', value_format='JSON', window_type='tumbling', window_size='1 second');",
        "CREATE STREAM OUTPUT as SELECT l.K, l.ROWTIME AS TIME, l.WINDOWSTART AS WSTART, l.WINDOWEND AS WEND, f0, f1 FROM left_stream l join right_stream r WITHIN 1 seconds ON l.k = r.k;"
      ],
      "inputs": [
        {"topic": "left", "key": "k", "value": {"F0": 4}, "timestamp": 1, "window": {"start": 0, "end": 1000, "type": "time"}},
        {"topic": "right", "key": "k", "value": {"F1": 6}, "timestamp": 2, "window": {"start": 0, "end": 1000, "type": "time"}}
      ],
      "outputs": [{"topic": "OUTPUT", "key": "k", "value": {"F0": 4, "F1": 6, "TIME": 1, "WSTART": 0, "WEND": 1000}, "timestamp": 2, "window": {"start": 0, "end": 1000, "type": "time"}}]
    },
    {
      "name": "group-by rejects window bounds in projection",
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, F0 INT) WITH (kafka_topic='input', value_format='JSON');",
        "CREATE TABLE OUTPUT AS SELECT K, WINDOWSTART, COUNT(*) AS COUNT FROM INPUT GROUP BY WINDOWSTART;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "Reserved column name in select: `WINDOWSTART`. Please remove or alias the column."
      }
    },
    {
      "name": "non-join qualified select star",
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, F0 INT) WITH (kafka_topic='input', value_format='JSON');",
        "CREATE STREAM OUTPUT as SELECT i.* FROM INPUT i;"
      ],
      "inputs": [{"topic": "input", "value": {"F0": 4}}],
      "outputs": [{"topic": "OUTPUT", "value": {"F0": 4}}]
    },
    {
      "name": "non-join select star with unknown qualifier",
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, F0 INT) WITH (kafka_topic='input', value_format='JSON');",
        "CREATE STREAM OUTPUT as SELECT K, unknown.* FROM INPUT i;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "'UNKNOWN' is not a valid stream/table name or alias."
      }
    },
    {
      "name": "join qualified select star left",
      "statements": [
        "CREATE STREAM INPUT_1 (K STRING KEY, F0 INT) WITH (kafka_topic='input_1', value_format='JSON');",
        "CREATE STREAM INPUT_2 (K STRING KEY, F0 INT) WITH (kafka_topic='input_2', value_format='JSON');",
        "CREATE STREAM OUTPUT as SELECT i1.* FROM INPUT_1 i1 JOIN INPUT_2 i2 WITHIN 10 SECONDS ON i1.K = i2.K;"
      ],
      "inputs": [
        {"topic": "input_1", "key": "1", "value": {"F0": 4}, "timestamp": 10},
        {"topic": "input_2", "key": "1", "value": {"F0": 4}, "timestamp": 11}
      ],
      "outputs": [{"topic": "OUTPUT", "key": "1", "value": {"I1_F0": 4}, "timestamp": 11}]
    },
    {
      "name": "join qualified select star right",
      "statements": [
        "CREATE STREAM INPUT_1 (K STRING KEY, F0 INT) WITH (kafka_topic='input_1', value_format='JSON');",
        "CREATE STREAM INPUT_2 (K STRING KEY, F0 INT) WITH (kafka_topic='input_2', value_format='JSON');",
        "CREATE STREAM OUTPUT as SELECT i2.* FROM INPUT_1 i1 JOIN INPUT_2 i2 WITHIN 10 SECONDS ON i1.K = i2.K;"
      ],
      "inputs": [
        {"topic": "input_1", "key": "1", "value": {"F0": 4}, "timestamp": 10},
        {"topic": "input_2", "key": "1", "value": {"F0": 4}, "timestamp": 11}
      ],
      "outputs": [{"topic": "OUTPUT", "key": "1", "value": {"I2_F0": 4}, "timestamp": 11}]
    },
    {
      "name": "join unqualified select star",
      "statements": [
        "CREATE STREAM INPUT_1 (K STRING KEY, F0 INT) WITH (kafka_topic='input_1', value_format='JSON');",
        "CREATE STREAM INPUT_2 (K STRING KEY, F0 INT) WITH (kafka_topic='input_2', value_format='JSON');",
        "CREATE STREAM OUTPUT as SELECT * FROM INPUT_1 i1 JOIN INPUT_2 i2 WITHIN 10 SECONDS ON i1.K = i2.K;"
      ],
      "inputs": [
        {"topic": "input_1", "key": "1", "value": {"F0": 4}, "timestamp": 10},
        {"topic": "input_2", "key": "1", "value": {"F0": 4}, "timestamp": 11}
      ],
      "outputs": [{"topic": "OUTPUT", "key": "1", "value": {"I1_F0": 4, "I2_K": "1", "I2_F0": 4}, "timestamp": 11}]
    },
    {
      "name": "join unknown qualified select star",
      "statements": [
        "CREATE STREAM INPUT_1 (K STRING KEY, F0 INT) WITH (kafka_topic='input_1', value_format='JSON');",
        "CREATE STREAM INPUT_2 (K STRING KEY, F0 INT) WITH (kafka_topic='input_2', value_format='JSON');",
        "CREATE STREAM OUTPUT as SELECT unknown.* FROM INPUT_1 i1 JOIN INPUT_2 i2 WITHIN 10 SECONDS ON i1.K = i2.K;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "'UNKNOWN' is not a valid stream/table name or alias."
      }
    },
    {
      "name": "non-join unknown field",
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, F0 INT) WITH (kafka_topic='input', value_format='JSON');",
        "CREATE STREAM OUTPUT as SELECT K, unknown FROM INPUT;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "Line: 3, Col: 3: SELECT column 'UNKNOWN' cannot be resolved."
      }
    },
    {
      "name": "join unknown field",
      "statements": [
        "CREATE STREAM INPUT_1 (K STRING KEY, F0 INT) WITH (kafka_topic='input_1', value_format='JSON');",
        "CREATE STREAM INPUT_2 (K STRING KEY, F0 INT) WITH (kafka_topic='input_2', value_format='JSON');",
        "CREATE STREAM OUTPUT as SELECT I1.K, unknown FROM INPUT_1 i1 JOIN INPUT_2 i2 WITHIN 10 SECONDS ON i1.K = i2.K;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "Line: 3, Col: 3: SELECT column 'UNKNOWN' cannot be resolved"
      }
    },
    {
      "name": "join unknown field source",
      "statements": [
        "CREATE STREAM INPUT_1 (K STRING KEY, F0 INT) WITH (kafka_topic='input_1', value_format='JSON');",
        "CREATE STREAM INPUT_2 (K STRING KEY, F0 INT) WITH (kafka_topic='input_2', value_format='JSON');",
        "CREATE STREAM OUTPUT as SELECT * FROM INPUT_1 i1 JOIN INPUT_2 i2 WITHIN 10 SECONDS ON unknown.K = i2.K;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "'UNKNOWN' is not a valid stream/table name or alias."
      }
    },
    {
      "name": "join ambiguous field",
      "statements": [
        "CREATE STREAM INPUT_1 (K STRING KEY, F0 INT) WITH (kafka_topic='input_1', value_format='JSON');",
        "CREATE STREAM INPUT_2 (K STRING KEY, F0 INT) WITH (kafka_topic='input_2', value_format='JSON');",
        "CREATE STREAM OUTPUT as SELECT I1.K, F0 FROM INPUT_1 i1 JOIN INPUT_2 i2 WITHIN 10 SECONDS ON i1.K = i2.K;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "Line: 3, Col: 38: Column 'F0' is ambiguous. Could be I1.F0 or I2.F0."
      }
    },
    {
      "name": "should allow ROWKEY as value column",
      "statements": [
        "CREATE STREAM INPUT (id int key, rowkey string) WITH (kafka_topic='input', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT * FROM input;"
      ],
      "inputs": [{"topic": "input", "key": 42, "value": {"rowkey": "a"}}],
      "outputs": [{"topic": "OUTPUT", "key": 42, "value": {"ROWKEY": "a"}}],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "ID INT KEY, ROWKEY STRING"}
        ]
      }
    },
    {
      "name": "should handle sources with generated column names",
      "statements": [
        "CREATE STREAM INPUT (KSQL_COL_3 INT KEY, KSQL_COL_2 INT, KSQL_COL_4 INT) WITH (kafka_topic='input', value_format='JSON');",
        "CREATE STREAM OUTPUT as SELECT KSQL_COL_3, KSQL_COL_2, ABS(KSQL_COL_2), ABS(KSQL_COL_2), ABS(KSQL_COL_2) FROM INPUT;"
      ],
      "inputs": [
        {"topic": "input", "key": 1, "value": {"KSQL_COL_2": 2, "KSQL_COL_4": 4}}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 1, "value": {"KSQL_COL_2": 2, "KSQL_COL_0": 2, "KSQL_COL_1": 2, "KSQL_COL_5": 2}}
      ]
    },
    {
      "name": "should handle sources with generated column names - with select star",
      "statements": [
        "CREATE STREAM INPUT (KSQL_COL_3 INT KEY, KSQL_COL_2 INT, KSQL_COL_4 INT) WITH (kafka_topic='input', value_format='JSON');",
        "CREATE STREAM OUTPUT as SELECT ABS(KSQL_COL_2), ABS(KSQL_COL_2), ABS(KSQL_COL_2), * FROM INPUT;"
      ],
      "inputs": [
        {"topic": "input", "key": 1, "value": {"KSQL_COL_2": 2, "KSQL_COL_4": 4}}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 1, "value": {"KSQL_COL_2": 2, "KSQL_COL_4": 4, "KSQL_COL_0": 2, "KSQL_COL_1": 2, "KSQL_COL_5": 2}}
      ]
    },
    {
      "name": "multiple key columns",
      "statements": [
        "CREATE STREAM INPUT (ID1 INT KEY, ID2 INT KEY, NAME STRING) WITH (kafka_topic='input',value_format='JSON');"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.parser.exception.ParseFailedException",
        "message": "Only single KEY column supported. Multiple KEY columns found: `ID1` (Line: 1, Col: 22), `ID2` (Line: 1, Col: 35)"
      }
    },
    {
      "name": "table with key column",
      "statements": [
        "CREATE TABLE INPUT (ID INT KEY, NAME STRING) WITH (kafka_topic='input',value_format='JSON');"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.parser.exception.ParseFailedException",
        "message": "Line: 1, Col: 21: Column `ID` is a 'KEY' column: please use 'PRIMARY KEY' for tables."
      }
    },
    {
      "name": "stream with primary key column",
      "statements": [
        "CREATE STREAM INPUT (ID INT PRIMARY KEY, NAME STRING) WITH (kafka_topic='input',value_format='JSON');"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.parser.exception.ParseFailedException",
        "message": "Line: 1, Col: 22: Column `ID` is a 'PRIMARY KEY' column: please use 'KEY' for streams."
      }
    },
    {
      "name": "copy simple key column into value",
      "statements": [
        "CREATE STREAM INPUT (ID INT KEY, F0 INT) WITH (kafka_topic='input', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT ID, AS_VALUE(ID) AS ID_COPY FROM INPUT;"
      ],
      "inputs": [
        {"topic": "input", "key": 10, "value": {"F0": 4}}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 10, "value": {"ID_COPY": 10}}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "ID INT KEY, ID_COPY INT"}
        ]
      }
    },
    {
      "name": "table without primary key fails",
      "statements": [
        "CREATE TABLE INPUT (ID INT, F0 INT) WITH (kafka_topic='input', value_format='JSON');"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlStatementException",
        "message": "Tables require a PRIMARY KEY. Please define the PRIMARY KEY."
      }
    },
    {
      "name": "table without primary key fails - schema inference",
      "statements": [
        "CREATE TABLE INPUT WITH (kafka_topic='input', value_format='Avro');"
      ],
      "topics": [
        {
          "name": "input",
          "schema": {"name": "blah", "type": "record", "fields": [{"name": "c1", "type": "int"}]},
          "format": "AVRO"
        }
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "Tables require a PRIMARY KEY. Please define the PRIMARY KEY.\nUse a partial schema to define the primary key and still load the value columns from the Schema Registry, for example:\n\tCREATE TABLE INPUT (ID INT PRIMARY KEY) WITH (...);"
      }
    },
    {
      "name": "stream without key column",
      "statements": [
        "CREATE STREAM INPUT (ID INT, F0 INT) WITH (kafka_topic='input', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT * FROM INPUT;"
      ],
      "inputs": [
        {"topic": "input", "key": null, "value": {"ID": 1, "F0": 2}},
        {"topic": "input", "key": "should be ignored", "value": {"ID": 2, "F0": 4}}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": null, "value": {"ID": 1, "F0": 2}},
        {"topic": "OUTPUT", "key": null, "value": {"ID": 2, "F0": 4}}
      ],
      "post": {
        "sources": [
          {"name": "INPUT", "type": "stream", "schema": "ID INT, F0 INT"},
          {"name": "OUTPUT", "type": "stream", "schema": "ID INT, F0 INT"}
        ]
      }
    }
  ]
}
