{
  "tests": [
    {
      "name": "validate without elements FAILS",
      "format": ["DELIMITED", "KAFKA"],
      "statements": [
        "CREATE STREAM INPUT WITH (kafka_topic='input', value_format='{FORMAT}');"
      ],
      "topics": [
        {
          "name": "input",
          "valueSchema": {"name": "blah", "type": "record", "fields": [{"name": "c1", "type": "int"}]},
          "valueFormat": "AVRO"
        }
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "No columns supplied."
      }
    },
    {
      "name": "validate without elements OK - AVRO",
      "statements": [
        "CREATE STREAM INPUT WITH (kafka_topic='input', value_format='AvRo');",
        "CREATE STREAM OUTPUT WITH(PARTITIONS = 4) as SELECT * FROM input;"
      ],
      "topics": [
        {
          "name": "input",
          "valueSchema": {"name": "blah", "type": "record", "fields": [{"name": "c1", "type": "int"}]},
          "valueFormat": "AVRO"
        },
        {
          "name": "OUTPUT",
          "valueFormat": "AVRO",
          "partitions": 4
        }
      ],
      "inputs": [{"topic": "input", "value": {"c1": 4}}],
      "outputs": [{"topic": "OUTPUT", "value": {"C1": 4}}]
    },
    {
      "name": "validate schema id without elements OK - AVRO",
      "statements": [
        "CREATE STREAM INPUT WITH (kafka_topic='input', value_format='AvRo', value_schema_id=1);",
        "CREATE STREAM OUTPUT WITH(PARTITIONS = 4) as SELECT * FROM input;"
      ],
      "topics": [
        {
          "name": "input",
          "valueSchema": {"name": "blah", "type": "record", "fields": [{"name": "c1", "type": "int"}]},
          "valueFormat": "AVRO"
        },
        {
          "name": "OUTPUT",
          "valueFormat": "AVRO",
          "partitions": 4
        }
      ],
      "inputs": [{"topic": "input", "value": {"c1": 4}}],
      "outputs": [{"topic": "OUTPUT", "value": {"c1": 4}}]
    },
    {
      "name": "validate key schema id wrong format without elements FAILS",
      "statements": [
        "CREATE STREAM INPUT WITH (kafka_topic='input', key_format='kafka', value_format='protobuf', key_schema_id=1);"
      ],
      "topics": [
        {
          "name": "input",
          "valueSchema": "syntax = \"proto3\"; message ConnectDefault1 { int32 c1 = 1; }",
          "valueFormat": "PROTOBUF",
          "keySchema": "syntax = \"proto3\"; message ConnectDefault1 { int32 c0 = 1; }",
          "keyFormat": "PROTOBUF"
        }
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "KEY_FORMAT should support schema inference when KEY_SCHEMA_ID is provided. Current format is KAFKA."
      }
    },
    {
      "name": "validate value schema id wrong format without elements FAILS",
      "statements": [
        "CREATE STREAM INPUT WITH (kafka_topic='input', key_format='protobuf', value_format='kafka', value_schema_id=1);"
      ],
      "topics": [
        {
          "name": "input",
          "valueSchema": "syntax = \"proto3\"; message ConnectDefault1 { int32 c1 = 1; }",
          "valueFormat": "PROTOBUF",
          "keySchema": "syntax = \"proto3\"; message ConnectDefault1 { int32 c0 = 1; }",
          "keyFormat": "PROTOBUF"
        }
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "VALUE_FORMAT should support schema inference when VALUE_SCHEMA_ID is provided. Current format is KAFKA."
      }
    },
    {
      "name": "validate key schema id with table elements FAILS",
      "statements": [
        "CREATE STREAM INPUT (`c3` INT KEY) WITH (kafka_topic='input', key_format='protobuf', value_format='protobuf', key_schema_id=1);"
      ],
      "topics": [
        {
          "name": "input",
          "valueSchema": "syntax = \"proto3\"; message ConnectDefault1 { int32 c1 = 1; int32 c2 = 2;}",
          "valueFormat": "PROTOBUF",
          "keySchema": "syntax = \"proto3\"; message ConnectDefault1 { int32 c0 = 1; }",
          "keyFormat": "PROTOBUF"
        }
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "Table elements and KEY_SCHEMA_ID cannot both exist for create statement."
      }
    },
    {
      "name": "validate value schema id with table elements FAILS",
      "statements": [
        "CREATE STREAM INPUT (`c1` INT, `c2` INT) WITH (kafka_topic='input', key_format='protobuf', value_format='protobuf', value_schema_id=2);"
      ],
      "topics": [
        {
          "name": "input",
          "valueSchema": "syntax = \"proto3\"; message ConnectDefault1 { int32 c1 = 1;}",
          "valueFormat": "PROTOBUF",
          "keySchema": "syntax = \"proto3\"; message ConnectDefault1 { int32 c0 = 1; }",
          "keyFormat": "PROTOBUF"
        }
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "Table elements and VALUE_SCHEMA_ID cannot both exist for create statement."
      }
    },
    {
      "name": "validate unwrapped value without elements OK - AVRO",
      "statements": [
        "CREATE STREAM INPUT WITH (kafka_topic='input', value_format='AvRo', wrap_single_value=false);",
        "CREATE STREAM OUTPUT as SELECT * FROM input;"
      ],
      "topics": [
        {"name": "input", "valueFormat": "AVRO", "valueSchema": "int"},
        {"name": "OUTPUT", "valueFormat": "AVRO", "valueSchema": {"name": "blah", "type": "record", "fields": [{"name": "ROWVAL", "type": "int"}]}}
      ],
      "inputs": [{"topic": "input", "value": 4}],
      "outputs": [{"topic": "OUTPUT", "value": {"ROWVAL": 4}}]
    },
    {
      "name": "validate without elements OK - PROTOBUF",
      "statements": [
        "CREATE STREAM INPUT WITH (kafka_topic='input', value_format='PROTOBUF');",
        "CREATE STREAM OUTPUT WITH(PARTITIONS = 4) as SELECT * FROM input;"
      ],
      "topics": [
        {
          "name": "input",
          "valueSchema": "syntax = \"proto3\"; message ConnectDefault1 { int32 c1 = 1; }",
          "valueFormat": "PROTOBUF"
        },
        {
          "name": "OUTPUT",
          "valueFormat": "PROTOBUF",
          "partitions": 4
        }
      ],
      "inputs": [{"topic": "input", "value": {"c1": 4}}],
      "outputs": [{"topic": "OUTPUT", "value": {"C1": 4}}]
    },
    {
      "name": "validate without elements with non-default schema name OK - PROTOBUF",
      "statements": [
        "CREATE STREAM INPUT WITH (kafka_topic='input', value_format='PROTOBUF');",
        "CREATE STREAM OUTPUT WITH(PARTITIONS = 4) as SELECT * FROM input;"
      ],
      "topics": [
        {
          "name": "input",
          "valueSchema": "syntax = \"proto3\"; message ValueName { int32 c1 = 1; }",
          "valueFormat": "PROTOBUF"
        },
        {
          "name": "OUTPUT",
          "valueFormat": "PROTOBUF",
          "partitions": 4
        }
      ],
      "inputs": [{"topic": "input", "value": {"c1": 4}}],
      "outputs": [{"topic": "OUTPUT", "value": {"C1": 4}}]
    },
    {
      "name": "validate schema id without elements OK - PROTOBUF",
      "statements": [
        "CREATE STREAM INPUT WITH (kafka_topic='input', value_format='PROTOBUF', value_schema_id=1);",
        "CREATE STREAM OUTPUT WITH(PARTITIONS = 4) as SELECT * FROM input;"
      ],
      "topics": [
        {
          "name": "input",
          "valueSchema": "syntax = \"proto3\"; message ConnectDefault1 { int32 c1 = 1; }",
          "valueFormat": "PROTOBUF"
        },
        {
          "name": "OUTPUT",
          "valueFormat": "PROTOBUF",
          "partitions": 4
        }
      ],
      "inputs": [{"topic": "input", "value": {"c1": 4}}],
      "outputs": [{"topic": "OUTPUT", "value": {"c1": 4}}]
    },
    {
      "name": "validate schema id without elements with non-default schema name OK - PROTOBUF",
      "statements": [
        "CREATE STREAM INPUT WITH (kafka_topic='input', value_format='PROTOBUF', value_schema_id=1);",
        "CREATE STREAM OUTPUT WITH(PARTITIONS = 4) as SELECT * FROM input;"
      ],
      "topics": [
        {
          "name": "input",
          "valueSchema": "syntax = \"proto3\"; message ValueName { int32 c1 = 1; }",
          "valueFormat": "PROTOBUF"
        },
        {
          "name": "OUTPUT",
          "valueFormat": "PROTOBUF",
          "partitions": 4
        }
      ],
      "inputs": [{"topic": "input", "value": {"c1": 4}}],
      "outputs": [{"topic": "OUTPUT", "value": {"c1": 4}}]
    },
    {
      "name": "validate without elements OK - JSON_SR SCHEMA",
      "statements": [
        "CREATE STREAM INPUT WITH (kafka_topic='input', value_format='JSON_SR');",
        "CREATE STREAM OUTPUT WITH(PARTITIONS = 4) as SELECT * FROM input;"
      ],
      "topics": [
        {
          "name": "input",
          "valueSchema": {"type": "object","properties": {"c1": {"type": "integer"}}},
          "valueFormat": "JSON"
        },
        {
          "name": "OUTPUT",
          "valueFormat": "JSON",
          "partitions": 4
        }
      ],
      "inputs": [{"topic": "input", "value": {"c1": 4}}],
      "outputs": [{"topic": "OUTPUT", "value": {"C1": 4}}]
    },
    {
      "name": "validate schema id without elements OK - JSON_SR SCHEMA",
      "statements": [
        "CREATE STREAM INPUT WITH (kafka_topic='input', value_format='JSON_SR', value_schema_id=1);",
        "CREATE STREAM OUTPUT WITH(PARTITIONS = 4) as SELECT * FROM input;"
      ],
      "topics": [
        {
          "name": "input",
          "valueSchema": {"type": "object","properties": {"c1": {"type": "integer"}}},
          "valueFormat": "JSON"
        },
        {
          "name": "OUTPUT",
          "valueFormat": "JSON",
          "partitions": 4
        }
      ],
      "inputs": [{"topic": "input", "value": {"c1": 4}}],
      "outputs": [{"topic": "OUTPUT", "value": {"c1": 4}}]
    },
    {
      "name": "with invalid or reserved words in schema - JSON",
      "statements": [
        "CREATE STREAM INPUT (`@TIMESTAMP` BIGINT, `FROM` BIGINT) WITH (kafka_topic='input', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT * FROM input;"
      ],
      "topics": [
        {
          "name": "input",
          "valueFormat": "JSON"
        },
        {
          "name": "OUTPUT",
          "valueFormat": "JSON"
        }
      ],
      "inputs": [{"topic": "input", "value": {"@timestamp": 4, "from": 5}}],
      "outputs": [{"topic": "OUTPUT", "value": {"@TIMESTAMP": 4, "FROM": 5}}],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "`@TIMESTAMP` BIGINT, `FROM` BIGINT"}
        ]
      }
    },
    {
      "name": "validate without value elements OK - AVRO",
      "statements": [
        "CREATE STREAM INPUT (rowkey int key) WITH (kafka_topic='input', value_format='AvRo');",
        "CREATE STREAM OUTPUT AS SELECT * FROM input;"
      ],
      "topics": [
        {
          "name": "input",
          "valueSchema": {"name": "blah", "type": "record", "fields": [{"name": "c1", "type": "int"}]},
          "valueFormat": "AVRO"
        },
        {
          "name": "OUTPUT",
          "valueFormat": "AVRO"
        }
      ],
      "inputs": [{"topic": "input", "key": 42, "value": {"c1": 4}}],
      "outputs": [{"topic": "OUTPUT", "key": 42, "value": {"C1": 4}}],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "ROWKEY INT KEY, `C1` INT"}
        ]
      }
    },
    {
      "name": "validate schema id without value elements OK - AVRO",
      "statements": [
        "CREATE STREAM INPUT (rowkey int key) WITH (kafka_topic='input', value_format='AvRo', value_schema_id=1);",
        "CREATE STREAM OUTPUT AS SELECT * FROM input;"
      ],
      "topics": [
        {
          "name": "input",
          "valueSchema": {"name": "blah", "type": "record", "fields": [{"name": "c1", "type": "int"}]},
          "valueFormat": "AVRO"
        },
        {
          "name": "OUTPUT",
          "valueFormat": "AVRO"
        }
      ],
      "inputs": [{"topic": "input", "key": 42, "value": {"c1": 4}}],
      "outputs": [{"topic": "OUTPUT", "key": 42, "value": {"c1": 4}}],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "ROWKEY INT KEY, `c1` INT"}
        ]
      }
    },
    {
      "name": "validate schema id without key value elements OK - AVRO",
      "statements": [
        "CREATE STREAM INPUT WITH (kafka_topic='input', key_format='avro', value_format='AvRo', key_schema_id=1, value_schema_id=2);",
        "CREATE STREAM OUTPUT AS SELECT * FROM input;"
      ],
      "topics": [
        {
          "name": "input",
          "keySchema": {"type": "int"},
          "keyFormat": "AVRO",
          "valueSchema": {"name": "blah", "type": "record", "fields": [{"name": "c1", "type": "int"}]},
          "valueFormat": "AVRO"
        },
        {
          "name": "OUTPUT",
          "valueFormat": "AVRO"
        }
      ],
      "inputs": [{"topic": "input", "key": 42, "value": {"c1": 4}}],
      "outputs": [{"topic": "OUTPUT", "key": 42, "value": {"c1": 4}}],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "ROWKEY INT KEY, `c1` INT"}
        ]
      }
    },
    {
      "name": "validate without value elements OK - PROTOBUF",
      "statements": [
        "CREATE STREAM INPUT (rowkey int key) WITH (kafka_topic='input', value_format='PROTOBUF');",
        "CREATE STREAM OUTPUT AS SELECT * FROM input;"
      ],
      "topics": [
        {
          "name": "input",
          "valueSchema": "syntax = \"proto3\"; message ConnectDefault1 { int32 c1 = 1; }",
          "valueFormat": "PROTOBUF"
        },
        {
          "name": "OUTPUT",
          "valueFormat": "PROTOBUF"
        }
      ],
      "inputs": [{"topic": "input", "key": 42, "value": {"c1": 4}}],
      "outputs": [{"topic": "OUTPUT", "key": 42, "value": {"C1": 4}}],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "ROWKEY INT KEY, `C1` INT"}
        ]
      }
    },
    {
      "name": "validate schema id without value elements OK - PROTOBUF",
      "statements": [
        "CREATE STREAM INPUT (rowkey int key) WITH (kafka_topic='input', value_format='PROTOBUF', value_schema_id=1);",
        "CREATE STREAM OUTPUT AS SELECT * FROM input;"
      ],
      "topics": [
        {
          "name": "input",
          "valueSchema": "syntax = \"proto3\"; message ConnectDefault1 { int32 c1 = 1; }",
          "valueFormat": "PROTOBUF"
        },
        {
          "name": "OUTPUT",
          "valueFormat": "PROTOBUF"
        }
      ],
      "inputs": [{"topic": "input", "key": 42, "value": {"c1": 4}}],
      "outputs": [{"topic": "OUTPUT", "key": 42, "value": {"c1": 4}}],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "ROWKEY INT KEY, `c1` INT"}
        ]
      }
    },
    {
      "name": "validate schema id without key value elements OK - PROTOBUF",
      "statements": [
        "CREATE STREAM INPUT WITH (kafka_topic='input', format='PROTOBUF', key_schema_id=1, value_schema_id=2);",
        "CREATE STREAM OUTPUT AS SELECT * FROM input;"
      ],
      "topics": [
        {
          "name": "input",
          "valueSchema": "syntax = \"proto3\"; message ConnectDefault1 { int32 c1 = 1; }",
          "valueFormat": "PROTOBUF",
          "keySchema": "syntax = \"proto3\"; message ConnectDefault1 { int32 c0 = 1; }",
          "keyFormat": "PROTOBUF"
        },
        {
          "name": "OUTPUT",
          "valueFormat": "PROTOBUF",
          "keyFormat": "PROTOBUF"
        }
      ],
      "inputs": [{"topic": "input", "key": {"c0": 42}, "value": {"c1": 4}}],
      "outputs": [{"topic": "OUTPUT", "key": {"c0": 42}, "value": {"c1": 4}}],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "`c0` INT KEY, `c1` INT"}
        ]
      }
    },
    {
      "name": "validate schema id and schema full name from multiple schema definitions OK - PROTOBUF",
      "statements": [
        "CREATE STREAM INPUT WITH (kafka_topic='input', format='PROTOBUF', key_schema_id=1, key_schema_full_name='KeySchema2', value_schema_id=2, value_schema_full_name='ValueSchema2');",
        "CREATE STREAM OUTPUT AS SELECT * FROM input;"
      ],
      "topics": [
        {
          "name": "input",
          "valueSchema": "syntax = \"proto3\"; message ValueSchema1 { int32 C0 = 1; } message ValueSchema2 { int32 C1 = 1; }",
          "valueFormat": "PROTOBUF",
          "keySchema": "syntax = \"proto3\"; message KeySchema1 { int32 K0 = 1; } message KeySchema2 { int32 K1 = 1; }",
          "keyFormat": "PROTOBUF"
        },
        {
          "name": "OUTPUT",
          "valueFormat": "PROTOBUF",
          "keyFormat": "PROTOBUF"
        }
      ],
      "inputs": [{"topic": "input", "key": {"k1": 42}, "value": {"c1": 4}}],
      "outputs": [{"topic": "OUTPUT", "key": {"k1": 42}, "value": {"c1": 4}}],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "`K1` INT KEY, `C1` INT"}
        ]
      }
    },
    {
      "name": "validate without value elements OK - JSON_SR SCHEMA",
      "statements": [
        "CREATE STREAM INPUT (rowkey int key) WITH (kafka_topic='input', value_format='JSON_SR');",
        "CREATE STREAM OUTPUT AS SELECT * FROM input;"
      ],
      "topics": [
        {
          "name": "input",
          "valueSchema": {"type": "object","properties": {"c1": {"type": "integer"}}},
          "valueFormat": "JSON"
        },
        {
          "name": "OUTPUT",
          "valueFormat": "JSON"
        }
      ],
      "inputs": [{"topic": "input", "key": 42, "value": {"c1": 4}}],
      "outputs": [{"topic": "OUTPUT", "key": 42, "value": {"C1": 4}}],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "ROWKEY INT KEY, `C1` BIGINT"}
        ]
      }
    },
    {
      "name": "validate schema id without value elements OK - JSON_SR SCHEMA",
      "statements": [
        "CREATE STREAM INPUT (rowkey int key) WITH (kafka_topic='input', value_format='JSON_SR', value_schema_id=1);",
        "CREATE STREAM OUTPUT AS SELECT * FROM input;"
      ],
      "topics": [
        {
          "name": "input",
          "valueSchema": {"type": "object","properties": {"c1": {"type": "integer"}}},
          "valueFormat": "JSON_SR"
        },
        {
          "name": "OUTPUT",
          "valueFormat": "JSON"
        }
      ],
      "inputs": [{"topic": "input", "key": 42, "value": {"c1": 4}}],
      "outputs": [{"topic": "OUTPUT", "key": 42, "value": {"c1": 4}}],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "ROWKEY INT KEY, `c1` BIGINT"}
        ]
      }
    },
    {
      "name": "validate schema id without key value elements OK - JSON_SR SCHEMA",
      "statements": [
        "CREATE STREAM INPUT WITH (kafka_topic='input', format='JSON_SR', key_schema_id=1, value_schema_id=2);",
        "CREATE STREAM OUTPUT AS SELECT * FROM input;"
      ],
      "topics": [
        {
          "name": "input",
          "valueSchema": {"type": "object","properties": {"c1": {"type": "integer"}}},
          "valueFormat": "JSON_SR",
          "keySchema": {"oneOf":[{"type":"null"},{"type":"integer","connect.type":"int32"}]},
          "keyFormat": "JSON_SR"
        },
        {
          "name": "OUTPUT",
          "valueFormat": "JSON",
          "keyFormat": "JSON"
        }
      ],
      "inputs": [{"topic": "input", "key": 42, "value": {"c1": 4}}],
      "outputs": [{"topic": "OUTPUT", "key": 42, "value": {"c1": 4}}],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "ROWKEY INT KEY, `c1` BIGINT"}
        ]
      }
    },
    {
      "name": "validate without value elements OK - custom key name",
      "statements": [
        "CREATE STREAM INPUT (id int key) WITH (kafka_topic='input', value_format='JSON_SR');",
        "CREATE STREAM OUTPUT AS SELECT * FROM input;"
      ],
      "topics": [
        {
          "name": "input",
          "valueSchema": {"type": "object", "properties": {"c1": {"type": "integer"}}},
          "valueFormat": "JSON"
        },
        {
          "name": "OUTPUT",
          "valueFormat": "JSON"
        }
      ],
      "inputs": [{"topic": "input", "key": 42, "value": {"c1": 4}}],
      "outputs": [{"topic": "OUTPUT", "key": 42, "value": {"C1": 4}}],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "ID INT KEY, C1 BIGINT"}
        ]
      }
    },
    {
      "name": "validate schema id without value elements OK - custom key name",
      "statements": [
        "CREATE STREAM INPUT (id int key) WITH (kafka_topic='input', value_format='JSON_SR', value_schema_id=1);",
        "CREATE STREAM OUTPUT AS SELECT * FROM input;"
      ],
      "topics": [
        {
          "name": "input",
          "valueSchema": {"type": "object", "properties": {"c1": {"type": "integer"}}},
          "valueFormat": "JSON"
        },
        {
          "name": "OUTPUT",
          "valueFormat": "JSON"
        }
      ],
      "inputs": [{"topic": "input", "key": 42, "value": {"c1": 4}}],
      "outputs": [{"topic": "OUTPUT", "key": 42, "value": {"c1": 4}}],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "ID INT KEY, `c1` BIGINT"}
        ]
      }
    },
    {
      "name": "validate with elements OK",
      "format": ["JSON", "PROTOBUF"],
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, V0 INT) WITH (kafka_topic='input', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT AS SELECT * FROM INPUT;"
      ],
      "inputs": [{"topic": "input", "value": {"V0": 4}}],
      "outputs": [{"topic": "OUTPUT", "value": {"V0": 4}}]
    },
    {
      "name": "validate with elements OK - AVRO",
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, V0 INT) WITH (kafka_topic='input', value_format='AVRO');",
        "CREATE STREAM OUTPUT WITH(PARTITIONS = 4) as SELECT * FROM input;"
      ],
      "topics": [
        {
          "name": "input",
          "valueSchema": {"name": "blah", "type": "record", "fields": [{"name": "v0", "type": "int"}]},
          "valueFormat": "AVRO"
        },
        {
          "name": "OUTPUT",
          "valueFormat": "AVRO",
          "partitions": 4
        }
      ],
      "inputs": [{"topic": "input", "value": {"v0": 4}}],
      "outputs": [{"topic": "OUTPUT", "value": {"V0": 4}}]
    },
    {
      "name": "validate multiple value elements in C* FAILS - KAFKA",
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, V0 INT, V1 STRING) WITH (kafka_topic='input', value_format='KafkA');"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "The 'KAFKA' format only supports a single field. Got: [`V0` INTEGER, `V1` STRING]"
      }
    },
    {
      "name": "validate multiple value elements in C*AS FAILS - KAFKA",
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, V0 INT, V1 STRING) WITH (kafka_topic='input', value_format='DELIMITED');",
        "CREATE STREAM OUTPUT WITH (value_format='kafka') AS SELECT * FROM INPUT;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "The 'KAFKA' format only supports a single field. Got: [`V0` INTEGER, `V1` STRING]"
      }
    },
    {
      "name": "validate boolean elements FAILS - KAFKA",
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, V0 BOOLEAN) WITH (kafka_topic='input', value_format='KAFKA');"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "The 'KAFKA' format does not support type 'BOOLEAN'"
      }
    },
    {
      "name": "validate boolean elements OK",
      "format": ["DELIMITED"],
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, V0 BOOLEAN) WITH (kafka_topic='input', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT AS SELECT * FROM INPUT;"
      ],
      "inputs": [{"topic": "input", "value": "true"}],
      "outputs": [{"topic": "OUTPUT", "value": "true"}]
    },
    {
      "name": "validate boolean elements OK",
      "format": ["JSON", "JSON_SR", "AVRO", "PROTOBUF"],
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, V0 BOOLEAN) WITH (kafka_topic='input', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT AS SELECT * FROM INPUT;"
      ],
      "inputs": [{"topic": "input", "value": {"V0": true}}],
      "outputs": [{"topic": "OUTPUT", "value": {"V0": true}}]
    },
    {
      "name": "validate int elements OK",
      "format": ["DELIMITED"],
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, V0 INT) WITH (kafka_topic='input', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT AS SELECT * FROM INPUT;"
      ],
      "inputs": [{"topic": "input", "value": "10"}],
      "outputs": [{"topic": "OUTPUT", "value": "10"}]
    },
    {
      "name": "validate int elements OK",
      "format": ["KAFKA"],
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, V0 INT) WITH (kafka_topic='input', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT AS SELECT * FROM INPUT;"
      ],
      "inputs": [{"topic": "input", "value": 10}],
      "outputs": [{"topic": "OUTPUT", "value": 10}]
    },
    {
      "name": "validate int elements OK",
      "format": ["JSON", "JSON_SR", "AVRO", "PROTOBUF"],
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, V0 INT) WITH (kafka_topic='input', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT AS SELECT * FROM INPUT;"
      ],
      "inputs": [{"topic": "input", "value": {"V0": 10}}],
      "outputs": [{"topic": "OUTPUT", "value": {"V0": 10}}]
    },
    {
      "name": "validate bigint elements OK",
      "format": ["DELIMITED"],
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, V0 BIGINT) WITH (kafka_topic='input', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT AS SELECT * FROM INPUT;"
      ],
      "inputs": [{"topic": "input", "value": "10000000000"}],
      "outputs": [{"topic": "OUTPUT", "value": "10000000000"}]
    },
    {
      "name": "validate bigint elements OK",
      "format": ["KAFKA"],
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, V0 BIGINT) WITH (kafka_topic='input', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT AS SELECT * FROM INPUT;"
      ],
      "inputs": [{"topic": "input", "value": 10000000000}],
      "outputs": [{"topic": "OUTPUT", "value": 10000000000}]
    },
    {
      "name": "validate bigint elements OK",
      "format": ["JSON", "JSON_SR", "AVRO", "PROTOBUF"],
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, V0 BIGINT) WITH (kafka_topic='input', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT AS SELECT * FROM INPUT;"
      ],
      "inputs": [{"topic": "input", "value": {"V0": 10000000000}}],
      "outputs": [{"topic": "OUTPUT", "value": {"V0": 10000000000}}]
    },
    {
      "name": "validate double elements OK",
      "format": ["DELIMITED"],
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, V0 DOUBLE) WITH (kafka_topic='input', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT AS SELECT * FROM INPUT;"
      ],
      "inputs": [{"topic": "input", "value": "10.1"}],
      "outputs": [{"topic": "OUTPUT", "value": "10.1"}]
    },
    {
      "name": "validate double elements OK",
      "format": ["KAFKA"],
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, V0 DOUBLE) WITH (kafka_topic='input', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT AS SELECT * FROM INPUT;"
      ],
      "inputs": [{"topic": "input", "value": 10.1}],
      "outputs": [{"topic": "OUTPUT", "value": 10.1}]
    },
    {
      "name": "validate double elements OK",
      "format": ["JSON", "JSON_SR", "AVRO", "PROTOBUF"],
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, V0 DOUBLE) WITH (kafka_topic='input', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT AS SELECT * FROM INPUT;"
      ],
      "inputs": [{"topic": "input", "value": {"V0": 10.1}}],
      "outputs": [{"topic": "OUTPUT", "value": {"V0": 10.1}}]
    },
    {
      "name": "validate decimal elements OK",
      "format": ["JSON", "JSON_SR"],
      "statements": [
        "CREATE STREAM INPUT (V0 DECIMAL(15,14)) WITH (kafka_topic='input', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT AS SELECT * FROM INPUT;"
      ],
      "inputs": [{"topic": "input", "value": {"V0": 1.12345678901234}}],
      "outputs": [{"topic": "OUTPUT", "value": {"V0": 1.12345678901234}}]
    },
    {
      "name": "validate string elements OK",
      "format": ["DELIMITED", "KAFKA"],
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, V0 STRING) WITH (kafka_topic='input', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT AS SELECT * FROM INPUT;"
      ],
      "inputs": [{"topic": "input", "value": "Hello"}],
      "outputs": [{"topic": "OUTPUT", "value": "Hello"}]
    },
    {
      "name": "validate string elements OK",
      "format": ["JSON", "JSON_SR", "AVRO", "PROTOBUF"],
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, V0 STRING) WITH (kafka_topic='input', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT AS SELECT * FROM INPUT;"
      ],
      "inputs": [{"topic": "input", "value": {"V0": "Hello"}}],
      "outputs": [{"topic": "OUTPUT", "value": {"V0": "Hello"}}]
    },
    {
      "name": "validate array element in C* FAILS",
      "format": ["DELIMITED", "KAFKA"],
      "statements": [
        "CREATE STREAM INPUT (V0 ARRAY<INT>) WITH (kafka_topic='input', value_format='{FORMAT}');"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "format does not support type 'ARRAY'"
      }
    },
    {
      "name": "validate array element in C*AS FAILS",
      "format": ["DELIMITED", "KAFKA"],
      "statements": [
        "CREATE STREAM INPUT (V0 ARRAY<INT>) WITH (kafka_topic='input', value_format='JSON');",
        "CREATE STREAM OUTPUT WITH (value_format='{FORMAT}') AS SELECT * FROM INPUT;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "format does not support type 'ARRAY'"
      }
    },
    {
      "name": "validate array element OK",
      "format": ["JSON", "JSON_SR", "AVRO", "PROTOBUF"],
      "statements": [
        "CREATE STREAM INPUT (V0 ARRAY<INT>) WITH (kafka_topic='input', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT AS SELECT * FROM INPUT;"
      ],
      "inputs": [{"topic": "input", "value": {"V0": [1]}}],
      "outputs": [{"topic": "OUTPUT", "value": {"V0": [1]}}]
    },
    {
      "name": "validate map element in C* FAILS",
      "format": ["DELIMITED", "KAFKA"],
      "statements": [
        "CREATE STREAM INPUT (V0 MAP<STRING, INT>) WITH (kafka_topic='input', value_format='{FORMAT}');"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "format does not support type 'MAP'"
      }
    },
    {
      "name": "validate map element in C*AS FAILS",
      "format": ["DELIMITED", "KAFKA"],
      "statements": [
        "CREATE STREAM INPUT (V0 MAP<STRING, INT>) WITH (kafka_topic='input', value_format='JSON');",
        "CREATE STREAM OUTPUT WITH(value_format='{FORMAT}') AS SELECT * FROM INPUT;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "format does not support type 'MAP'"
      }
    },
    {
      "name": "validate map element OK",
      "format": ["JSON", "AVRO", "PROTOBUF"],
      "statements": [
        "CREATE STREAM INPUT (V0 MAP<STRING, INT>) WITH (kafka_topic='input', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT AS SELECT * FROM INPUT;"
      ],
      "inputs": [{"topic": "input", "value": {"V0": {"k1": 1}}}],
      "outputs": [{"topic": "OUTPUT", "value": {"V0": {"k1": 1}}}]
    },
    {
      "name": "validate struct element in C* FAILS",
      "format": ["DELIMITED", "KAFKA"],
      "statements": [
        "CREATE STREAM INPUT (V0 STRUCT<F0 STRING>) WITH (kafka_topic='input', value_format='{FORMAT}');"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "format does not support type 'STRUCT'"
      }
    },
    {
      "name": "validate struct element in C*AS FAILS",
      "format": ["DELIMITED", "KAFKA"],
      "statements": [
        "CREATE STREAM INPUT (V0 STRUCT<F0 STRING>) WITH (kafka_topic='input', value_format='JSON');",
        "CREATE STREAM OUTPUT WITH(value_format='{FORMAT}') AS SELECT * FROM INPUT;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "format does not support type 'STRUCT'"
      }
    },
    {
      "name": "validate struct element OK",
      "format": ["JSON", "JSON_SR", "AVRO", "PROTOBUF"],
      "statements": [
        "CREATE STREAM INPUT (V0 STRUCT<F0 STRING, F1 INT>) WITH (kafka_topic='input', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT AS SELECT * FROM INPUT;"
      ],
      "inputs": [{"topic": "input", "value": {"V0": {"f0": "bob", "f1": 1}}}],
      "outputs": [{"topic": "OUTPUT", "value": {"V0": {"F0": "bob", "F1": 1}}}]
    },
    {
      "name": "validate AVRO uses null for unknown element",
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, c1 INT, unknown INT) WITH (kafka_topic='input', value_format='AVRO');",
        "CREATE STREAM S WITH(PARTITIONS = 4) as SELECT * FROM input;"
      ],
      "topics": [
        {
          "name": "input",
          "valueSchema": {"name": "blah", "type": "record", "fields": [{"name": "c1", "type": "int"}]},
          "valueFormat": "AVRO"
        },
        {
          "name": "S",
          "valueFormat": "AVRO",
          "partitions": 4
        }
      ],
      "inputs": [{"topic": "input", "value": {"c1": 4}}],
      "outputs": [{"topic": "S", "value": {"UNKNOWN": null, "C1": 4}}]
    },
    {
      "name": "non-join should reject ROWTIME in projection",
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, F0 INT) WITH (kafka_topic='input', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT K, ROWTIME FROM INPUT;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "Reserved column name in select: `ROWTIME`. Please remove or alias the column."
      }
    },
    {
      "name": "non-join should reject WINDOWSTART in projection",
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, F0 INT) WITH (kafka_topic='input', value_format='JSON', window_type='session');",
        "CREATE STREAM OUTPUT AS SELECT K, WINDOWSTART FROM INPUT;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "Reserved column name in select: `WINDOWSTART`. Please remove or alias the column."
      }
    },
    {
      "name": "non-join should reject WINDOWEND in projection",
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, F0 INT) WITH (kafka_topic='input', value_format='JSON', window_type='session');",
        "CREATE STREAM OUTPUT AS SELECT K, WINDOWEND FROM INPUT;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "Reserved column name in select: `WINDOWEND`. Please remove or alias the column."
      }
    },
    {
      "name": "non-join leaves aliased system columns in output's value schema",
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, F0 INT) WITH (kafka_topic='input', value_format='JSON', window_type='session');",
        "CREATE STREAM OUTPUT AS SELECT K, F0, ROWTIME AS TIME, WINDOWSTART AS WSTART, WINDOWEND AS WEND FROM INPUT;"
      ],
      "inputs": [{"topic": "input", "key": "k", "value": {"F0": 4}, "timestamp": 1, "window": {"start": 12, "end": 465, "type": "session"}}],
      "outputs": [{"topic": "OUTPUT", "key": "k", "value": {"F0": 4, "TIME": 1, "WSTART": 12, "WEND": 465}, "timestamp": 1, "window": {"start": 12, "end": 465, "type": "session"}}]
    },
    {
      "name": "join should reject ROWTIME in projection",
      "statements": [
        "CREATE STREAM LEFT_STREAM (K STRING KEY, F0 INT) WITH (kafka_topic='left', value_format='JSON');",
        "CREATE STREAM RIGHT_STREAM (K STRING KEY, F1 INT) WITH (kafka_topic='right', value_format='JSON');",
        "CREATE STREAM OUTPUT as SELECT l.K, l.ROWTIME AS ROWTIME, f0, f1 FROM left_stream l join right_stream r WITHIN 1 seconds ON l.k = r.k;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "Reserved column name in select: `ROWTIME`. Please remove or alias the column."
      }
    },
    {
      "name": "join should reject WINDOWSTART in projection",
      "statements": [
        "CREATE STREAM LEFT_STREAM (K STRING KEY, F0 INT) WITH (kafka_topic='left', value_format='JSON', window_type='tumbling', window_size='1 second');",
        "CREATE STREAM RIGHT_STREAM (K STRING KEY, F1 INT) WITH (kafka_topic='right', value_format='JSON', window_type='tumbling', window_size='1 second');",
        "CREATE STREAM OUTPUT as SELECT l.K, l.WINDOWSTART AS WINDOWSTART, f0 FROM left_stream l join right_stream r WITHIN 1 seconds ON l.k = r.k;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "Reserved column name in select: `WINDOWSTART`. Please remove or alias the column."
      }
    },
    {
      "name": "join should reject WINDOWEND in projection",
      "statements": [
        "CREATE STREAM LEFT_STREAM (K STRING KEY, F0 INT) WITH (kafka_topic='left', value_format='JSON', window_type='tumbling', window_size='1 second');",
        "CREATE STREAM RIGHT_STREAM (K STRING KEY, F1 INT) WITH (kafka_topic='right', value_format='JSON', window_type='tumbling', window_size='1 second');",
        "CREATE STREAM OUTPUT as SELECT l.K, l.WINDOWEND AS WINDOWEND, f0 FROM left_stream l join right_stream r WITHIN 1 seconds ON l.k = r.k;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "Reserved column name in select: `WINDOWEND`. Please remove or alias the column."
      }
    },
    {
      "name": "join leaves aliased system columns in output's value schema",
      "statements": [
        "CREATE STREAM LEFT_STREAM (K STRING KEY, F0 INT) WITH (kafka_topic='left', value_format='JSON', window_type='tumbling', window_size='1 second');",
        "CREATE STREAM RIGHT_STREAM (K STRING KEY, F1 INT) WITH (kafka_topic='right', value_format='JSON', window_type='tumbling', window_size='1 second');",
        "CREATE STREAM OUTPUT as SELECT l.K, l.ROWTIME AS TIME, l.WINDOWSTART AS WSTART, l.WINDOWEND AS WEND, f0, f1 FROM left_stream l join right_stream r WITHIN 1 seconds ON l.k = r.k;"
      ],
      "inputs": [
        {"topic": "left", "key": "k", "value": {"F0": 4}, "timestamp": 1, "window": {"start": 0, "end": 1000, "type": "time"}},
        {"topic": "right", "key": "k", "value": {"F1": 6}, "timestamp": 2, "window": {"start": 0, "end": 1000, "type": "time"}}
      ],
      "outputs": [{"topic": "OUTPUT", "key": "k", "value": {"F0": 4, "F1": 6, "TIME": 1, "WSTART": 0, "WEND": 1000}, "timestamp": 2, "window": {"start": 0, "end": 1000, "type": "time"}}]
    },
    {
      "name": "group-by rejects window bounds in projection",
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, F0 INT) WITH (kafka_topic='input', value_format='JSON');",
        "CREATE TABLE OUTPUT AS SELECT K, WINDOWSTART, COUNT(*) AS COUNT FROM INPUT GROUP BY WINDOWSTART;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "Reserved column name in select: `WINDOWSTART`. Please remove or alias the column."
      }
    },
    {
      "name": "non-join qualified select star",
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, F0 INT) WITH (kafka_topic='input', value_format='JSON');",
        "CREATE STREAM OUTPUT as SELECT i.* FROM INPUT i;"
      ],
      "inputs": [{"topic": "input", "value": {"F0": 4}}],
      "outputs": [{"topic": "OUTPUT", "value": {"F0": 4}}]
    },
    {
      "name": "non-join select star with unknown qualifier",
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, F0 INT) WITH (kafka_topic='input', value_format='JSON');",
        "CREATE STREAM OUTPUT as SELECT K, unknown.* FROM INPUT i;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "'UNKNOWN' is not a valid stream/table name or alias."
      }
    },
    {
      "name": "join qualified select star left",
      "statements": [
        "CREATE STREAM INPUT_1 (K STRING KEY, F0 INT) WITH (kafka_topic='input_1', value_format='JSON');",
        "CREATE STREAM INPUT_2 (K STRING KEY, F0 INT) WITH (kafka_topic='input_2', value_format='JSON');",
        "CREATE STREAM OUTPUT as SELECT i1.* FROM INPUT_1 i1 JOIN INPUT_2 i2 WITHIN 10 SECONDS ON i1.K = i2.K;"
      ],
      "inputs": [
        {"topic": "input_1", "key": "1", "value": {"F0": 4}, "timestamp": 10},
        {"topic": "input_2", "key": "1", "value": {"F0": 4}, "timestamp": 11}
      ],
      "outputs": [{"topic": "OUTPUT", "key": "1", "value": {"I1_F0": 4}, "timestamp": 11}]
    },
    {
      "name": "join qualified select star right",
      "statements": [
        "CREATE STREAM INPUT_1 (K STRING KEY, F0 INT) WITH (kafka_topic='input_1', value_format='JSON');",
        "CREATE STREAM INPUT_2 (K STRING KEY, F0 INT) WITH (kafka_topic='input_2', value_format='JSON');",
        "CREATE STREAM OUTPUT as SELECT i2.* FROM INPUT_1 i1 JOIN INPUT_2 i2 WITHIN 10 SECONDS ON i1.K = i2.K;"
      ],
      "inputs": [
        {"topic": "input_1", "key": "1", "value": {"F0": 4}, "timestamp": 10},
        {"topic": "input_2", "key": "1", "value": {"F0": 4}, "timestamp": 11}
      ],
      "outputs": [{"topic": "OUTPUT", "key": "1", "value": {"I2_F0": 4}, "timestamp": 11}]
    },
    {
      "name": "join unqualified select star",
      "statements": [
        "CREATE STREAM INPUT_1 (K STRING KEY, F0 INT) WITH (kafka_topic='input_1', value_format='JSON');",
        "CREATE STREAM INPUT_2 (K STRING KEY, F0 INT) WITH (kafka_topic='input_2', value_format='JSON');",
        "CREATE STREAM OUTPUT as SELECT * FROM INPUT_1 i1 JOIN INPUT_2 i2 WITHIN 10 SECONDS ON i1.K = i2.K;"
      ],
      "inputs": [
        {"topic": "input_1", "key": "1", "value": {"F0": 4}, "timestamp": 10},
        {"topic": "input_2", "key": "1", "value": {"F0": 4}, "timestamp": 11}
      ],
      "outputs": [{"topic": "OUTPUT", "key": "1", "value": {"I1_F0": 4, "I2_K": "1", "I2_F0": 4}, "timestamp": 11}]
    },
    {
      "name": "join unknown qualified select star",
      "statements": [
        "CREATE STREAM INPUT_1 (K STRING KEY, F0 INT) WITH (kafka_topic='input_1', value_format='JSON');",
        "CREATE STREAM INPUT_2 (K STRING KEY, F0 INT) WITH (kafka_topic='input_2', value_format='JSON');",
        "CREATE STREAM OUTPUT as SELECT unknown.* FROM INPUT_1 i1 JOIN INPUT_2 i2 WITHIN 10 SECONDS ON i1.K = i2.K;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "'UNKNOWN' is not a valid stream/table name or alias."
      }
    },
    {
      "name": "non-join unknown field",
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, F0 INT) WITH (kafka_topic='input', value_format='JSON');",
        "CREATE STREAM OUTPUT as SELECT K, unknown FROM INPUT;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlStatementException",
        "message": "SELECT column 'UNKNOWN' cannot be resolved."
      }
    },
    {
      "name": "join unknown field",
      "statements": [
        "CREATE STREAM INPUT_1 (K STRING KEY, F0 INT) WITH (kafka_topic='input_1', value_format='JSON');",
        "CREATE STREAM INPUT_2 (K STRING KEY, F0 INT) WITH (kafka_topic='input_2', value_format='JSON');",
        "CREATE STREAM OUTPUT as SELECT I1.K, unknown FROM INPUT_1 i1 JOIN INPUT_2 i2 WITHIN 10 SECONDS ON i1.K = i2.K;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlStatementException",
        "message": "SELECT column 'UNKNOWN' cannot be resolved"
      }
    },
    {
      "name": "join unknown field source",
      "statements": [
        "CREATE STREAM INPUT_1 (K STRING KEY, F0 INT) WITH (kafka_topic='input_1', value_format='JSON');",
        "CREATE STREAM INPUT_2 (K STRING KEY, F0 INT) WITH (kafka_topic='input_2', value_format='JSON');",
        "CREATE STREAM OUTPUT as SELECT * FROM INPUT_1 i1 JOIN INPUT_2 i2 WITHIN 10 SECONDS ON unknown.K = i2.K;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "'UNKNOWN' is not a valid stream/table name or alias."
      }
    },
    {
      "name": "join ambiguous field",
      "statements": [
        "CREATE STREAM INPUT_1 (K STRING KEY, F0 INT) WITH (kafka_topic='input_1', value_format='JSON');",
        "CREATE STREAM INPUT_2 (K STRING KEY, F0 INT) WITH (kafka_topic='input_2', value_format='JSON');",
        "CREATE STREAM OUTPUT as SELECT I1.K, F0 FROM INPUT_1 i1 JOIN INPUT_2 i2 WITHIN 10 SECONDS ON i1.K = i2.K;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "Line: 3, Col: 38: Column 'F0' is ambiguous. Could be I1.F0 or I2.F0."
      }
    },
    {
      "name": "should allow ROWKEY as value column",
      "statements": [
        "CREATE STREAM INPUT (id int key, rowkey string) WITH (kafka_topic='input', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT * FROM input;"
      ],
      "inputs": [{"topic": "input", "key": 42, "value": {"rowkey": "a"}}],
      "outputs": [{"topic": "OUTPUT", "key": 42, "value": {"ROWKEY": "a"}}],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "ID INT KEY, ROWKEY STRING"}
        ]
      }
    },
    {
      "name": "should handle sources with generated column names",
      "statements": [
        "CREATE STREAM INPUT (KSQL_COL_3 INT KEY, KSQL_COL_2 INT, KSQL_COL_4 INT) WITH (kafka_topic='input', value_format='JSON');",
        "CREATE STREAM OUTPUT as SELECT KSQL_COL_3, KSQL_COL_2, ABS(KSQL_COL_2), ABS(KSQL_COL_2), ABS(KSQL_COL_2) FROM INPUT;"
      ],
      "inputs": [
        {"topic": "input", "key": 1, "value": {"KSQL_COL_2": 2, "KSQL_COL_4": 4}}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 1, "value": {"KSQL_COL_2": 2, "KSQL_COL_0": 2, "KSQL_COL_1": 2, "KSQL_COL_5": 2}}
      ]
    },
    {
      "name": "should handle sources with generated column names - with select star",
      "statements": [
        "CREATE STREAM INPUT (KSQL_COL_3 INT KEY, KSQL_COL_2 INT, KSQL_COL_4 INT) WITH (kafka_topic='input', value_format='JSON');",
        "CREATE STREAM OUTPUT as SELECT ABS(KSQL_COL_2), ABS(KSQL_COL_2), ABS(KSQL_COL_2), * FROM INPUT;"
      ],
      "inputs": [
        {"topic": "input", "key": 1, "value": {"KSQL_COL_2": 2, "KSQL_COL_4": 4}}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 1, "value": {"KSQL_COL_2": 2, "KSQL_COL_4": 4, "KSQL_COL_0": 2, "KSQL_COL_1": 2, "KSQL_COL_5": 2}}
      ]
    },
    {
      "name": "table with key column",
      "statements": [
        "CREATE TABLE INPUT (ID INT KEY, NAME STRING) WITH (kafka_topic='input',value_format='JSON');"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.parser.exception.ParseFailedException",
        "message": "Line: 1, Col: 21: Column `ID` is a 'KEY' column: please use 'PRIMARY KEY' for tables."
      }
    },
    {
      "name": "stream with primary key column",
      "statements": [
        "CREATE STREAM INPUT (ID INT PRIMARY KEY, NAME STRING) WITH (kafka_topic='input',value_format='JSON');"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.parser.exception.ParseFailedException",
        "message": "Line: 1, Col: 22: Column `ID` is a 'PRIMARY KEY' column: please use 'KEY' for streams."
      }
    },
    {
      "name": "copy simple key column into value",
      "statements": [
        "CREATE STREAM INPUT (ID INT KEY, F0 INT) WITH (kafka_topic='input', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT ID, AS_VALUE(ID) AS ID_COPY FROM INPUT;"
      ],
      "inputs": [
        {"topic": "input", "key": 10, "value": {"F0": 4}}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 10, "value": {"ID_COPY": 10}}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "ID INT KEY, ID_COPY INT"}
        ]
      }
    },
    {
      "name": "table without primary key fails",
      "statements": [
        "CREATE TABLE INPUT (ID INT, F0 INT) WITH (kafka_topic='input', value_format='JSON');"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlStatementException",
        "message": "Tables require a PRIMARY KEY. Please define the PRIMARY KEY."
      }
    },
    {
      "name": "table without primary key fails - schema inference",
      "statements": [
        "CREATE TABLE INPUT WITH (kafka_topic='input', value_format='Avro');"
      ],
      "topics": [
        {
          "name": "input",
          "valueSchema": {"name": "blah", "type": "record", "fields": [{"name": "c1", "type": "int"}]},
          "valueFormat": "AVRO"
        }
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "Tables require a PRIMARY KEY. Please define the PRIMARY KEY."
      }
    },
    {
      "name": "stream without key column",
      "statements": [
        "CREATE STREAM INPUT (ID INT, F0 INT) WITH (kafka_topic='input', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT * FROM INPUT;"
      ],
      "inputs": [
        {"topic": "input", "key": null, "value": {"ID": 1, "F0": 2}},
        {"topic": "input", "key": "should be ignored", "value": {"ID": 2, "F0": 4}}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": null, "value": {"ID": 1, "F0": 2}},
        {"topic": "OUTPUT", "key": null, "value": {"ID": 2, "F0": 4}}
      ],
      "post": {
        "sources": [
          {"name": "INPUT", "type": "stream", "schema": "ID INT, F0 INT"},
          {"name": "OUTPUT", "type": "stream", "schema": "ID INT, F0 INT"}
        ]
      }
    },
    {
      "name": "import windowed stream with no key",
      "statements": [
        "CREATE STREAM INPUT (F0 INT) WITH (kafka_topic='input', value_format='JSON', window_type='SESSION');"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlStatementException",
        "message": "Windowed sources require a key column."
      }
    },
    {
      "name": "validate same schema schema id in csas OK - AVRO",
      "statements": [
        "CREATE STREAM INPUT (`id` INT KEY, `c1` INT) WITH (kafka_topic='input', value_format='avro', partitions=1);",
        "CREATE STREAM OUTPUT WITH(value_schema_id=2, PARTITIONS = 4) as SELECT * FROM input;"
      ],
      "topics": [
        {
          "name": "OUTPUT",
          "valueSchema": {"name": "blah", "type": "record", "fields": [{"name": "c1", "type": "int"}]},
          "valueFormat": "AVRO",
          "partitions": 4
        }
      ],
      "inputs": [{"topic": "input", "key": 42, "value": {"c1": 4}}],
      "outputs": [{"topic": "OUTPUT", "key": 42, "value": {"c1": 4}}],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "`id` INT KEY, `c1` INT"}
        ]
      }
    },
    {
      "name": "validate extra required field schema schema id in csas FAILS - AVRO",
      "statements": [
        "CREATE STREAM INPUT (`id` INT KEY, `c1` INT) WITH (kafka_topic='input', value_format='avro', partitions=1);",
        "CREATE STREAM OUTPUT WITH(value_schema_id=2, PARTITIONS = 4) as SELECT * FROM input;"
      ],
      "topics": [
        {
          "name": "OUTPUT",
          "valueSchema": {"name": "blah", "type": "record", "fields": [{"name": "c1", "type": "int"}, {"name":  "c2", "type":  "double"}]},
          "valueFormat": "AVRO",
          "partitions": 4
        }
      ],
      "inputs": [{"topic": "input", "key": 42, "value": {"c1": 4}}],
      "outputs": [{"topic": "OUTPUT", "key": 42, "value": {"c1": 4}}],
      "expectedException": {
        "type": "org.apache.kafka.streams.errors.StreamsException",
        "message": "Exception caught in process",
        "cause": "org.apache.kafka.streams.errors.StreamsException",
        "causeMessage": "Unable to serialize record"
      }
    },
    {
      "name": "validate incompatible type schema id in csas FAILS - AVRO",
      "statements": [
        "CREATE STREAM INPUT (`id` INT KEY, `c1` INT) WITH (kafka_topic='input', value_format='avro', partitions=1);",
        "CREATE STREAM OUTPUT WITH(value_schema_id=2, PARTITIONS = 4) as SELECT * FROM input;"
      ],
      "topics": [
        {
          "name": "OUTPUT",
          "valueSchema": {"name": "blah", "type": "record", "fields": [{"name": "c1", "type": "string"}, {"name":  "c2", "type":  "double"}]},
          "valueFormat": "AVRO",
          "partitions": 4
        }
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlStatementException",
        "message": "The following value columns are changed, missing or reordered: [`c1` INTEGER]. Schema from schema registry is [`c1` STRING, `c2` DOUBLE]"
      }
    },
    {
      "name": "validate reordered field schema id in csas FAILS - AVRO",
      "statements": [
        "CREATE STREAM INPUT (`id` INT KEY, `c1` INT) WITH (kafka_topic='input', value_format='avro', partitions=1);",
        "CREATE STREAM OUTPUT WITH(value_schema_id=2, PARTITIONS = 4) as SELECT * FROM input;"
      ],
      "topics": [
        {
          "name": "OUTPUT",
          "valueSchema": {"name": "blah", "type": "record", "fields": [{"name": "c2", "type": "double"}, {"name":  "c1", "type":  "int"}]},
          "valueFormat": "AVRO",
          "partitions": 4
        }
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlStatementException",
        "message": "The following value columns are changed, missing or reordered: [`c1` INTEGER]. Schema from schema registry is [`c2` DOUBLE, `c1` INTEGER]"
      }
    },
    {
      "name": "validate extra optional field schema schema id in csas OK - AVRO",
      "statements": [
        "CREATE STREAM INPUT (`id` INT KEY, `c1` INT) WITH (kafka_topic='input', value_format='avro', partitions=1);",
        "CREATE STREAM OUTPUT WITH(value_schema_id=2, PARTITIONS = 4) as SELECT * FROM input;"
      ],
      "topics": [
        {
          "name": "OUTPUT",
          "valueSchema": {"name": "blah", "type": "record", "fields": [{"name": "c1", "type": "int"}, {"name":  "c2", "type":  ["null","int"], "default": null}]},
          "valueFormat": "AVRO",
          "partitions": 4
        }
      ],
      "inputs": [{"topic": "input", "key": 42, "value": {"c1": 4}}],
      "outputs": [{"topic": "OUTPUT", "key": 42, "value": {"c1": 4, "c2": null}}],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "`id` INT KEY, `c1` INT"}
        ]
      }
    },
    {
      "name": "validate extra field with default value schema schema id in csas OK - AVRO",
      "statements": [
        "CREATE STREAM INPUT (`id` INT KEY, `c1` INT) WITH (kafka_topic='input', value_format='avro', partitions=1);",
        "CREATE STREAM OUTPUT WITH(value_schema_id=2, PARTITIONS = 4) as SELECT * FROM input;"
      ],
      "topics": [
        {
          "name": "OUTPUT",
          "valueFormat": "AVRO",
          "valueSchema": {"name": "blah", "type": "record", "fields": [{"name": "c1", "type": "int"}, {"name":  "c2", "type": "int", "default": 100}]},
          "partitions": 4
        }
      ],
      "inputs": [{"topic": "input", "key": 42, "value": {"c1": 4}}],
      "outputs": [{"topic": "OUTPUT", "key": 42, "value": {"c1": 4, "c2": 100}}],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "`id` INT KEY, `c1` INT"}
        ]
      }
    },
    {
      "name": "validate extra optional field with schema schema id in csas OK - PROTOBUF",
      "statements": [
        "CREATE STREAM INPUT (`id` INT KEY, `c1` INT) WITH (kafka_topic='input', value_format='avro', partitions=1);",
        "CREATE STREAM OUTPUT WITH(key_schema_id=2, key_format='protobuf', value_format='protobuf', value_schema_id=3, PARTITIONS = 4) as SELECT * FROM input;"
      ],
      "topics": [
        {
          "name": "OUTPUT",
          "valueSchema": "syntax = \"proto3\"; message ConnectDefault1 { int32 c1 = 1; string c2 = 2; }",
          "valueFormat": "PROTOBUF",
          "keySchema": "syntax = \"proto3\"; message ConnectDefault1 { int32 id = 1; }",
          "keyFormat": "PROTOBUF",
          "partitions": 4
        }
      ],
      "inputs": [{"topic": "input", "key": 42, "value": {"c1": 4}}],
      "outputs": [{"topic": "OUTPUT", "key": {"id": 42}, "value": {"c1": 4, "c2": ""}}],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "`id` INT KEY, `c1` INT"}
        ]
      }
    },
        {
      "name": "validate extra optional field with schema schema id in csas OK - JSON_SR",
      "statements": [
        "CREATE STREAM INPUT (`ROWKEY` struct<`id` BIGINT> KEY, `c1` BIGINT) WITH (key_format='avro', kafka_topic='input', value_format='avro', partitions=1);",
        "CREATE STREAM OUTPUT WITH(key_schema_id=3, key_format='json_sr', value_format='json_sr', value_schema_id=4, PARTITIONS = 4) as SELECT * FROM input;"
      ],
      "topics": [
        {
          "name": "OUTPUT",
          "valueSchema": {"type": "object","properties": {"c1": {"type": "integer"}, "c2":  {"type": "string"}}},
          "valueFormat": "JSON",
          "keySchema": {"type": "object","properties": {"id": {"type": "integer"}}},
          "keyFormat": "JSON",
          "partitions": 4
        }
      ],
      "inputs": [{"topic": "input", "key": {"id": 42}, "value": {"c1": 4}}],
      "outputs": [{"topic": "OUTPUT", "key": {"id": 42}, "value": {"c1": 4, "c2":  null}}],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "`ROWKEY` struct<`id` BIGINT> KEY, `c1` BIGINT"}
        ]
      }
    }
  ]
}
