{
  "comments": [
    "Tests covering use of the INSERT INTO clause"
  ],
  "tests": [
    {
      "name": "simple",
      "statements": [
        "CREATE STREAM SOURCE1 (K STRING KEY, data VARCHAR) WITH (kafka_topic='stream-source', value_format='DELIMITED');",
        "CREATE STREAM SOURCE2 (K STRING KEY, data VARCHAR) WITH (kafka_topic='insert-source', value_format='DELIMITED');",
        "CREATE STREAM OUTPUT AS SELECT * FROM SOURCE1;",
        "INSERT INTO OUTPUT SELECT * FROM SOURCE2;"
      ],
      "inputs": [
        {"topic": "insert-source", "key": "k1", "value": "v1"}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": "k1", "value": "v1"}
      ]
    },
    {
      "name": "streams with no key columns",
      "statements": [
        "CREATE STREAM SOURCE1 (K STRING, data VARCHAR) WITH (kafka_topic='stream-source', value_format='JSON');",
        "CREATE STREAM SOURCE2 (K STRING, data VARCHAR) WITH (kafka_topic='insert-source', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT * FROM SOURCE1;",
        "INSERT INTO OUTPUT SELECT * FROM SOURCE2;"
      ],
      "inputs": [
        {"topic": "stream-source", "value": {"K": "k1", "data": "v1"}},
        {"topic": "insert-source", "value": {"K": "k2", "data": "v2"}}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": null, "value": {"K": "k1", "DATA": "v1"}},
        {"topic": "OUTPUT", "key": null, "value": {"K": "k2", "DATA": "v2"}}
      ]
    },
    {
      "name": "with custom topic name",
      "statements": [
        "CREATE STREAM SOURCE1 (K STRING KEY, data VARCHAR) WITH (kafka_topic='stream-source', value_format='DELIMITED');",
        "CREATE STREAM SOURCE2 (K STRING KEY, data VARCHAR) WITH (kafka_topic='insert-source', value_format='DELIMITED');",
        "CREATE STREAM OUTPUT WITH(kafka_topic='custom') AS SELECT * FROM SOURCE1;",
        "INSERT INTO OUTPUT SELECT * FROM SOURCE2;"
      ],
      "inputs": [
        {"topic": "insert-source", "key": "k1", "value": "v1"}
      ],
      "outputs": [
        {"topic": "custom", "key": "k1", "value": "v1"}
      ]
    },
    {
      "name": "topic with different schema",
      "statements": [
        "CREATE STREAM SOURCE1 (K STRING KEY, data VARCHAR) WITH (kafka_topic='stream-source', value_format='JSON');",
        "CREATE STREAM SOURCE2 (K STRING KEY, data BIGINT) WITH (kafka_topic='insert-source', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT * FROM SOURCE1;",
        "INSERT INTO OUTPUT SELECT * FROM SOURCE2;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlStatementException",
        "message": "Incompatible schema between results and sink"
      }
    },
    {
      "name": "table",
      "statements": [
        "CREATE STREAM SOURCE (K STRING KEY, d1 VARCHAR) WITH (kafka_topic='SOURCE', value_format='DELIMITED');",
        "CREATE TABLE OUTPUT (d1 STRING PRIMARY KEY, COUNT BIGINT) WITH (kafka_topic='OUTPUT', value_format='DELIMITED');",
        "INSERT INTO OUTPUT SELECT d1, COUNT() AS COUNT FROM SOURCE GROUP BY d1;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlStatementException",
        "message": "INSERT INTO can only be used to insert into a stream. OUTPUT is a table."
      }
    },
    {
      "name": "unknown",
      "statements": [
        "CREATE STREAM SOURCE (K STRING KEY, d1 VARCHAR) WITH (kafka_topic='SOURCE', value_format='DELIMITED');",
        "INSERT INTO UNKNOWN SELECT d1, COUNT() FROM SOURCE GROUP BY d1;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "Line: 2, Col: 13: Source `UNKNOWN` does not exist."
      }
    },
    {
      "name": "convert formats: DELIMITED to JSON",
      "statements": [
        "CREATE STREAM SOURCE1 (K STRING KEY, data VARCHAR) WITH (kafka_topic='stream-source', value_format='DELIMITED');",
        "CREATE STREAM SOURCE2 (K STRING KEY, data VARCHAR) WITH (kafka_topic='insert-source', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT * FROM SOURCE1;",
        "INSERT INTO OUTPUT SELECT * FROM SOURCE2;"
      ],
      "inputs": [
        {"topic": "insert-source", "key": "k1", "value": {"data": "v1"}}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": "k1", "value": "v1"}
      ]
    },
    {
      "name": "convert formats: JSON to AVRO",
      "statements": [
        "CREATE STREAM SOURCE (K STRING KEY, A bigint, B varchar) WITH (kafka_topic='source', value_format='JSON');",
        "CREATE STREAM SINK (K STRING KEY, A bigint, B varchar) WITH (kafka_topic='sink', value_format='AVRO');",
        "INSERT INTO SINK SELECT * FROM SOURCE;"
      ],
      "inputs": [
        {"topic": "source", "key": "0", "value": {"A": 123, "B": "falcon"}, "timestamp": 0},
        {"topic": "source", "key": "0", "value": {"A": 456, "B": "giraffe"}, "timestamp": 0},
        {"topic": "source", "key": "0", "value": {"A": 789, "B": "turtle"}, "timestamp": 0}
      ],
      "outputs": [
        {"topic": "sink", "key": "0", "value": {"A": 123, "B": "falcon"}, "timestamp": 0},
        {"topic": "sink", "key": "0", "value": {"A": 456, "B": "giraffe"}, "timestamp": 0},
        {"topic": "sink", "key": "0", "value": {"A": 789, "B": "turtle"}, "timestamp": 0}
      ]
    },
    {
      "name": "convert formats: AVRO to JSON",
      "statements": [
        "CREATE STREAM SOURCE (K STRING KEY, A bigint, B varchar) WITH (kafka_topic='source', value_format='AVRO');",
        "CREATE STREAM SINK (K STRING KEY, A bigint, B varchar) WITH (kafka_topic='sink', value_format='JSON');",
        "INSERT INTO SINK SELECT * FROM SOURCE;"
      ],
      "inputs": [
        {"topic": "source", "key": "0", "value": {"A": 123, "B": "falcon"}, "timestamp": 0},
        {"topic": "source", "key": "0", "value": {"A": 456, "B": "giraffe"}, "timestamp": 0},
        {"topic": "source", "key": "0", "value": {"A": 789, "B": "turtle"}, "timestamp": 0}
      ],
      "outputs": [
        {"topic": "sink", "key": "0", "value": {"A": 123, "B": "falcon"}, "timestamp": 0},
        {"topic": "sink", "key": "0", "value": {"A": 456, "B": "giraffe"}, "timestamp": 0},
        {"topic": "sink", "key": "0", "value": {"A": 789, "B": "turtle"}, "timestamp": 0}
      ]
    },
    {
      "name": "join",
      "statements": [
        "CREATE STREAM SOURCE1 (K STRING KEY, data VARCHAR) WITH (kafka_topic='stream-source', value_format='DELIMITED');",
        "CREATE STREAM SOURCE2 (K STRING KEY, data VARCHAR) WITH (kafka_topic='insert-source', value_format='DELIMITED');",
        "CREATE STREAM OUTPUT AS SELECT K, DATA AS DATA_1, DATA AS DATA_2 FROM SOURCE1;",
        "INSERT INTO OUTPUT SELECT S1.K AS K, S1.DATA AS DATA_1, S2.DATA AS DATA_2 FROM SOURCE1 S1 JOIN SOURCE2 S2 WITHIN 1 SECOND ON S1.K = S2.K;"
      ],
      "inputs": [
        {"topic": "stream-source", "key": "k1", "value": "v1"},
        {"topic": "insert-source", "key": "k1", "value": "v2"}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": "k1", "value": "v1,v1"},
        {"topic": "OUTPUT", "key": "k1", "value": "v1,v2"}
      ]
    },
    {
      "name": "join with repartition",
      "statements": [
        "CREATE STREAM SOURCE1 (ID STRING KEY, k VARCHAR) WITH (kafka_topic='s1', value_format='JSON');",
        "CREATE STREAM SOURCE2 (ID STRING KEY, k VARCHAR) WITH (kafka_topic='s2', value_format='JSON');",
        "CREATE STREAM OUTPUT (k VARCHAR KEY, data VARCHAR, i INT) WITH (kafka_topic='OUTPUT', value_format='JSON', PARTITIONS=1);",
        "INSERT INTO OUTPUT SELECT S1.K AS K, S1.ID + S2.ID as DATA, 1 as I FROM SOURCE1 S1 JOIN SOURCE2 S2 WITHIN 1 SECOND ON S1.k = S2.k;"
      ],
      "inputs": [
        {"topic": "s1", "key": "s1-key", "value": {"K": "v1"}, "timestamp": 0},
        {"topic": "s2", "key": "s2-key", "value": {"K": "v1"}, "timestamp": 0}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": "v1", "value": {"DATA": "s1-keys2-key", "I": 1}}
      ]
    },
    {
      "name": "implicitly casts",
      "statements": [
        "CREATE STREAM SOURCE (ignored VARCHAR) WITH (kafka_topic='source', value_format='AVRO');",
        "CREATE STREAM TARGET (c1 DECIMAL(5,2), c2 DECIMAL(5,2)) WITH (kafka_topic='target', value_format='AVRO');",
        "INSERT INTO TARGET SELECT 1 as c1, 2.0 as c2 FROM SOURCE;"
      ],
      "inputs": [
        {"topic": "source", "value": {"ignored": "v1"}}
      ],
      "outputs": [
        {"topic": "target", "value": {"C1": 1.00, "C2": 2.00}}
      ]
    },
    {
      "name": "join mismatch (fewer columns than expected)",
      "statements": [
        "CREATE STREAM SOURCE1 (K STRING KEY, data VARCHAR) WITH (kafka_topic='stream-source', value_format='DELIMITED');",
        "CREATE STREAM SOURCE2 (K STRING KEY, data VARCHAR) WITH (kafka_topic='insert-source', value_format='DELIMITED');",
        "CREATE STREAM OUTPUT AS SELECT K, DATA AS DATA_1, DATA AS DATA_2 FROM SOURCE1;",
        "INSERT INTO OUTPUT SELECT S1.K AS K, S1.DATA AS DATA_1 FROM SOURCE1 S1 JOIN SOURCE2 S2 WITHIN 1 SECOND ON S1.K = S2.K;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlStatementException",
        "message": "Result schema is `K` STRING KEY, `DATA_1` STRING\nSink schema is `K` STRING KEY, `DATA_1` STRING, `DATA_2` STRING"
      }
    },
    {
      "name": "join mismatch (more columns than expected)",
      "statements": [
        "CREATE STREAM SOURCE1 (K STRING KEY, data VARCHAR) WITH (kafka_topic='stream-source', value_format='DELIMITED');",
        "CREATE STREAM SOURCE2 (K STRING KEY, data VARCHAR) WITH (kafka_topic='insert-source', value_format='DELIMITED');",
        "CREATE STREAM OUTPUT AS SELECT K, DATA AS DATA_1, DATA AS DATA_2 FROM SOURCE1;",
        "INSERT INTO OUTPUT SELECT S1.K AS K, S1.DATA AS DATA_1, S2.DATA AS DATA_2, S2.DATA AS DATA_3 FROM SOURCE1 S1 JOIN SOURCE2 S2 WITHIN 1 SECOND ON S1.K = S2.K;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlStatementException",
        "message": "Result schema is `K` STRING KEY, `DATA_1` STRING, `DATA_2` STRING, `DATA_3` STRING\nSink schema is `K` STRING KEY, `DATA_1` STRING, `DATA_2` STRING"
      }
    },
    {
      "name": "fails when not inserting value to a VARCHAR NOT NULL column",
      "statements": [
        "CREATE STREAM SOURCE1 (K STRING KEY, data VARCHAR NOT NULL) WITH (kafka_topic='insert-source', value_format='JSON');",
        "INSERT INTO SOURCE1 (K) VALUES ('bar');"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "Invalid value: null used for required field: \"DATA\", schema type: STRING"
      }
    },
    {
      "name": "fails when not inserting value to a STRING NOT NULL column",
      "statements": [
        "CREATE STREAM SOURCE1 (K STRING KEY, data STRING NOT NULL) WITH (kafka_topic='insert-source', value_format='JSON');",
        "INSERT INTO SOURCE1 (K) VALUES ('bar');"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "Invalid value: null used for required field: \"DATA\", schema type: STRING"
      }
    },
    {
      "name": "fails when not inserting value to a INT32 NOT NULL column",
      "statements": [
        "CREATE STREAM SOURCE1 (K STRING KEY, data INT NOT NULL) WITH (kafka_topic='insert-source', value_format='JSON');",
        "INSERT INTO SOURCE1 (K) VALUES ('bar');"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "Invalid value: null used for required field: \"DATA\", schema type: INT32"
      }
    },
    {
      "name": "fails when not inserting value to a BOOLEAN NOT NULL column",
      "statements": [
        "CREATE STREAM SOURCE1 (K STRING KEY, data BOOLEAN NOT NULL) WITH (kafka_topic='insert-source', value_format='JSON');",
        "INSERT INTO SOURCE1 (K) VALUES ('bar');"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "Invalid value: null used for required field: \"DATA\", schema type: BOOLEAN"
      }
    },
    {
      "name": "fails when not inserting value to a BIGINT NOT NULL column",
      "statements": [
        "CREATE STREAM SOURCE1 (K STRING KEY, data BIGINT NOT NULL) WITH (kafka_topic='insert-source', value_format='JSON');",
        "INSERT INTO SOURCE1 (K) VALUES ('bar');"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "Invalid value: null used for required field: \"DATA\", schema type: INT64"
      }
    },
    {
      "name": "fails when not inserting value to a DOUBLE NOT NULL column",
      "statements": [
        "CREATE STREAM SOURCE1 (K STRING KEY, data DOUBLE NOT NULL) WITH (kafka_topic='insert-source', value_format='JSON');",
        "INSERT INTO SOURCE1 (K) VALUES ('bar');"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "Invalid value: null used for required field: \"DATA\", schema type: FLOAT64"
      }
    },
    {
      "name": "fails when not inserting value to a DECIMAL NOT NULL column",
      "statements": [
        "CREATE STREAM SOURCE1 (K STRING KEY, data DECIMAL(20,10) NOT NULL) WITH (kafka_topic='insert-source', value_format='JSON');",
        "INSERT INTO SOURCE1 (K) VALUES ('bar') ;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "Invalid value: null used for required field: \"DATA\", schema type: BYTES"
      }
    },
    {
      "name": "fails when not inserting value to a ARRAY<STRING> NOT NULL column",
      "statements": [
        "CREATE STREAM SOURCE1 (K STRING KEY, data ARRAY<STRING> NOT NULL) WITH (kafka_topic='insert-source', value_format='JSON');",
        "INSERT INTO SOURCE1 (K) VALUES ('bar') ;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "Invalid value: null used for required field: \"DATA\", schema type: ARRAY"
      }
    },
    {
      "name": "fails when not inserting value to a MAP<STRING, INT> NOT NULL column",
      "statements": [
        "CREATE STREAM SOURCE1 (K STRING KEY, data MAP<STRING, INT> NOT NULL) WITH (kafka_topic='insert-source', value_format='JSON');",
        "INSERT INTO SOURCE1 (K) VALUES ('bar') ;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "Invalid value: null used for required field: \"DATA\", schema type: MAP"
      }
    },
    {
      "name": "fails when not inserting value to a MAP<STRING, INT NOT NULL> NOT NULL column",
      "statements": [
        "CREATE STREAM SOURCE1 (K STRING KEY, data MAP<STRING, INT NOT NULL> NOT NULL) WITH (kafka_topic='insert-source', value_format='JSON');",
        "INSERT INTO SOURCE1 (K, data) VALUES ('bar', MAP('key':=null)) ;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "Failed to insert values into 'SOURCE1'. Invalid insert value: Cannot construct a map with all NULL values (see https://github.com/confluentinc/ksql/issues/4239). As a workaround, you may cast a NULL value to the desired type.. expression:MAP('key':=null), schema:"
      }
    },
    {
      "name": "fails when inserting null to a STRUCT<a VARCHAR, b INT> NOT NULL column",
      "statements": [
        "CREATE STREAM SOURCE1 (K STRING KEY, data STRUCT<a VARCHAR, b INT> NOT NULL) WITH (kafka_topic='insert-source', value_format='JSON');",
        "INSERT INTO SOURCE1 (K) VALUES ('bar') ;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "Invalid value: null used for required field: \"DATA\", schema type: STRUCT"
      }
    },
    {
      "name": "fails when inserting null to a STRUCT<a VARCHAR, b INT NOT NULL> NOT NULL column",
      "statements": [
        "CREATE STREAM SOURCE1 (data STRUCT<a VARCHAR, b INTEGER NOT NULL, c DOUBLE NOT NULL> NOT NULL) WITH (kafka_topic='insert-source', value_format='JSON');",
        "INSERT INTO SOURCE1 (data) VALUES (STRUCT(a:='a')) ;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlStatementException",
        "message": "Failed to insert values into 'SOURCE1'. Could not serialize value: [ Struct{A=a} ]. Failed to prepare Struct value field 'DATA' for serialization. This could happen if the value was produced by a user-defined function where the schema has non-optional return types."
      }
    },
    {
      "name": "fails when inserting null to a MAP<STRING, STRUCT<a VARCHAR, b INT NOT NULL>> column",
      "statements": [
        "CREATE STREAM SOURCE1 (data MAP<STRING, STRUCT<a VARCHAR, b INT NOT NULL>>) WITH (kafka_topic='insert-source', value_format='JSON');",
        "INSERT INTO SOURCE1 (data) VALUES (MAP('key':=STRUCT(a:='a'))) ;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "Invalid value: null used for required field: \"B\", schema type: INT32"
      }
    },
    {
      "name": "fails when inserting null to a ARRAY<STRUCT<a VARCHAR, b INT NOT NULL>> column",
      "statements": [
        "CREATE STREAM SOURCE1 (data ARRAY<STRUCT<a VARCHAR, b INT NOT NULL>>) WITH (kafka_topic='insert-source', value_format='JSON');",
        "INSERT INTO SOURCE1 (data) VALUES (ARRAY[STRUCT(a:='a')]) ;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "Invalid value: null used for required field: \"B\", schema type: INT32"
      }
    },
    {
      "name": "fails when inserting null to a ARRAY<STRUCT<a VARCHAR NOT NULL, b INT NULL, c DOUBLE NOT NULL>> column",
      "statements": [
        "CREATE STREAM SOURCE1 (data ARRAY<STRUCT<a VARCHAR, b INT NULL, c DOUBLE NOT NULL>>) WITH (kafka_topic='insert-source', value_format='JSON');",
        "INSERT INTO SOURCE1 (data) VALUES (ARRAY[STRUCT(b:=1)]) ;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "Invalid value: null used for required field: \"C\", schema type: FLOAT64"
      }
    },
    {
      "name": "insert null into NOT NULL field fails the insert",
      "statements": [
        "CREATE STREAM SOURCE1 (v1 VARCHAR NOT NULL, v2 STRING NOT NULL) WITH (kafka_topic='insert-source', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT * FROM SOURCE1;",
        "INSERT INTO OUTPUT (v2) VALUES ('string');"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "Invalid value: null used for required field: \"V1\", schema type: STRING"
      }
    },
    {
      "name": "insert primitives VARCHAR NULL",
      "statements": [
        "CREATE STREAM SOURCE1 (v1 VARCHAR NULL) WITH (kafka_topic='insert-source', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT * FROM SOURCE1;",
        "INSERT INTO OUTPUT (v1) VALUES ('varchar1');"
      ],
      "inputs": [
        {"topic": "insert-source",  "value": {"v1" : "varchar2" }}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": null, "value": {"V1": "varchar1" }},
        {"topic": "OUTPUT", "key": null, "value": {"V1": "varchar2" }}
      ]
    },
    {
      "name": "insert values to STRING NULL",
      "statements": [
        "CREATE STREAM SOURCE1 (v1 STRING NULL) WITH (kafka_topic='insert-source', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT * FROM SOURCE1;",
        "INSERT INTO OUTPUT (v1) VALUES ('string1');"
      ],
      "inputs": [
        {"topic": "insert-source", "value": {"v1": "string2"}}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": null, "value": {"V1": "string1" }},
        {"topic": "OUTPUT", "key": null, "value": {"V1": "string2" }}
      ]
    },
    {
      "name": "insert values to INT NULL",
      "statements": [
        "CREATE STREAM SOURCE1 (v1 INT NULL) WITH (kafka_topic='insert-source', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT * FROM SOURCE1;",
        "INSERT INTO OUTPUT (v1) VALUES (1);"
      ],
      "inputs": [
        {"topic": "insert-source", "value": {"v1": 2}}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": null, "value": {"V1": 1 }},
        {"topic": "OUTPUT", "key": null, "value": {"V1": 2 }}
      ]
    },
    {
      "name": "insert values to INTEGER NULL",
      "statements": [
        "CREATE STREAM SOURCE1 (v1 INTEGER NULL) WITH (kafka_topic='insert-source', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT * FROM SOURCE1;",
        "INSERT INTO OUTPUT (v1) VALUES (1);"
      ],
      "inputs": [
        {"topic": "insert-source", "value": {"v1": 2}}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": null, "value": {"V1": 1 }},
        {"topic": "OUTPUT", "key": null, "value": {"V1": 2 }}
      ]
    },
    {
      "name": "insert values to DOUBLE NULL",
      "statements": [
        "CREATE STREAM SOURCE1 (v1 DOUBLE NULL) WITH (kafka_topic='insert-source', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT * FROM SOURCE1;",
        "INSERT INTO OUTPUT (v1) VALUES (1.0);"
      ],
      "inputs": [
        {"topic": "insert-source", "value": {"v1": 2.0}}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": null, "value": {"V1": 1.0 }},
        {"topic": "OUTPUT", "key": null, "value": {"V1": 2.0 }}
      ]
    },
    {
      "name": "insert values to BIGINT NULL",
      "statements": [
        "CREATE STREAM SOURCE1 (v1 BIGINT NULL) WITH (kafka_topic='insert-source', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT * FROM SOURCE1;",
        "INSERT INTO OUTPUT (v1) VALUES (1);"
      ],
      "inputs": [
        {"topic": "insert-source", "value": {"v1": 2}}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": null, "value": {"V1": 1 }},
        {"topic": "OUTPUT", "key": null, "value": {"V1": 2 }}
      ]
    },
    {
      "name": "insert values to BOOLEAN NULL",
      "statements": [
        "CREATE STREAM SOURCE1 (v1 BOOLEAN NULL) WITH (kafka_topic='insert-source', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT * FROM SOURCE1;",
        "INSERT INTO OUTPUT (v1) VALUES (true);"
      ],
      "inputs": [
        {"topic": "insert-source", "value": {"v1": false}}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": null, "value": {"V1": true }},
        {"topic": "OUTPUT", "key": null, "value": {"V1": false }}
      ]
    },
    {
      "name": "insert values to DECIMAL NULL",
      "statements": [
        "CREATE STREAM SOURCE1 (v1 DECIMAL(6,4) NULL) WITH (kafka_topic='insert-source', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT * FROM SOURCE1;",
        "INSERT INTO OUTPUT (v1) VALUES (1);"
      ],
      "inputs": [
        {"topic": "insert-source", "value": {"v1": 2}}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": null, "value": {"V1": 1.0000 }},
        {"topic": "OUTPUT", "key": null, "value": {"V1": 2.0000 }}
      ]
    },
    {
      "name": "insert values to MAP NULL",
      "statements": [
        "CREATE STREAM SOURCE1 (v1 MAP<STRING, INTEGER NULL> NULL) WITH (kafka_topic='insert-source', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT * FROM SOURCE1;",
        "INSERT INTO OUTPUT (v1) VALUES (MAP('k':=1));"
      ],
      "inputs": [
        {"topic": "insert-source", "value": {"v1": {"k": 2}}}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": null, "value": {"V1": {"k": 1} }},
        {"topic": "OUTPUT", "key": null, "value": {"V1": {"k": 2} }}
      ]
    },
    {
      "name": "insert values to ARRAY NULL",
      "statements": [
        "CREATE STREAM SOURCE1 (v1 ARRAY<INTEGER> NULL) WITH (kafka_topic='insert-source', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT * FROM SOURCE1;",
        "INSERT INTO OUTPUT (v1) VALUES (ARRAY[1]);"
      ],
      "inputs": [
        {"topic": "insert-source", "value": {"v1": [2]}}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": null, "value": {"V1": [1] }},
        {"topic": "OUTPUT", "key": null, "value": {"V1": [2] }}
      ]
    }
  ]
}