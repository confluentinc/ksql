{
  "comments": [
    "Tests covering use of the INSERT INTO clause"
  ],
  "tests": [
    {
      "name": "simple",
      "statements": [
        "CREATE STREAM SOURCE1 (K STRING KEY, data VARCHAR) WITH (kafka_topic='stream-source', value_format='DELIMITED');",
        "CREATE STREAM SOURCE2 (K STRING KEY, data VARCHAR) WITH (kafka_topic='insert-source', value_format='DELIMITED');",
        "CREATE STREAM OUTPUT AS SELECT * FROM SOURCE1;",
        "INSERT INTO OUTPUT SELECT * FROM SOURCE2;"
      ],
      "inputs": [
        {"topic": "insert-source", "key": "k1", "value": "v1"}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": "k1", "value": "v1"}
      ]
    },
    {
      "name": "streams with no key columns",
      "statements": [
        "CREATE STREAM SOURCE1 (K STRING, data VARCHAR) WITH (kafka_topic='stream-source', value_format='JSON');",
        "CREATE STREAM SOURCE2 (K STRING, data VARCHAR) WITH (kafka_topic='insert-source', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT * FROM SOURCE1;",
        "INSERT INTO OUTPUT SELECT * FROM SOURCE2;"
      ],
      "inputs": [
        {"topic": "stream-source", "value": {"K": "k1", "data": "v1"}},
        {"topic": "insert-source", "value": {"K": "k2", "data": "v2"}}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": null, "value": {"K": "k1", "DATA": "v1"}},
        {"topic": "OUTPUT", "key": null, "value": {"K": "k2", "DATA": "v2"}}
      ]
    },
    {
      "name": "with custom topic name",
      "statements": [
        "CREATE STREAM SOURCE1 (K STRING KEY, data VARCHAR) WITH (kafka_topic='stream-source', value_format='DELIMITED');",
        "CREATE STREAM SOURCE2 (K STRING KEY, data VARCHAR) WITH (kafka_topic='insert-source', value_format='DELIMITED');",
        "CREATE STREAM OUTPUT WITH(kafka_topic='custom') AS SELECT * FROM SOURCE1;",
        "INSERT INTO OUTPUT SELECT * FROM SOURCE2;"
      ],
      "inputs": [
        {"topic": "insert-source", "key": "k1", "value": "v1"}
      ],
      "outputs": [
        {"topic": "custom", "key": "k1", "value": "v1"}
      ]
    },
    {
      "name": "topic with different schema",
      "statements": [
        "CREATE STREAM SOURCE1 (K STRING KEY, data VARCHAR) WITH (kafka_topic='stream-source', value_format='JSON');",
        "CREATE STREAM SOURCE2 (K STRING KEY, data BIGINT) WITH (kafka_topic='insert-source', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT * FROM SOURCE1;",
        "INSERT INTO OUTPUT SELECT * FROM SOURCE2;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlStatementException",
        "message": "Incompatible schema between results and sink"
      }
    },
    {
      "name": "table",
      "statements": [
        "CREATE STREAM SOURCE (K STRING KEY, d1 VARCHAR) WITH (kafka_topic='SOURCE', value_format='DELIMITED');",
        "CREATE TABLE OUTPUT (d1 STRING PRIMARY KEY, COUNT BIGINT) WITH (kafka_topic='OUTPUT', value_format='DELIMITED');",
        "INSERT INTO OUTPUT SELECT d1, COUNT() AS COUNT FROM SOURCE GROUP BY d1;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlStatementException",
        "message": "INSERT INTO can only be used to insert into a stream. OUTPUT is a table."
      }
    },
    {
      "name": "unknown",
      "statements": [
        "CREATE STREAM SOURCE (K STRING KEY, d1 VARCHAR) WITH (kafka_topic='SOURCE', value_format='DELIMITED');",
        "INSERT INTO UNKNOWN SELECT d1, COUNT() FROM SOURCE GROUP BY d1;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "Line: 2, Col: 13: Source `UNKNOWN` does not exist."
      }
    },
    {
      "name": "convert formats: DELIMITED to JSON",
      "statements": [
        "CREATE STREAM SOURCE1 (K STRING KEY, data VARCHAR) WITH (kafka_topic='stream-source', value_format='DELIMITED');",
        "CREATE STREAM SOURCE2 (K STRING KEY, data VARCHAR) WITH (kafka_topic='insert-source', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT * FROM SOURCE1;",
        "INSERT INTO OUTPUT SELECT * FROM SOURCE2;"
      ],
      "inputs": [
        {"topic": "insert-source", "key": "k1", "value": {"data": "v1"}}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": "k1", "value": "v1"}
      ]
    },
    {
      "name": "convert formats: JSON to AVRO",
      "statements": [
        "CREATE STREAM SOURCE (K STRING KEY, A bigint, B varchar) WITH (kafka_topic='source', value_format='JSON');",
        "CREATE STREAM SINK (K STRING KEY, A bigint, B varchar) WITH (kafka_topic='sink', value_format='AVRO');",
        "INSERT INTO SINK SELECT * FROM SOURCE;"
      ],
      "inputs": [
        {"topic": "source", "key": "0", "value": {"A": 123, "B": "falcon"}, "timestamp": 0},
        {"topic": "source", "key": "0", "value": {"A": 456, "B": "giraffe"}, "timestamp": 0},
        {"topic": "source", "key": "0", "value": {"A": 789, "B": "turtle"}, "timestamp": 0}
      ],
      "outputs": [
        {"topic": "sink", "key": "0", "value": {"A": 123, "B": "falcon"}, "timestamp": 0},
        {"topic": "sink", "key": "0", "value": {"A": 456, "B": "giraffe"}, "timestamp": 0},
        {"topic": "sink", "key": "0", "value": {"A": 789, "B": "turtle"}, "timestamp": 0}
      ]
    },
    {
      "name": "convert formats: AVRO to JSON",
      "statements": [
        "CREATE STREAM SOURCE (K STRING KEY, A bigint, B varchar) WITH (kafka_topic='source', value_format='AVRO');",
        "CREATE STREAM SINK (K STRING KEY, A bigint, B varchar) WITH (kafka_topic='sink', value_format='JSON');",
        "INSERT INTO SINK SELECT * FROM SOURCE;"
      ],
      "inputs": [
        {"topic": "source", "key": "0", "value": {"A": 123, "B": "falcon"}, "timestamp": 0},
        {"topic": "source", "key": "0", "value": {"A": 456, "B": "giraffe"}, "timestamp": 0},
        {"topic": "source", "key": "0", "value": {"A": 789, "B": "turtle"}, "timestamp": 0}
      ],
      "outputs": [
        {"topic": "sink", "key": "0", "value": {"A": 123, "B": "falcon"}, "timestamp": 0},
        {"topic": "sink", "key": "0", "value": {"A": 456, "B": "giraffe"}, "timestamp": 0},
        {"topic": "sink", "key": "0", "value": {"A": 789, "B": "turtle"}, "timestamp": 0}
      ]
    },
    {
      "name": "convert formats: JSON to PROTOBUF",
      "statements": [
        "CREATE STREAM SOURCE (K STRING KEY, A bigint, B varchar) WITH (kafka_topic='source', value_format='JSON');",
        "CREATE STREAM SINK (K STRING KEY, A bigint, B varchar) WITH (kafka_topic='sink', value_format='PROTOBUF');",
        "INSERT INTO SINK SELECT * FROM SOURCE;"
      ],
      "inputs": [
        {"topic": "source", "key": "0", "value": {"A": 123, "B": "falcon"}, "timestamp": 0},
        {"topic": "source", "key": "0", "value": {"A": 456, "B": "giraffe"}, "timestamp": 0},
        {"topic": "source", "key": "0", "value": {"A": 789, "B": "turtle"}, "timestamp": 0}
      ],
      "outputs": [
        {"topic": "sink", "key": "0", "value": {"A": 123, "B": "falcon"}, "timestamp": 0},
        {"topic": "sink", "key": "0", "value": {"A": 456, "B": "giraffe"}, "timestamp": 0},
        {"topic": "sink", "key": "0", "value": {"A": 789, "B": "turtle"}, "timestamp": 0}
      ]
    },
    {
      "name": "convert formats: PROTOBUF to JSON",
      "statements": [
        "CREATE STREAM SOURCE (K STRING KEY, A bigint, B varchar) WITH (kafka_topic='source', value_format='PROTOBUF');",
        "CREATE STREAM SINK (K STRING KEY, A bigint, B varchar) WITH (kafka_topic='sink', value_format='JSON');",
        "INSERT INTO SINK SELECT * FROM SOURCE;"
      ],
      "inputs": [
        {"topic": "source", "key": "0", "value": {"A": 123, "B": "falcon"}, "timestamp": 0},
        {"topic": "source", "key": "0", "value": {"A": 456, "B": "giraffe"}, "timestamp": 0},
        {"topic": "source", "key": "0", "value": {"A": 789, "B": "turtle"}, "timestamp": 0}
      ],
      "outputs": [
        {"topic": "sink", "key": "0", "value": {"A": 123, "B": "falcon"}, "timestamp": 0},
        {"topic": "sink", "key": "0", "value": {"A": 456, "B": "giraffe"}, "timestamp": 0},
        {"topic": "sink", "key": "0", "value": {"A": 789, "B": "turtle"}, "timestamp": 0}
      ]
    },
    {
      "name": "convert formats: JSON to PROTOBUF_NOSR",
      "statements": [
        "CREATE STREAM SOURCE (K STRING KEY, A bigint, B varchar) WITH (kafka_topic='source', value_format='JSON');",
        "CREATE STREAM SINK (K STRING KEY, A bigint, B varchar) WITH (kafka_topic='sink', value_format='PROTOBUF_NOSR');",
        "INSERT INTO SINK SELECT * FROM SOURCE;"
      ],
      "inputs": [
        {"topic": "source", "key": "0", "value": {"A": 123, "B": "falcon"}, "timestamp": 0},
        {"topic": "source", "key": "0", "value": {"A": 456, "B": "giraffe"}, "timestamp": 0},
        {"topic": "source", "key": "0", "value": {"A": 789, "B": "turtle"}, "timestamp": 0}
      ],
      "outputs": [
        {"topic": "sink", "key": "0", "value": {"A": 123, "B": "falcon"}, "timestamp": 0},
        {"topic": "sink", "key": "0", "value": {"A": 456, "B": "giraffe"}, "timestamp": 0},
        {"topic": "sink", "key": "0", "value": {"A": 789, "B": "turtle"}, "timestamp": 0}
      ]
    },
    {
      "name": "convert formats: PROTOBUF_NOSR to JSON",
      "statements": [
        "CREATE STREAM SOURCE (K STRING KEY, A bigint, B varchar) WITH (kafka_topic='source', value_format='PROTOBUF_NOSR');",
        "CREATE STREAM SINK (K STRING KEY, A bigint, B varchar) WITH (kafka_topic='sink', value_format='JSON');",
        "INSERT INTO SINK SELECT * FROM SOURCE;"
      ],
      "inputs": [
        {"topic": "source", "key": "0", "value": {"A": 123, "B": "falcon"}, "timestamp": 0},
        {"topic": "source", "key": "0", "value": {"A": 456, "B": "giraffe"}, "timestamp": 0},
        {"topic": "source", "key": "0", "value": {"A": 789, "B": "turtle"}, "timestamp": 0}
      ],
      "outputs": [
        {"topic": "sink", "key": "0", "value": {"A": 123, "B": "falcon"}, "timestamp": 0},
        {"topic": "sink", "key": "0", "value": {"A": 456, "B": "giraffe"}, "timestamp": 0},
        {"topic": "sink", "key": "0", "value": {"A": 789, "B": "turtle"}, "timestamp": 0}
      ]
    },
    {
      "name": "INSERT INTO stream with SCHEMA_ID and SCHEMA_FULL_NAME",
      "statements": [
        "CREATE STREAM SOURCE WITH (kafka_topic='source', format='PROTOBUF', KEY_SCHEMA_ID=1, KEY_SCHEMA_FULL_NAME='ProtobufKey2', VALUE_SCHEMA_ID=2, VALUE_SCHEMA_FULL_NAME='ProtobufValue2');",
        "CREATE STREAM SINK WITH (kafka_topic='sink', format='PROTOBUF', KEY_SCHEMA_FULL_NAME='ProtobufKey2', VALUE_SCHEMA_FULL_NAME='ProtobufValue2');",
        "INSERT INTO SINK SELECT * FROM SOURCE;"
      ],
      "topics": [
        {
          "name": "source",
          "keyFormat": "PROTOBUF",
          "keySchema": "syntax = \"proto3\"; message ProtobufKey1 {uint32 k1 = 1;} message ProtobufKey2 {string K = 1;}",
          "valueFormat": "PROTOBUF",
          "valueSchema": "syntax = \"proto3\"; message ProtobufValue1 {float c1 = 1; uint32 c2 = 2;} message ProtobufValue2 {uint64 A = 1; string B = 2;}"
        },
        {
          "name": "sink",
          "keyFormat": "PROTOBUF",
          "keySchema": "syntax = \"proto3\"; message ProtobufKey1 {uint32 k1 = 1;} message ProtobufKey2 {string K = 1;}",
          "valueFormat": "PROTOBUF",
          "valueSchema": "syntax = \"proto3\"; message ProtobufValue1 {float c1 = 1; uint32 c2 = 2;} message ProtobufValue2 {uint64 A = 1; string B = 2;}"
        }
      ],
      "inputs": [
        {"topic": "source", "key": {"K": "0"}, "value": {"A": 123, "B": "falcon"}, "timestamp": 0},
        {"topic": "source", "key": {"K": "0"}, "value": {"A": 456, "B": "giraffe"}, "timestamp": 0},
        {"topic": "source", "key": {"K": "0"}, "value": {"A": 789, "B": "turtle"}, "timestamp": 0}
      ],
      "outputs": [
        {"topic": "sink", "key": {"K": "0"}, "value": {"A": 123, "B": "falcon"}, "timestamp": 0},
        {"topic": "sink", "key": {"K": "0"}, "value": {"A": 456, "B": "giraffe"}, "timestamp": 0},
        {"topic": "sink", "key": {"K": "0"}, "value": {"A": 789, "B": "turtle"}, "timestamp": 0}
      ]
    },
    {
      "name": "join",
      "statements": [
        "CREATE STREAM SOURCE1 (K STRING KEY, data VARCHAR) WITH (kafka_topic='stream-source', value_format='DELIMITED');",
        "CREATE STREAM SOURCE2 (K STRING KEY, data VARCHAR) WITH (kafka_topic='insert-source', value_format='DELIMITED');",
        "CREATE STREAM OUTPUT AS SELECT K, DATA AS DATA_1, DATA AS DATA_2 FROM SOURCE1;",
        "INSERT INTO OUTPUT SELECT S1.K AS K, S1.DATA AS DATA_1, S2.DATA AS DATA_2 FROM SOURCE1 S1 JOIN SOURCE2 S2 WITHIN 1 SECOND ON S1.K = S2.K;"
      ],
      "inputs": [
        {"topic": "stream-source", "key": "k1", "value": "v1"},
        {"topic": "insert-source", "key": "k1", "value": "v2"}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": "k1", "value": "v1,v1"},
        {"topic": "OUTPUT", "key": "k1", "value": "v1,v2"}
      ]
    },
    {
      "name": "join with repartition",
      "statements": [
        "CREATE STREAM SOURCE1 (ID STRING KEY, k VARCHAR) WITH (kafka_topic='s1', value_format='JSON');",
        "CREATE STREAM SOURCE2 (ID STRING KEY, k VARCHAR) WITH (kafka_topic='s2', value_format='JSON');",
        "CREATE STREAM OUTPUT (k VARCHAR KEY, data VARCHAR, i INT) WITH (kafka_topic='OUTPUT', value_format='JSON', PARTITIONS=1);",
        "INSERT INTO OUTPUT SELECT S1.K AS K, S1.ID + S2.ID as DATA, 1 as I FROM SOURCE1 S1 JOIN SOURCE2 S2 WITHIN 1 SECOND ON S1.k = S2.k;"
      ],
      "inputs": [
        {"topic": "s1", "key": "s1-key", "value": {"K": "v1"}, "timestamp": 0},
        {"topic": "s2", "key": "s2-key", "value": {"K": "v1"}, "timestamp": 0}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": "v1", "value": {"DATA": "s1-keys2-key", "I": 1}}
      ]
    },
    {
      "name": "implicitly casts",
      "statements": [
        "CREATE STREAM SOURCE (ignored VARCHAR) WITH (kafka_topic='source', value_format='AVRO');",
        "CREATE STREAM TARGET (c1 DECIMAL(5,2), c2 DECIMAL(5,2)) WITH (kafka_topic='target', value_format='AVRO');",
        "INSERT INTO TARGET SELECT 1 as c1, 2.0 as c2 FROM SOURCE;"
      ],
      "inputs": [
        {"topic": "source", "value": {"ignored": "v1"}}
      ],
      "outputs": [
        {"topic": "target", "value": {"C1": 1.00, "C2": 2.00}}
      ]
    },
    {
      "name": "join mismatch (fewer columns than expected)",
      "statements": [
        "CREATE STREAM SOURCE1 (K STRING KEY, data VARCHAR) WITH (kafka_topic='stream-source', value_format='DELIMITED');",
        "CREATE STREAM SOURCE2 (K STRING KEY, data VARCHAR) WITH (kafka_topic='insert-source', value_format='DELIMITED');",
        "CREATE STREAM OUTPUT AS SELECT K, DATA AS DATA_1, DATA AS DATA_2 FROM SOURCE1;",
        "INSERT INTO OUTPUT SELECT S1.K AS K, S1.DATA AS DATA_1 FROM SOURCE1 S1 JOIN SOURCE2 S2 WITHIN 1 SECOND ON S1.K = S2.K;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlStatementException",
        "message": "Result schema is `K` STRING KEY, `DATA_1` STRING\nSink schema is `K` STRING KEY, `DATA_1` STRING, `DATA_2` STRING"
      }
    },
    {
      "name": "join mismatch (more columns than expected)",
      "statements": [
        "CREATE STREAM SOURCE1 (K STRING KEY, data VARCHAR) WITH (kafka_topic='stream-source', value_format='DELIMITED');",
        "CREATE STREAM SOURCE2 (K STRING KEY, data VARCHAR) WITH (kafka_topic='insert-source', value_format='DELIMITED');",
        "CREATE STREAM OUTPUT AS SELECT K, DATA AS DATA_1, DATA AS DATA_2 FROM SOURCE1;",
        "INSERT INTO OUTPUT SELECT S1.K AS K, S1.DATA AS DATA_1, S2.DATA AS DATA_2, S2.DATA AS DATA_3 FROM SOURCE1 S1 JOIN SOURCE2 S2 WITHIN 1 SECOND ON S1.K = S2.K;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlStatementException",
        "message": "Result schema is `K` STRING KEY, `DATA_1` STRING, `DATA_2` STRING, `DATA_3` STRING\nSink schema is `K` STRING KEY, `DATA_1` STRING, `DATA_2` STRING"
      }
    }
  ]
}