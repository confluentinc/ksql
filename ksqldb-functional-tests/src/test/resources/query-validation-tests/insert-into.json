{
  "comments": [
    "Tests covering use of the INSERT INTO clause"
  ],
  "tests": [
    {
      "name": "simple",
      "statements": [
        "CREATE STREAM SOURCE1 (K STRING KEY, data VARCHAR) WITH (kafka_topic='stream-source', value_format='DELIMITED');",
        "CREATE STREAM SOURCE2 (K STRING KEY, data VARCHAR) WITH (kafka_topic='insert-source', value_format='DELIMITED');",
        "CREATE STREAM OUTPUT AS SELECT * FROM SOURCE1;",
        "INSERT INTO OUTPUT SELECT * FROM SOURCE2;"
      ],
      "inputs": [
        {"topic": "insert-source", "key": "k1", "value": "v1"}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": "k1", "value": "v1"}
      ]
    },
    {
      "name": "streams with no key columns",
      "statements": [
        "CREATE STREAM SOURCE1 (K STRING, data VARCHAR) WITH (kafka_topic='stream-source', value_format='JSON');",
        "CREATE STREAM SOURCE2 (K STRING, data VARCHAR) WITH (kafka_topic='insert-source', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT * FROM SOURCE1;",
        "INSERT INTO OUTPUT SELECT * FROM SOURCE2;"
      ],
      "inputs": [
        {"topic": "stream-source", "value": {"K": "k1", "data": "v1"}},
        {"topic": "insert-source", "value": {"K": "k2", "data": "v2"}}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": null, "value": {"K": "k1", "DATA": "v1"}},
        {"topic": "OUTPUT", "key": null, "value": {"K": "k2", "DATA": "v2"}}
      ]
    },
    {
      "name": "with custom topic name",
      "statements": [
        "CREATE STREAM SOURCE1 (K STRING KEY, data VARCHAR) WITH (kafka_topic='stream-source', value_format='DELIMITED');",
        "CREATE STREAM SOURCE2 (K STRING KEY, data VARCHAR) WITH (kafka_topic='insert-source', value_format='DELIMITED');",
        "CREATE STREAM OUTPUT WITH(kafka_topic='custom') AS SELECT * FROM SOURCE1;",
        "INSERT INTO OUTPUT SELECT * FROM SOURCE2;"
      ],
      "inputs": [
        {"topic": "insert-source", "key": "k1", "value": "v1"}
      ],
      "outputs": [
        {"topic": "custom", "key": "k1", "value": "v1"}
      ]
    },
    {
      "name": "topic with different schema",
      "statements": [
        "CREATE STREAM SOURCE1 (K STRING KEY, data VARCHAR) WITH (kafka_topic='stream-source', value_format='JSON');",
        "CREATE STREAM SOURCE2 (K STRING KEY, data BIGINT) WITH (kafka_topic='insert-source', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT * FROM SOURCE1;",
        "INSERT INTO OUTPUT SELECT * FROM SOURCE2;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlStatementException",
        "message": "Incompatible schema between results and sink"
      }
    },
    {
      "name": "table",
      "statements": [
        "CREATE STREAM SOURCE (K STRING KEY, d1 VARCHAR) WITH (kafka_topic='SOURCE', value_format='DELIMITED');",
        "CREATE TABLE OUTPUT (d1 STRING PRIMARY KEY, COUNT BIGINT) WITH (kafka_topic='OUTPUT', value_format='DELIMITED');",
        "INSERT INTO OUTPUT SELECT d1, COUNT() AS COUNT FROM SOURCE GROUP BY d1;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlStatementException",
        "message": "INSERT INTO can only be used to insert into a stream. OUTPUT is a table."
      }
    },
    {
      "name": "unknown",
      "statements": [
        "CREATE STREAM SOURCE (K STRING KEY, d1 VARCHAR) WITH (kafka_topic='SOURCE', value_format='DELIMITED');",
        "INSERT INTO UNKNOWN SELECT d1, COUNT() FROM SOURCE GROUP BY d1;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlException",
        "message": "Line: 2, Col: 13: Source `UNKNOWN` does not exist."
      }
    },
    {
      "name": "convert formats: DELIMITED to JSON",
      "statements": [
        "CREATE STREAM SOURCE1 (K STRING KEY, data VARCHAR) WITH (kafka_topic='stream-source', value_format='DELIMITED');",
        "CREATE STREAM SOURCE2 (K STRING KEY, data VARCHAR) WITH (kafka_topic='insert-source', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT * FROM SOURCE1;",
        "INSERT INTO OUTPUT SELECT * FROM SOURCE2;"
      ],
      "inputs": [
        {"topic": "insert-source", "key": "k1", "value": {"data": "v1"}}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": "k1", "value": "v1"}
      ]
    },
    {
      "name": "convert formats: JSON to AVRO",
      "statements": [
        "CREATE STREAM SOURCE (K STRING KEY, A bigint, B varchar) WITH (kafka_topic='source', value_format='JSON');",
        "CREATE STREAM SINK (K STRING KEY, A bigint, B varchar) WITH (kafka_topic='sink', value_format='AVRO');",
        "INSERT INTO SINK SELECT * FROM SOURCE;"
      ],
      "inputs": [
        {"topic": "source", "key": "0", "value": {"A": 123, "B": "falcon"}, "timestamp": 0},
        {"topic": "source", "key": "0", "value": {"A": 456, "B": "giraffe"}, "timestamp": 0},
        {"topic": "source", "key": "0", "value": {"A": 789, "B": "turtle"}, "timestamp": 0}
      ],
      "outputs": [
        {"topic": "sink", "key": "0", "value": {"A": 123, "B": "falcon"}, "timestamp": 0},
        {"topic": "sink", "key": "0", "value": {"A": 456, "B": "giraffe"}, "timestamp": 0},
        {"topic": "sink", "key": "0", "value": {"A": 789, "B": "turtle"}, "timestamp": 0}
      ]
    },
    {
      "name": "convert formats: AVRO to JSON",
      "statements": [
        "CREATE STREAM SOURCE (K STRING KEY, A bigint, B varchar) WITH (kafka_topic='source', value_format='AVRO');",
        "CREATE STREAM SINK (K STRING KEY, A bigint, B varchar) WITH (kafka_topic='sink', value_format='JSON');",
        "INSERT INTO SINK SELECT * FROM SOURCE;"
      ],
      "inputs": [
        {"topic": "source", "key": "0", "value": {"A": 123, "B": "falcon"}, "timestamp": 0},
        {"topic": "source", "key": "0", "value": {"A": 456, "B": "giraffe"}, "timestamp": 0},
        {"topic": "source", "key": "0", "value": {"A": 789, "B": "turtle"}, "timestamp": 0}
      ],
      "outputs": [
        {"topic": "sink", "key": "0", "value": {"A": 123, "B": "falcon"}, "timestamp": 0},
        {"topic": "sink", "key": "0", "value": {"A": 456, "B": "giraffe"}, "timestamp": 0},
        {"topic": "sink", "key": "0", "value": {"A": 789, "B": "turtle"}, "timestamp": 0}
      ]
    },
    {
      "name": "join",
      "statements": [
        "CREATE STREAM SOURCE1 (K STRING KEY, data VARCHAR) WITH (kafka_topic='stream-source', value_format='DELIMITED');",
        "CREATE STREAM SOURCE2 (K STRING KEY, data VARCHAR) WITH (kafka_topic='insert-source', value_format='DELIMITED');",
        "CREATE STREAM OUTPUT AS SELECT K, DATA AS DATA_1, DATA AS DATA_2 FROM SOURCE1;",
        "INSERT INTO OUTPUT SELECT S1.K AS K, S1.DATA AS DATA_1, S2.DATA AS DATA_2 FROM SOURCE1 S1 JOIN SOURCE2 S2 WITHIN 1 SECOND ON S1.K = S2.K;"
      ],
      "inputs": [
        {"topic": "stream-source", "key": "k1", "value": "v1"},
        {"topic": "insert-source", "key": "k1", "value": "v2"}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": "k1", "value": "v1,v1"},
        {"topic": "OUTPUT", "key": "k1", "value": "v1,v2"}
      ]
    },
    {
      "name": "join with repartition",
      "statements": [
        "CREATE STREAM SOURCE1 (ID STRING KEY, k VARCHAR) WITH (kafka_topic='s1', value_format='JSON');",
        "CREATE STREAM SOURCE2 (ID STRING KEY, k VARCHAR) WITH (kafka_topic='s2', value_format='JSON');",
        "CREATE STREAM OUTPUT (k VARCHAR KEY, data VARCHAR, i INT) WITH (kafka_topic='OUTPUT', value_format='JSON', PARTITIONS=1);",
        "INSERT INTO OUTPUT SELECT S1.K AS K, S1.ID + S2.ID as DATA, 1 as I FROM SOURCE1 S1 JOIN SOURCE2 S2 WITHIN 1 SECOND ON S1.k = S2.k;"
      ],
      "inputs": [
        {"topic": "s1", "key": "s1-key", "value": {"K": "v1"}, "timestamp": 0},
        {"topic": "s2", "key": "s2-key", "value": {"K": "v1"}, "timestamp": 0}
      ],
      "outputs": [
        {"topic": "_confluent-ksql-some.ksql.service.idquery_INSERTQUERY_0-Join-left-repartition", "key": "v1", "value": {"S1_K": "v1", "S1_ROWTIME": 0, "S1_ID": "s1-key"}},
        {"topic": "_confluent-ksql-some.ksql.service.idquery_INSERTQUERY_0-KSTREAM-JOINTHIS-0000000016-store-changelog", "window": {"start": 0, "end": 1000, "type": "time"}, "key": "v1", "value": {"S1_K": "v1", "S1_ROWTIME": 0, "S1_ID": "s1-key"}},
        {"topic": "_confluent-ksql-some.ksql.service.idquery_INSERTQUERY_0-Join-right-repartition", "key": "v1", "value": {"S2_K": "v1", "S2_ROWTIME": 0, "S2_ID": "s2-key"}},
        {"topic": "_confluent-ksql-some.ksql.service.idquery_INSERTQUERY_0-KSTREAM-JOINOTHER-0000000017-store-changelog", "window": {"start": 0, "end": 1000, "type": "time"}, "key": "v1", "value": {"S2_K": "v1", "S2_ROWTIME": 0, "S2_ID": "s2-key"}},
        {"topic": "OUTPUT", "key": "v1", "value": {"DATA": "s1-keys2-key", "I": 1}}
      ]
    },
    {
      "name": "implicitly casts",
      "statements": [
        "CREATE STREAM SOURCE (ignored VARCHAR) WITH (kafka_topic='source', value_format='AVRO');",
        "CREATE STREAM TARGET (c1 DECIMAL(5,2), c2 DECIMAL(5,2)) WITH (kafka_topic='target', value_format='AVRO');",
        "INSERT INTO TARGET SELECT 1 as c1, 2.0 as c2 FROM SOURCE;"
      ],
      "inputs": [
        {"topic": "source", "value": {"ignored": "v1"}}
      ],
      "outputs": [
        {"topic": "target", "value": {"C1": 1.00, "C2": 2.00}}
      ]
    }
  ]
}