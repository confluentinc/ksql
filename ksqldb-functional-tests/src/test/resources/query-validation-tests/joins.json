{
  "tests": [
    {
      "name": "matching columns in both sides = select *",
      "statements": [
        "CREATE STREAM L (A INT KEY, B INT, C INT) WITH (kafka_topic='LEFT', value_format='JSON');",
        "CREATE STREAM R (A INT KEY, B INT, C INT) WITH (kafka_topic='RIGHT', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT * FROM L INNER JOIN R WITHIN 10 SECONDS ON L.A = R.A;"
      ],
      "inputs": [
        {"topic": "LEFT", "key": 0, "value": {"B": 1, "C": 2}, "timestamp": 10},
        {"topic": "RIGHT", "key": 0, "value": {"B": -1, "C": -2}, "timestamp": 11}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 0, "value": {"R_A": 0, "L_B": 1, "R_B": -1, "L_C": 2, "R_C": -2}, "timestamp":  11}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "L_A INT KEY, L_B INT, L_C INT, R_A INT, R_B INT, R_C INT"}
        ],
        "topics": {
          "blacklist": ".*-repartition"
        }
      }
    },
    {
      "name": "matching columns in both sides = select left.* and right.*",
      "statements": [
        "CREATE STREAM L (A INT KEY, B INT, C INT) WITH (kafka_topic='LEFT', value_format='JSON');",
        "CREATE STREAM R (A INT KEY, B INT, C INT) WITH (kafka_topic='RIGHT', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT l.*, r.* FROM L INNER JOIN R WITHIN 10 SECONDS ON L.A = R.A;"
      ],
      "inputs": [
        {"topic": "LEFT", "key": 0, "value": {"B": 1, "C": 2}, "timestamp": 10},
        {"topic": "RIGHT", "key": 0, "value": {"B": -1, "C": -2}, "timestamp": 11}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 0, "value": {"R_A": 0, "L_B": 1, "R_B": -1, "L_C": 2, "R_C": -2}, "timestamp":  11}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "L_A INT KEY, L_B INT, L_C INT, R_A INT, R_B INT, R_C INT"}
        ],
        "topics": {
          "blacklist": ".*-repartition"
        }
      }
    },
    {
      "name": "matching columns in both sides = select left.* and right.* with WHERE",
      "statements": [
        "CREATE STREAM L (A INT KEY, B INT, C INT) WITH (kafka_topic='LEFT', value_format='JSON');",
        "CREATE STREAM R (A INT KEY, B INT, C INT) WITH (kafka_topic='RIGHT', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT l.*, r.* FROM L INNER JOIN R WITHIN 10 SECONDS ON L.A = R.A WHERE R.B < 5;"
      ],
      "inputs": [
        {"topic": "LEFT", "key": 0, "value": {"B": 1, "C": 2}, "timestamp": 10},
        {"topic": "RIGHT", "key": 0, "value": {"B": -1, "C": -2}, "timestamp": 11},
        {"topic": "RIGHT", "key": 0, "value": {"B": 9, "C": 10}, "timestamp": 12}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 0, "value": {"R_A": 0, "L_B": 1, "R_B": -1, "L_C": 2, "R_C": -2}, "timestamp":  11}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "L_A INT KEY, L_B INT, L_C INT, R_A INT, R_B INT, R_C INT"}
        ],
        "topics": {
          "blacklist": ".*-repartition"
        }
      }
    },
    {
      "name": "aliased join condition",
      "statements": [
        "CREATE STREAM left_stream (id INT KEY, b INT, c INT) WITH (kafka_topic='LEFT_TOPIC', value_format='JSON');",
        "CREATE STREAM right_stream (id INT KEY, e INT, f INT) WITH (kafka_topic='RIGHT_TOPIC', value_format='JSON');",
        "CREATE STREAM output AS SELECT ls.id, ls.b, ls.c, rs.e, rs.f FROM left_stream AS ls INNER JOIN right_stream AS rs WITHIN 10 SECONDS ON ls.id = rs.id;"
      ],
      "inputs": [
        {"topic": "LEFT_TOPIC", "key": 0, "value": {"b": 1, "c": 2}, "timestamp": 10},
        {"topic": "RIGHT_TOPIC", "key": 0, "value": {"e": -1, "f": -2}, "timestamp": 11}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 0, "value": {"B": 1, "C": 2, "E": -1, "F": -2}, "timestamp":  11}
      ],
      "post": {
        "topics": {
          "blacklist": ".*-repartition"
        }
      }
    },
    {
      "name": "aliased join key",
      "statements": [
        "CREATE STREAM L (A INT KEY, B INT, C INT) WITH (kafka_topic='LEFT', value_format='JSON');",
        "CREATE STREAM R (A INT KEY, B INT, C INT) WITH (kafka_topic='RIGHT', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT l.A AS A, l.B, l.C, r.* FROM L INNER JOIN R WITHIN 10 SECONDS ON L.A = R.A;"
      ],
      "inputs": [
        {"topic": "LEFT", "key": 0, "value": {"B": 1, "C": 2}, "timestamp": 10},
        {"topic": "RIGHT", "key": 0, "value": {"B": -1, "C": -2}, "timestamp": 11}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 0, "value": {"L_B": 1, "L_C": 2, "R_A": 0, "R_B": -1, "R_C": -2}, "timestamp":  11}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "A INT KEY, L_B INT, L_C INT, R_A INT, R_B INT, R_C INT"}
        ],
        "topics": {
          "blacklist": ".*-repartition"
        }
      }
    },
    {
      "name": "aliased synthetic join key",
      "statements": [
        "CREATE STREAM L (A INT KEY, B INT, C INT) WITH (kafka_topic='LEFT', value_format='JSON');",
        "CREATE STREAM R (A INT KEY, B INT, C INT) WITH (kafka_topic='RIGHT', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT ROWKEY AS A, l.B, l.C, r.* FROM L INNER JOIN R WITHIN 10 SECONDS ON ABS(L.A) = ABS(R.A);"
      ],
      "inputs": [
        {"topic": "LEFT", "key": 0, "value": {"B": 1, "C": 2}, "timestamp": 10},
        {"topic": "RIGHT", "key": 0, "value": {"B": -1, "C": -2}, "timestamp": 11}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 0, "value": {"L_B": 1, "L_C": 2, "R_A": 0, "R_B": -1, "R_C": -2}, "timestamp":  11}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "A INT KEY, L_B INT, L_C INT, R_A INT, R_B INT, R_C INT"}
        ]
      }
    },
    {
      "name": "unaliased synthetic join key",
      "statements": [
        "CREATE TABLE L (ID INT PRIMARY KEY, V0 INT, V1 INT) WITH (kafka_topic='left_topic', value_format='JSON');",
        "CREATE TABLE R (ID INT PRIMARY KEY, V0 INT, V1 INT) WITH (kafka_topic='right_topic', value_format='JSON');",
        "CREATE TABLE OUTPUT as SELECT ROWKEY, L.ID, R.ID, L.V0, R.V1 FROM L FULL OUTER JOIN R on L.id = R.id;"
      ],
      "inputs": [
        {"topic": "left_topic", "key": 1, "value": {"V0": 2, "V1": 3}, "timestamp": 0},
        {"topic": "right_topic", "key": 1, "value": {"V0": 4, "V1": 5}, "timestamp": 100}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 1, "value": {"L_ID": 1, "R_ID": null, "L_V0": 2, "R_V1": null}, "timestamp": 0},
        {"topic": "OUTPUT", "key": 1, "value": {"L_ID": 1, "R_ID": 1, "L_V0": 2, "R_V1": 5}, "timestamp": 100}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "table", "schema": "ROWKEY INT KEY, L_ID INT, R_ID INT, L_V0 INT, R_V1 INT"}
        ]
      }
    },
    {
      "name": "inner join - with both join column in projection",
      "statements": [
        "CREATE STREAM L (A INT KEY, B INT, C INT) WITH (kafka_topic='LEFT', value_format='JSON');",
        "CREATE STREAM R (A INT KEY, B INT, C INT) WITH (kafka_topic='RIGHT', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT * FROM L INNER JOIN R WITHIN 10 SECONDS ON L.A = R.A;"
      ],
      "inputs": [
        {"topic": "LEFT", "key": 0, "value": {"B": 1, "C": 2}, "timestamp": 10},
        {"topic": "RIGHT", "key": 0, "value": {"B": -1, "C": -2}, "timestamp": 11}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 0, "value": {"L_B": 1, "L_C": 2, "R_A": 0, "R_B": -1, "R_C": -2}, "timestamp":  11}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "L_A INT KEY, L_B INT, L_C INT, R_A INT, R_B INT, R_C INT"}
        ]
      }
    },
    {
      "name": "inner join - with left join column in projection",
      "statements": [
        "CREATE STREAM L (A INT KEY, B INT, C INT) WITH (kafka_topic='LEFT', value_format='JSON');",
        "CREATE STREAM R (A INT KEY, B INT, C INT) WITH (kafka_topic='RIGHT', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT L.*, R.* FROM L INNER JOIN R WITHIN 10 SECONDS ON L.A = ABS(R.A);"
      ],
      "inputs": [
        {"topic": "LEFT", "key": 0, "value": {"B": 1, "C": 2}, "timestamp": 10},
        {"topic": "RIGHT", "key": 0, "value": {"B": -1, "C": -2}, "timestamp": 11}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 0, "value": {"L_B": 1, "L_C": 2, "R_A": 0, "R_B": -1, "R_C": -2}, "timestamp":  11}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "L_A INT KEY, L_B INT, L_C INT, R_A INT, R_B INT, R_C INT"}
        ]
      }
    },
    {
      "name": "inner join - with right join column in projection",
      "statements": [
        "CREATE STREAM L (A INT KEY, B INT, C INT) WITH (kafka_topic='LEFT', value_format='JSON');",
        "CREATE STREAM R (A INT KEY, B INT, C INT) WITH (kafka_topic='RIGHT', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT L.*, R.* FROM L INNER JOIN R WITHIN 10 SECONDS ON ABS(L.A) = R.A;"
      ],
      "inputs": [
        {"topic": "LEFT", "key": 0, "value": {"B": 1, "C": 2}, "timestamp": 10},
        {"topic": "RIGHT", "key": 0, "value": {"B": -1, "C": -2}, "timestamp": 11}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 0, "value": {"L_A": 0, "L_B": 1, "L_C": 2, "R_B": -1, "R_C": -2}, "timestamp":  11}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "R_A INT KEY, L_A INT, L_B INT, L_C INT, R_B INT, R_C INT"}
        ]
      }
    },
    {
      "name": "inner join - with only right join column in projection",
      "statements": [
        "CREATE STREAM L (A INT KEY, B INT, C INT) WITH (kafka_topic='LEFT', value_format='JSON');",
        "CREATE STREAM R (A INT KEY, B INT, C INT) WITH (kafka_topic='RIGHT', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT L.B, L.C, R.* FROM L INNER JOIN R WITHIN 10 SECONDS ON L.A = R.A;"
      ],
      "inputs": [
        {"topic": "LEFT", "key": 0, "value": {"B": 1, "C": 2}, "timestamp": 10},
        {"topic": "RIGHT", "key": 0, "value": {"B": -1, "C": -2}, "timestamp": 11}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 0, "value": {"L_B": 1, "L_C": 2, "R_B": -1, "R_C": -2}, "timestamp":  11}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "R_A INT KEY, L_B INT, L_C INT, R_B INT, R_C INT"}
        ]
      }
    },
    {
      "name": "inner join - missing join columns in projection",
      "statements": [
        "CREATE STREAM L (A INT KEY, B INT, C INT) WITH (kafka_topic='LEFT', value_format='JSON');",
        "CREATE STREAM R (A INT KEY, B INT, C INT) WITH (kafka_topic='RIGHT', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT l.B, l.C, R.B, R.C FROM L INNER JOIN R WITHIN 10 SECONDS ON L.A = R.A;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlStatementException",
        "message": "The query used to build `OUTPUT` must include the join expressions L.A or R.A in its projection (eg, SELECT L.A...)."
      }
    },
    {
      "name": "inner join - missing synthetic join column in projection",
      "statements": [
        "CREATE STREAM L (A INT KEY, B INT, C INT) WITH (kafka_topic='LEFT', value_format='JSON');",
        "CREATE STREAM R (A INT KEY, B INT, C INT) WITH (kafka_topic='RIGHT', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT l.*, r.* FROM L INNER JOIN R WITHIN 10 SECONDS ON ABS(L.A) = ABS(R.A);"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlStatementException",
        "message": "Key missing from projection (ie, SELECT). See https://cnfl.io/2LV7ouS.\nThe query used to build `OUTPUT` must include the join expression ROWKEY in its projection (eg, SELECT ROWKEY...).\nROWKEY was added as a synthetic key column because the join criteria did not match any source column. This expression must be included in the projection and may be aliased."
      }
    },
    {
      "name": "left join - with both join column in projection",
      "statements": [
        "CREATE STREAM L (A INT KEY, B INT, C INT) WITH (kafka_topic='LEFT', value_format='JSON');",
        "CREATE STREAM R (A INT KEY, B INT, C INT) WITH (kafka_topic='RIGHT', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT * FROM L LEFT JOIN R WITHIN 10 SECONDS ON L.A = R.A;"
      ],
      "inputs": [
        {"topic": "RIGHT", "key": 0, "value": {"B": -1, "C": -2}, "timestamp": 10},
        {"topic": "LEFT", "key": 0, "value": {"B": 1, "C": 2}, "timestamp": 10}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 0, "value": {"L_B": 1, "L_C": 2, "R_A": 0, "R_B": -1, "R_C": -2}, "timestamp":  10}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "L_A INT KEY, L_B INT, L_C INT, R_A INT, R_B INT, R_C INT"}
        ]
      }
    },
    {
      "name": "left join - with left join column in projection",
      "statements": [
        "CREATE STREAM L (A INT KEY, B INT, C INT) WITH (kafka_topic='LEFT', value_format='JSON');",
        "CREATE STREAM R (A INT KEY, B INT, C INT) WITH (kafka_topic='RIGHT', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT L.*, R.* FROM L LEFT JOIN R WITHIN 10 SECONDS ON L.A = ABS(R.A);"
      ],
      "inputs": [
        {"topic": "RIGHT", "key": 0, "value": {"B": -1, "C": -2}, "timestamp": 10},
        {"topic": "LEFT", "key": 0, "value": {"B": 1, "C": 2}, "timestamp": 10}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 0, "value": {"L_B": 1, "L_C": 2, "R_A": 0, "R_B": -1, "R_C": -2}, "timestamp":  10}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "L_A INT KEY, L_B INT, L_C INT, R_A INT, R_B INT, R_C INT"}
        ]
      }
    },
    {
      "name": "left join - with right join column in projection",
      "statements": [
        "CREATE STREAM L (A INT KEY, B INT, C INT) WITH (kafka_topic='LEFT', value_format='JSON');",
        "CREATE STREAM R (A INT KEY, B INT, C INT) WITH (kafka_topic='RIGHT', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT L.*, R.* FROM L LEFT JOIN R WITHIN 10 SECONDS ON ABS(L.A) = R.A;"
      ],
      "inputs": [
        {"topic": "RIGHT", "key": 0, "value": {"B": -1, "C": -2}, "timestamp": 10},
        {"topic": "LEFT", "key": 0, "value": {"B": 1, "C": 2}, "timestamp": 10}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 0, "value": {"L_A": 0, "L_B": 1, "L_C": 2, "R_B": -1, "R_C": -2}, "timestamp":  10}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "R_A INT KEY, L_A INT, L_B INT, L_C INT, R_B INT, R_C INT"}
        ]
      }
    },
    {
      "name": "left join - with synthetic join column in projection",
      "statements": [
        "CREATE STREAM L (ID INT KEY, V0 INT, V1 INT) WITH (kafka_topic='left_topic', value_format='JSON');",
        "CREATE STREAM R (ID INT KEY, V0 INT, V1 INT) WITH (kafka_topic='right_topic', value_format='JSON');",
        "CREATE STREAM OUTPUT as SELECT ROWKEY AS ID, L.ID, R.ID, L.V0, R.V1 FROM L LEFT JOIN R WITHIN 1 SECOND ON ABS(L.id) = ABS(R.id);"
      ],
      "inputs": [
        {"topic": "left_topic", "key": 1, "value": {"V0": 2, "V1": 3}, "timestamp": 0},
        {"topic": "right_topic", "key": 1, "value": {"V0": 4, "V1": 5}, "timestamp": 100}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 1, "value": {"L_ID": 1, "R_ID": null, "L_V0": 2, "R_V1": null}, "timestamp": 0},
        {"topic": "OUTPUT", "key": 1, "value": {"L_ID": 1, "R_ID": 1, "L_V0": 2, "R_V1": 5}, "timestamp": 100}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "ID INT KEY, L_ID INT, R_ID INT, L_V0 INT, R_V1 INT"}
        ]
      }
    },
    {
      "name": "left join - missing join columns in projection",
      "statements": [
        "CREATE STREAM L (A INT KEY, B INT, C INT) WITH (kafka_topic='LEFT', value_format='JSON');",
        "CREATE STREAM R (A INT KEY, B INT, C INT) WITH (kafka_topic='RIGHT', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT l.B, l.C, r.B, r.C FROM L LEFT JOIN R WITHIN 10 SECONDS ON L.A = R.A;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlStatementException",
        "message": "The query used to build `OUTPUT` must include the join expressions L.A or R.A in its projection (eg, SELECT L.A...)."
      }
    },
    {
      "name": "left join - missing join columns in projection - with star",
      "statements": [
        "CREATE STREAM L (A INT KEY, B INT, C INT) WITH (kafka_topic='LEFT', value_format='JSON');",
        "CREATE STREAM R (A INT KEY, B INT, C INT) WITH (kafka_topic='RIGHT', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT l.*, r.B, r.C FROM L LEFT JOIN R WITHIN 10 SECONDS ON ABS(L.A) = R.A;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlStatementException",
        "message": "The query used to build `OUTPUT` must include the join expression R.A in its projection (eg, SELECT R.A...)."
      }
    },
    {
      "name": "left join - missing synthetic join column in projection",
      "statements": [
        "CREATE STREAM L (A INT KEY, B INT, C INT) WITH (kafka_topic='LEFT', value_format='JSON');",
        "CREATE STREAM R (A INT KEY, B INT, C INT) WITH (kafka_topic='RIGHT', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT l.*, r.* FROM L LEFT JOIN R WITHIN 10 SECONDS ON ABS(L.A) = ABS(R.A);"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlStatementException",
        "message": "Key missing from projection (ie, SELECT). See https://cnfl.io/2LV7ouS.\nThe query used to build `OUTPUT` must include the join expression ROWKEY in its projection (eg, SELECT ROWKEY...).\nROWKEY was added as a synthetic key column because the join criteria did not match any source column."
      }
    },
    {
      "name": "full join - with both join column in projection",
      "statements": [
        "CREATE STREAM L (A INT KEY, B INT, C INT) WITH (kafka_topic='LEFT', value_format='JSON');",
        "CREATE STREAM R (A INT KEY, B INT, C INT) WITH (kafka_topic='RIGHT', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT * FROM L FULL OUTER JOIN R WITHIN 10 SECONDS ON L.A = R.A;"
      ],
      "inputs": [
        {"topic": "RIGHT", "key": 0, "value": {"B": -1, "C": -2}, "timestamp": 9},
        {"topic": "LEFT", "key": 0, "value": {"B": 1, "C": 2}, "timestamp": 10}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 0, "value": {"L_A": null, "L_B": null, "L_C": null, "R_A": 0, "R_B": -1, "R_C": -2}, "timestamp": 9},
        {"topic": "OUTPUT", "key": 0, "value": {"L_A": 0, "L_B": 1, "L_C": 2, "R_A": 0, "R_B": -1, "R_C": -2}, "timestamp": 10}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "ROWKEY INT KEY, L_A INT, L_B INT, L_C INT, R_A INT, R_B INT, R_C INT"}
        ]
      }
    },
    {
      "name": "full join - missing synthetic join column in projection",
      "statements": [
        "CREATE STREAM L (A INT KEY, B INT, C INT) WITH (kafka_topic='LEFT', value_format='JSON');",
        "CREATE STREAM R (A INT KEY, B INT, C INT) WITH (kafka_topic='RIGHT', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT l.B, l.C, r.* FROM L FULL OUTER JOIN R WITHIN 10 SECONDS ON L.A = R.A;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlStatementException",
        "message": "The query used to build `OUTPUT` must include the join expression ROWKEY in its projection (eg, SELECT ROWKEY...).\nROWKEY was added as a synthetic key column because the join criteria did not match any source column."
      }
    },
    {
      "name": "missing join columns in projection - with value column of same name",
      "statements": [
        "CREATE STREAM L (A INT KEY, B INT, C INT) WITH (kafka_topic='LEFT', value_format='JSON');",
        "CREATE STREAM R (A INT KEY, B INT, C INT) WITH (kafka_topic='RIGHT', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT l.B AS L_A, l.C, R.B AS R_A, R.C FROM L JOIN R WITHIN 10 SECONDS ON L.A = R.A;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlStatementException",
        "message": "The query used to build `OUTPUT` must include the join expressions L.A or R.A in its projection (eg, SELECT L.A...)."
      }
    },
    {
      "name": "key in projection more than once",
      "statements": [
        "CREATE STREAM L (A INT KEY, B INT, C INT) WITH (kafka_topic='LEFT', value_format='JSON');",
        "CREATE STREAM R (A INT KEY, B INT, C INT) WITH (kafka_topic='RIGHT', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT l.A, l.A AS KEY2, l.C, R.C FROM L JOIN R WITHIN 10 SECONDS ON L.A = R.A;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlStatementException",
        "message": "The projection contains a key column (`L_A`) more than once, aliased as: KEY2 and L_A."
      }
    },
    {
      "name": "stream stream left join",
      "format": ["AVRO", "JSON"],
      "statements": [
        "CREATE STREAM TEST (ID BIGINT KEY, NAME varchar, VALUE bigint) WITH (kafka_topic='left_topic', value_format='{FORMAT}');",
        "CREATE STREAM TEST_STREAM (ID BIGINT KEY, F1 varchar, F2 bigint) WITH (kafka_topic='right_topic', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT as SELECT t.id, name, value, f1, f2 FROM test t left join TEST_STREAM tt WITHIN 11 seconds ON t.id = tt.id;"
      ],
      "inputs": [
        {"topic": "left_topic", "key": 0, "value": {"NAME": "zero", "VALUE": 0}, "timestamp": 0},
        {"topic": "right_topic", "key": 0, "value": {"F1": "blah", "F2": 50}, "timestamp": 10000},
        {"topic": "left_topic", "key": 10, "value": {"NAME": "100", "VALUE": 5}, "timestamp": 11000},
        {"topic": "left_topic", "key": 0, "value": {"NAME": "foo", "VALUE": 100}, "timestamp": 13000},
        {"topic": "right_topic", "key": 0, "value": {"F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "right_topic", "key": 100, "value": {"F1": "newblah", "F2": 150}, "timestamp": 16000},
        {"topic": "left_topic", "key": 90, "value": {"NAME": "ninety", "VALUE": 90}, "timestamp": 17000},
        {"topic": "left_topic", "key": 0, "value": {"NAME": "bar", "VALUE": 99}, "timestamp": 30000}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "zero", "VALUE": 0, "F1": null, "F2": null}, "timestamp": 0},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "zero", "VALUE": 0, "F1": "blah", "F2": 50}, "timestamp": 10000},
        {"topic": "OUTPUT", "key": 10, "value": {"NAME": "100", "VALUE": 5, "F1": null, "F2": null}, "timestamp": 11000},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "foo", "VALUE": 100, "F1": "blah", "F2": 50}, "timestamp": 13000},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "foo", "VALUE": 100, "F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "OUTPUT", "key": 90, "value": {"NAME": "ninety", "VALUE": 90, "F1": null, "F2": null}, "timestamp": 17000},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "bar", "VALUE": 99, "F1": null, "F2": null}, "timestamp": 30000}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "T_ID BIGINT KEY, NAME STRING, VALUE BIGINT, F1 STRING, F2 BIGINT"}
        ],
        "topics": {
          "blacklist": ".*-repartition"
        }
      }
    },
    {
      "name": "stream stream left join - PROTOBUF",
      "format": ["PROTOBUF", "PROTOBUF_NOSR"],
      "statements": [
        "CREATE STREAM TEST (ID BIGINT KEY, NAME varchar, VALUE bigint) WITH (kafka_topic='left_topic', value_format='{FORMAT}');",
        "CREATE STREAM TEST_STREAM (ID BIGINT KEY, F1 varchar, F2 bigint) WITH (kafka_topic='right_topic', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT as SELECT t.id, name, value, f1, f2 FROM test t left join TEST_STREAM tt WITHIN 11 seconds ON t.id = tt.id;"
      ],
      "inputs": [
        {"topic": "left_topic", "key": 0, "value": {"NAME": "zero", "VALUE": 0}, "timestamp": 0},
        {"topic": "right_topic", "key": 0, "value": {"F1": "blah", "F2": 50}, "timestamp": 10000},
        {"topic": "left_topic", "key": 10, "value": {"NAME": "100", "VALUE": 5}, "timestamp": 11000},
        {"topic": "left_topic", "key": 0, "value": {"NAME": "foo", "VALUE": 100}, "timestamp": 13000},
        {"topic": "right_topic", "key": 0, "value": {"F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "right_topic", "key": 100, "value": {"F1": "newblah", "F2": 150}, "timestamp": 16000},
        {"topic": "left_topic", "key": 90, "value": {"NAME": "ninety", "VALUE": 90}, "timestamp": 17000},
        {"topic": "left_topic", "key": 0, "value": {"NAME": "bar", "VALUE": 99}, "timestamp": 30000}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "zero", "VALUE": 0, "F1": "", "F2": 0}, "timestamp": 0},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "zero", "VALUE": 0, "F1": "blah", "F2": 50}, "timestamp": 10000},
        {"topic": "OUTPUT", "key": 10, "value": {"NAME": "100", "VALUE": 5, "F1": "", "F2": 0}, "timestamp": 11000},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "foo", "VALUE": 100, "F1": "blah", "F2": 50}, "timestamp": 13000},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "foo", "VALUE": 100, "F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "OUTPUT", "key": 90, "value": {"NAME": "ninety", "VALUE": 90, "F1": "", "F2": 0}, "timestamp": 17000},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "bar", "VALUE": 99, "F1": "", "F2": 0}, "timestamp": 30000}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "T_ID BIGINT KEY, NAME STRING, VALUE BIGINT, F1 STRING, F2 BIGINT"}
        ],
        "topics": {
          "blacklist": ".*-repartition"
        }
      }
    },
    {
      "name": "stream stream left join - KAFKA",
      "statements": [
        "CREATE STREAM S_LEFT (ID BIGINT KEY, NAME varchar) WITH (kafka_topic='left_topic', value_format='KAFKA');",
        "CREATE STREAM S_RIGHT (ID BIGINT KEY, NAME varchar) WITH (kafka_topic='right_topic', value_format='KAFKA');",
        "CREATE STREAM OUTPUT WITH(value_format='delimited') as SELECT * FROM s_left LEFT JOIN s_right WITHIN 1 second ON s_left.id = s_right.id;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlStatementException",
        "message": "Source(s) S_LEFT, S_RIGHT are using the 'KAFKA' value format. This format does not yet support JOIN."
      }
    },
    {
      "name": "stream stream left join with key in projection - rekey",
      "format": ["AVRO", "JSON"],
      "statements": [
        "CREATE STREAM TEST (K STRING KEY, ID bigint, NAME varchar, VALUE bigint) WITH (kafka_topic='left_topic', value_format='{FORMAT}');",
        "CREATE STREAM TEST_STREAM (K STRING KEY, ID bigint, F1 varchar, F2 bigint) WITH (kafka_topic='right_topic', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT as SELECT t.id, t.k, name, value, f1, f2 FROM test t left join TEST_STREAM tt WITHIN 11 seconds ON t.id = tt.id;"
      ],
      "inputs": [
        {"topic": "left_topic", "key": "foo", "value": {"ID": 0, "NAME": "zero", "VALUE": 0}, "timestamp": 0},
        {"topic": "right_topic", "key": "foo", "value": {"ID": 0, "F1": "blah", "F2": 50}, "timestamp": 10000},
        {"topic": "left_topic", "key": "foo", "value": {"ID": 10, "NAME": "100", "VALUE": 5}, "timestamp": 11000},
        {"topic": "left_topic", "key": "foo", "value": {"ID": 0, "NAME": "foo", "VALUE": 100}, "timestamp": 13000},
        {"topic": "right_topic", "key": "foo", "value": {"ID": 0, "F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "right_topic", "key": "foo", "value": {"ID": 100, "F1": "newblah", "F2": 150}, "timestamp": 16000},
        {"topic": "left_topic", "key": "foo", "value": {"ID": 90, "NAME": "ninety", "VALUE": 90}, "timestamp": 17000},
        {"topic": "left_topic", "key": "foo", "value": {"ID": 0, "NAME": "bar", "VALUE": 99}, "timestamp": 30000}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 0, "value": {"T_K": "foo", "NAME": "zero", "VALUE": 0, "F1": null, "F2": null}, "timestamp": 0},
        {"topic": "OUTPUT", "key": 0, "value": {"T_K": "foo", "NAME": "zero", "VALUE": 0, "F1": "blah", "F2": 50}, "timestamp": 10000},
        {"topic": "OUTPUT", "key": 10, "value": {"T_K": "foo", "NAME": "100", "VALUE": 5, "F1": null, "F2": null}, "timestamp": 11000},
        {"topic": "OUTPUT", "key": 0, "value": {"T_K": "foo", "NAME": "foo", "VALUE": 100, "F1": "blah", "F2": 50}, "timestamp": 13000},
        {"topic": "OUTPUT", "key": 0, "value": {"T_K": "foo", "NAME": "foo", "VALUE": 100, "F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "OUTPUT", "key": 90, "value": {"T_K": "foo", "NAME": "ninety", "VALUE": 90, "F1": null, "F2": null}, "timestamp": 17000},
        {"topic": "OUTPUT", "key": 0, "value": {"T_K": "foo", "NAME": "bar", "VALUE": 99, "F1": null, "F2": null}, "timestamp": 30000}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "T_ID BIGINT KEY, T_K STRING, NAME STRING, VALUE BIGINT, F1 STRING, F2 BIGINT"}
        ]
      }
    },
    {
      "name": "stream stream left join with key in projection - rekey",
      "format": ["PROTOBUF", "PROTOBUF_NOSR"],
      "statements": [
        "CREATE STREAM TEST (K STRING KEY, ID bigint, NAME varchar, VALUE bigint) WITH (kafka_topic='left_topic', value_format='{FORMAT}');",
        "CREATE STREAM TEST_STREAM (K STRING KEY, ID bigint, F1 varchar, F2 bigint) WITH (kafka_topic='right_topic', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT as SELECT t.id, t.k, name, value, f1, f2 FROM test t left join TEST_STREAM tt WITHIN 11 seconds ON t.id = tt.id;"
      ],
      "inputs": [
        {"topic": "left_topic", "key": "foo", "value": {"ID": 0, "NAME": "zero", "VALUE": 0}, "timestamp": 0},
        {"topic": "right_topic", "key": "foo", "value": {"ID": 0, "F1": "blah", "F2": 50}, "timestamp": 10000},
        {"topic": "left_topic", "key": "foo", "value": {"ID": 10, "NAME": "100", "VALUE": 5}, "timestamp": 11000},
        {"topic": "left_topic", "key": "foo", "value": {"ID": 0, "NAME": "foo", "VALUE": 100}, "timestamp": 13000},
        {"topic": "right_topic", "key": "foo", "value": {"ID": 0, "F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "right_topic", "key": "foo", "value": {"ID": 100, "F1": "newblah", "F2": 150}, "timestamp": 16000},
        {"topic": "left_topic", "key": "foo", "value": {"ID": 90, "NAME": "ninety", "VALUE": 90}, "timestamp": 17000},
        {"topic": "left_topic", "key": "foo", "value": {"ID": 0, "NAME": "bar", "VALUE": 99}, "timestamp": 30000}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 0, "value": {"T_K": "foo","NAME": "zero", "VALUE": 0, "F1": "", "F2": 0}, "timestamp": 0},
        {"topic": "OUTPUT", "key": 0, "value": {"T_K": "foo", "NAME": "zero", "VALUE": 0, "F1": "blah", "F2": 50}, "timestamp": 10000},
        {"topic": "OUTPUT", "key": 10, "value": {"T_K": "foo", "NAME": "100", "VALUE": 5, "F1": "", "F2": 0}, "timestamp": 11000},
        {"topic": "OUTPUT", "key": 0, "value": {"T_K": "foo", "NAME": "foo", "VALUE": 100, "F1": "blah", "F2": 50}, "timestamp": 13000},
        {"topic": "OUTPUT", "key": 0, "value": {"T_K": "foo", "NAME": "foo", "VALUE": 100, "F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "OUTPUT", "key": 90, "value": {"T_K": "foo", "NAME": "ninety", "VALUE": 90, "F1": "", "F2": 0}, "timestamp": 17000},
        {"topic": "OUTPUT", "key": 0, "value": {"T_K": "foo", "NAME": "bar", "VALUE": 99, "F1": "", "F2": 0}, "timestamp": 30000}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "T_ID BIGINT KEY, T_K STRING, NAME STRING, VALUE BIGINT, F1 STRING, F2 BIGINT"}
        ]
      }
    },
    {
      "name": "stream stream left join - rekey",
      "format": ["AVRO", "JSON"],
      "statements": [
        "CREATE STREAM TEST (K STRING KEY, ID bigint, NAME varchar, VALUE bigint) WITH (kafka_topic='left_topic', value_format='{FORMAT}');",
        "CREATE STREAM TEST_STREAM (K STRING KEY, ID bigint, F1 varchar, F2 bigint) WITH (kafka_topic='right_topic', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT as SELECT t.id, name, value, f1, f2 FROM test t left join TEST_STREAM tt WITHIN 11 seconds ON t.id = tt.id;"
      ],
      "inputs": [
        {"topic": "left_topic", "value": {"ID": 0, "NAME": "zero", "VALUE": 0}, "timestamp": 0},
        {"topic": "right_topic", "value": {"ID": 0, "F1": "blah", "F2": 50}, "timestamp": 10000},
        {"topic": "left_topic", "value": {"ID": 10, "NAME": "100", "VALUE": 5}, "timestamp": 11000},
        {"topic": "left_topic", "value": {"ID": 0, "NAME": "foo", "VALUE": 100}, "timestamp": 13000},
        {"topic": "right_topic", "value": {"ID": 0, "F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "right_topic", "value": {"ID": 100, "F1": "newblah", "F2": 150}, "timestamp": 16000},
        {"topic": "left_topic", "value": {"ID": 90, "NAME": "ninety", "VALUE": 90}, "timestamp": 17000},
        {"topic": "left_topic", "value": {"ID": 0, "NAME": "bar", "VALUE": 99}, "timestamp": 30000}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "zero", "VALUE": 0, "F1": null, "F2": null}, "timestamp": 0},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "zero", "VALUE": 0, "F1": "blah", "F2": 50}, "timestamp": 10000},
        {"topic": "OUTPUT", "key": 10, "value": {"NAME": "100", "VALUE": 5, "F1": null, "F2": null}, "timestamp": 11000},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "foo", "VALUE": 100, "F1": "blah", "F2": 50}, "timestamp": 13000},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "foo", "VALUE": 100, "F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "OUTPUT", "key": 90, "value": {"NAME": "ninety", "VALUE": 90, "F1": null, "F2": null}, "timestamp": 17000},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "bar", "VALUE": 99, "F1": null, "F2": null}, "timestamp": 30000}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "T_ID BIGINT KEY, NAME STRING, VALUE BIGINT, F1 STRING, F2 BIGINT"}
        ]
      }
    },
    {
      "name": "stream stream left join - rekey",
      "format": ["PROTOBUF", "PROTOBUF_NOSR"],
      "statements": [
        "CREATE STREAM TEST (K STRING KEY, ID bigint, NAME varchar, VALUE bigint) WITH (kafka_topic='left_topic', value_format='{FORMAT}');",
        "CREATE STREAM TEST_STREAM (K STRING KEY, ID bigint, F1 varchar, F2 bigint) WITH (kafka_topic='right_topic', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT as SELECT t.id, name, value, f1, f2 FROM test t left join TEST_STREAM tt WITHIN 11 seconds ON t.id = tt.id;"
      ],
      "inputs": [
        {"topic": "left_topic", "value": {"ID": 0, "NAME": "zero", "VALUE": 0}, "timestamp": 0},
        {"topic": "right_topic", "value": {"ID": 0, "F1": "blah", "F2": 50}, "timestamp": 10000},
        {"topic": "left_topic", "value": {"ID": 10, "NAME": "100", "VALUE": 5}, "timestamp": 11000},
        {"topic": "left_topic", "value": {"ID": 0, "NAME": "foo", "VALUE": 100}, "timestamp": 13000},
        {"topic": "right_topic", "value": {"ID": 0, "F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "right_topic", "value": {"ID": 100, "F1": "newblah", "F2": 150}, "timestamp": 16000},
        {"topic": "left_topic", "value": {"ID": 90, "NAME": "ninety", "VALUE": 90}, "timestamp": 17000},
        {"topic": "left_topic", "value": {"ID": 0, "NAME": "bar", "VALUE": 99}, "timestamp": 30000}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "zero", "VALUE": 0, "F1": "", "F2": 0}, "timestamp": 0},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "zero", "VALUE": 0, "F1": "blah", "F2": 50}, "timestamp": 10000},
        {"topic": "OUTPUT", "key": 10, "value": {"NAME": "100", "VALUE": 5, "F1": "", "F2": 0}, "timestamp": 11000},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "foo", "VALUE": 100, "F1": "blah", "F2": 50}, "timestamp": 13000},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "foo", "VALUE": 100, "F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "OUTPUT", "key": 90, "value": {"NAME": "ninety", "VALUE": 90, "F1": "", "F2": 0}, "timestamp": 17000},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "bar", "VALUE": 99, "F1": "", "F2": 0}, "timestamp": 30000}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "T_ID BIGINT KEY, NAME STRING, VALUE BIGINT, F1 STRING, F2 BIGINT"}
        ]
      }
    },
    {
      "name": "stream stream right join",
      "format": ["AVRO", "JSON"],
      "statements": [
        "CREATE STREAM TEST (id BIGINT KEY, name VARCHAR, value BIGINT) WITH (kafka_topic='left_topic', value_format='{FORMAT}');",
        "CREATE STREAM TEST_STREAM (id BIGINT KEY, f1 VARCHAR, f2 BIGINT) WITH (kafka_topic='right_topic', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT as SELECT t.id, name, value, f1, f2 FROM test t RIGHT JOIN TEST_STREAM tt WITHIN 11 seconds ON t.id = tt.id;"
      ],
      "inputs": [
        {"topic": "left_topic", "key": 0, "value": {"NAME": "zero", "VALUE": 0}, "timestamp": 0},
        {"topic": "right_topic", "key": 0, "value": {"F1": "blah", "F2": 50}, "timestamp": 10000},
        {"topic": "left_topic", "key": 10, "value": {"NAME": "100", "VALUE": 5}, "timestamp": 11000},
        {"topic": "left_topic", "key": 0, "value": {"NAME": "foo", "VALUE": 100}, "timestamp": 13000},
        {"topic": "right_topic", "key": 0, "value": {"F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "right_topic", "key": 100, "value": {"F1": "newblah", "F2": 150}, "timestamp": 16000},
        {"topic": "left_topic", "key": 90, "value": {"NAME": "ninety", "VALUE": 90}, "timestamp": 17000},
        {"topic": "left_topic", "key": 0, "value": {"NAME": "bar", "VALUE": 99}, "timestamp": 30000}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "zero", "VALUE": 0, "F1": "blah", "F2": 50}, "timestamp": 10000},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "foo", "VALUE": 100, "F1": "blah", "F2": 50}, "timestamp": 13000},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "foo", "VALUE": 100, "F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "OUTPUT", "key": 100, "value": {"NAME": null, "VALUE": null, "F1": "newblah", "F2": 150}, "timestamp": 16000}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "T_ID BIGINT KEY, NAME STRING, VALUE BIGINT, F1 STRING, F2 BIGINT"}
        ],
        "topics": {
          "blacklist": ".*-repartition"
        }
      }
    },
    {
      "name": "stream stream right join all fields",
      "statements": [
        "CREATE STREAM TEST (ID BIGINT KEY, NAME varchar, VALUE bigint) WITH (kafka_topic='left_topic', value_format='DELIMITED');",
        "CREATE STREAM TEST_STREAM (ID BIGINT KEY, F1 varchar, F2 bigint) WITH (kafka_topic='right_topic', value_format='DELIMITED');",
        "CREATE STREAM OUTPUT as SELECT * FROM test t RIGHT JOIN TEST_STREAM tt WITHIN 11 seconds ON t.id = tt.id;"
      ],
      "inputs": [
        {"topic": "left_topic", "key": 0, "value": "zero,0", "timestamp": 0},
        {"topic": "right_topic", "key": 0, "value": "blah,50", "timestamp": 10000},
        {"topic": "left_topic", "key": 10, "value": "100,5", "timestamp": 11000},
        {"topic": "left_topic", "key": 0, "value": "foo,100", "timestamp": 13000},
        {"topic": "right_topic", "key": 0, "value": "a,10", "timestamp": 15000},
        {"topic": "right_topic", "key": 100, "value": "newblah,150", "timestamp": 16000},
        {"topic": "left_topic", "key": 90, "value": "ninety,90", "timestamp": 17000},
        {"topic": "left_topic", "key": 0, "value": "bar,99", "timestamp": 30000}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 0, "value": "zero,0,0,blah,50", "timestamp": 10000},
        {"topic": "OUTPUT", "key": 0, "value": "foo,100,0,blah,50", "timestamp": 13000},
        {"topic": "OUTPUT", "key": 0, "value": "foo,100,0,a,10", "timestamp": 15000},
        {"topic": "OUTPUT", "key": 100, "value": ",,100,newblah,150", "timestamp": 16000}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "T_ID BIGINT KEY, T_NAME STRING, T_VALUE BIGINT, TT_ID BIGINT, TT_F1 STRING, TT_F2 BIGINT"}
        ],
        "topics": {
          "blacklist": ".*-repartition"
        }
      }
    },
    {
      "name": "stream stream right join - PROTOBUF",
      "format": ["PROTOBUF", "PROTOBUF_NOSR"],
      "statements": [
        "CREATE STREAM TEST (id BIGINT KEY, name VARCHAR, value BIGINT) WITH (kafka_topic='left_topic', value_format='{FORMAT}');",
        "CREATE STREAM TEST_STREAM (id BIGINT KEY, f1 VARCHAR, f2 BIGINT) WITH (kafka_topic='right_topic', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT as SELECT t.id, name, value, f1, f2 FROM test t RIGHT JOIN TEST_STREAM tt WITHIN 11 seconds ON t.id = tt.id;"
      ],
      "inputs": [
        {"topic": "left_topic", "key": 0, "value": {"NAME": "zero", "VALUE": 0}, "timestamp": 0},
        {"topic": "right_topic", "key": 0, "value": {"F1": "blah", "F2": 50}, "timestamp": 10000},
        {"topic": "left_topic", "key": 10, "value": {"NAME": "100", "VALUE": 5}, "timestamp": 11000},
        {"topic": "left_topic", "key": 0, "value": {"NAME": "foo", "VALUE": 100}, "timestamp": 13000},
        {"topic": "right_topic", "key": 0, "value": {"F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "right_topic", "key": 100, "value": {"F1": "newblah", "F2": 150}, "timestamp": 16000},
        {"topic": "left_topic", "key": 90, "value": {"NAME": "ninety", "VALUE": 90}, "timestamp": 17000},
        {"topic": "left_topic", "key": 0, "value": {"NAME": "bar", "VALUE": 99}, "timestamp": 30000}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "zero", "VALUE": 0, "F1": "blah", "F2": 50}, "timestamp": 10000},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "foo", "VALUE": 100, "F1": "blah", "F2": 50}, "timestamp": 13000},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "foo", "VALUE": 100, "F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "OUTPUT", "key": 100, "value": {"NAME": "", "VALUE": 0, "F1": "newblah", "F2": 150}, "timestamp": 16000}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "T_ID BIGINT KEY, NAME STRING, VALUE BIGINT, F1 STRING, F2 BIGINT"}
        ],
        "topics": {
          "blacklist": ".*-repartition"
        }
      }
    },
    {
      "name": "stream stream right join - KAFKA",
      "statements": [
        "CREATE STREAM S_LEFT (ID BIGINT KEY, NAME varchar) WITH (kafka_topic='left_topic', value_format='KAFKA');",
        "CREATE STREAM S_RIGHT (ID BIGINT KEY, NAME varchar) WITH (kafka_topic='right_topic', value_format='KAFKA');",
        "CREATE STREAM OUTPUT WITH(value_format='delimited') as SELECT * FROM s_left RIGHT JOIN s_right WITHIN 1 second ON s_left.id = s_right.id;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlStatementException",
        "message": "Source(s) S_LEFT, S_RIGHT are using the 'KAFKA' value format. This format does not yet support JOIN."
      }
    },
    {
      "name": "stream stream right join with key in projection - rekey",
      "format": ["AVRO", "JSON"],
      "statements": [
        "CREATE STREAM TEST (K STRING KEY, ID bigint, NAME varchar, VALUE bigint) WITH (kafka_topic='left_topic', value_format='{FORMAT}');",
        "CREATE STREAM TEST_STREAM (K STRING KEY, ID bigint, F1 varchar, F2 bigint) WITH (kafka_topic='right_topic', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT as SELECT t.id, t.k, name, value, f1, f2 FROM test t RIGHT JOIN test_stream tt WITHIN 11 seconds ON t.id = tt.id;"
      ],
      "inputs": [
        {"topic": "left_topic", "key": "foo", "value": {"ID": 0, "NAME": "zero", "VALUE": 0}, "timestamp": 0},
        {"topic": "right_topic", "key": "foo", "value": {"ID": 0, "F1": "blah", "F2": 50}, "timestamp": 10000},
        {"topic": "left_topic", "key": "foo", "value": {"ID": 10, "NAME": "100", "VALUE": 5}, "timestamp": 11000},
        {"topic": "left_topic", "key": "foo", "value": {"ID": 0, "NAME": "foo", "VALUE": 100}, "timestamp": 13000},
        {"topic": "right_topic", "key": "foo", "value": {"ID": 0, "F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "right_topic", "key": "foo", "value": {"ID": 100, "F1": "newblah", "F2": 150}, "timestamp": 16000},
        {"topic": "left_topic", "key": "foo", "value": {"ID": 90, "NAME": "ninety", "VALUE": 90}, "timestamp": 17000},
        {"topic": "left_topic", "key": "foo", "value": {"ID": 0, "NAME": "bar", "VALUE": 99}, "timestamp": 30000}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 0, "value": {"T_K": "foo", "NAME": "zero", "VALUE": 0, "F1": "blah", "F2": 50}, "timestamp": 10000},
        {"topic": "OUTPUT", "key": 0, "value": {"T_K": "foo", "NAME": "foo", "VALUE": 100, "F1": "blah", "F2": 50}, "timestamp": 13000},
        {"topic": "OUTPUT", "key": 0, "value": {"T_K": "foo", "NAME": "foo", "VALUE": 100, "F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "OUTPUT", "key": 100, "value": {"T_K": null, "NAME": null, "VALUE": null, "F1": "newblah", "F2": 150}, "timestamp": 16000}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "T_ID BIGINT KEY, T_K STRING, NAME STRING, VALUE BIGINT, F1 STRING, F2 BIGINT"}
        ]
      }
    },
    {
      "name": "stream stream right join with key in projection - rekey",
      "format": ["PROTOBUF", "PROTOBUF_NOSR"],
      "statements": [
        "CREATE STREAM TEST (K STRING KEY, ID bigint, NAME varchar, VALUE bigint) WITH (kafka_topic='left_topic', value_format='{FORMAT}');",
        "CREATE STREAM TEST_STREAM (K STRING KEY, ID bigint, F1 varchar, F2 bigint) WITH (kafka_topic='right_topic', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT as SELECT t.id, t.k, name, value, f1, f2 FROM test t RIGHT JOIN test_stream tt WITHIN 11 seconds ON t.id = tt.id;"
      ],
      "inputs": [
        {"topic": "left_topic", "key": "foo", "value": {"ID": 0, "NAME": "zero", "VALUE": 0}, "timestamp": 0},
        {"topic": "right_topic", "key": "foo", "value": {"ID": 0, "F1": "blah", "F2": 50}, "timestamp": 10000},
        {"topic": "left_topic", "key": "foo", "value": {"ID": 10, "NAME": "100", "VALUE": 5}, "timestamp": 11000},
        {"topic": "left_topic", "key": "foo", "value": {"ID": 0, "NAME": "foo", "VALUE": 100}, "timestamp": 13000},
        {"topic": "right_topic", "key": "foo", "value": {"ID": 0, "F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "right_topic", "key": "foo", "value": {"ID": 100, "F1": "newblah", "F2": 150}, "timestamp": 16000},
        {"topic": "left_topic", "key": "foo", "value": {"ID": 90, "NAME": "ninety", "VALUE": 90}, "timestamp": 17000},
        {"topic": "left_topic", "key": "foo", "value": {"ID": 0, "NAME": "bar", "VALUE": 99}, "timestamp": 30000}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 0, "value": {"T_K": "foo", "NAME": "zero", "VALUE": 0, "F1": "blah", "F2": 50}, "timestamp": 10000},
        {"topic": "OUTPUT", "key": 0, "value": {"T_K": "foo", "NAME": "foo", "VALUE": 100, "F1": "blah", "F2": 50}, "timestamp": 13000},
        {"topic": "OUTPUT", "key": 0, "value": {"T_K": "foo", "NAME": "foo", "VALUE": 100, "F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "OUTPUT", "key": 100, "value": {"T_K": "", "NAME": "", "VALUE": 0, "F1": "newblah", "F2": 150}, "timestamp": 16000}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "T_ID BIGINT KEY, T_K STRING, NAME STRING, VALUE BIGINT, F1 STRING, F2 BIGINT"}
        ]
      }
    },
    {
      "name": "stream stream right join - rekey",
      "format": ["AVRO", "JSON"],
      "statements": [
        "CREATE STREAM TEST (K STRING KEY, ID bigint, NAME varchar, VALUE bigint) WITH (kafka_topic='left_topic', value_format='{FORMAT}');",
        "CREATE STREAM TEST_STREAM (K STRING KEY, ID bigint, F1 varchar, F2 bigint) WITH (kafka_topic='right_topic', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT as SELECT t.id, name, value, f1, f2 FROM test t RIGHT JOIN test_stream tt WITHIN 11 seconds ON t.id = tt.id;"
      ],
      "inputs": [
        {"topic": "left_topic", "value": {"ID": 0, "NAME": "zero", "VALUE": 0}, "timestamp": 0},
        {"topic": "right_topic", "value": {"ID": 0, "F1": "blah", "F2": 50}, "timestamp": 10000},
        {"topic": "left_topic", "value": {"ID": 10, "NAME": "100", "VALUE": 5}, "timestamp": 11000},
        {"topic": "left_topic", "value": {"ID": 0, "NAME": "foo", "VALUE": 100}, "timestamp": 13000},
        {"topic": "right_topic", "value": {"ID": 0, "F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "right_topic", "value": {"ID": 100, "F1": "newblah", "F2": 150}, "timestamp": 16000},
        {"topic": "left_topic", "value": {"ID": 90, "NAME": "ninety", "VALUE": 90}, "timestamp": 17000},
        {"topic": "left_topic", "value": {"ID": 0, "NAME": "bar", "VALUE": 99}, "timestamp": 30000}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "zero", "VALUE": 0, "F1": "blah", "F2": 50}, "timestamp": 10000},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "foo", "VALUE": 100, "F1": "blah", "F2": 50}, "timestamp": 13000},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "foo", "VALUE": 100, "F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "OUTPUT", "key": 100, "value": {"NAME": null, "VALUE": null, "F1": "newblah", "F2": 150}, "timestamp": 16000}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "T_ID BIGINT KEY, NAME STRING, VALUE BIGINT, F1 STRING, F2 BIGINT"}
        ]
      }
    },
    {
      "name": "stream stream right join - rekey",
      "format": ["PROTOBUF", "PROTOBUF_NOSR"],
      "statements": [
        "CREATE STREAM TEST (K STRING KEY, ID bigint, NAME varchar, VALUE bigint) WITH (kafka_topic='left_topic', value_format='{FORMAT}');",
        "CREATE STREAM TEST_STREAM (K STRING KEY, ID bigint, F1 varchar, F2 bigint) WITH (kafka_topic='right_topic', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT as SELECT t.id, name, value, f1, f2 FROM test t RIGHT JOIN test_stream tt WITHIN 11 seconds ON t.id = tt.id;"
      ],
      "inputs": [
        {"topic": "left_topic", "value": {"ID": 0, "NAME": "zero", "VALUE": 0}, "timestamp": 0},
        {"topic": "right_topic", "value": {"ID": 0, "F1": "blah", "F2": 50}, "timestamp": 10000},
        {"topic": "left_topic", "value": {"ID": 10, "NAME": "100", "VALUE": 5}, "timestamp": 11000},
        {"topic": "left_topic", "value": {"ID": 0, "NAME": "foo", "VALUE": 100}, "timestamp": 13000},
        {"topic": "right_topic", "value": {"ID": 0, "F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "right_topic", "value": {"ID": 100, "F1": "newblah", "F2": 150}, "timestamp": 16000},
        {"topic": "left_topic", "value": {"ID": 90, "NAME": "ninety", "VALUE": 90}, "timestamp": 17000},
        {"topic": "left_topic", "value": {"ID": 0, "NAME": "bar", "VALUE": 99}, "timestamp": 30000}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "zero", "VALUE": 0, "F1": "blah", "F2": 50}, "timestamp": 10000},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "foo", "VALUE": 100, "F1": "blah", "F2": 50}, "timestamp": 13000},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "foo", "VALUE": 100, "F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "OUTPUT", "key": 100, "value": {"NAME": "", "VALUE": 0, "F1": "newblah", "F2": 150}, "timestamp": 16000}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "T_ID BIGINT KEY, NAME STRING, VALUE BIGINT, F1 STRING, F2 BIGINT"}
        ]
      }
    },
    {
      "name": "stream stream inner join",
      "format": ["AVRO", "JSON", "PROTOBUF", "PROTOBUF_NOSR"],
      "statements": [
        "CREATE STREAM TEST (ID BIGINT KEY, NAME varchar, VALUE bigint) WITH (kafka_topic='left_topic', value_format='{FORMAT}');",
        "CREATE STREAM TEST_STREAM (ID BIGINT KEY, F1 varchar, F2 bigint) WITH (kafka_topic='right_topic', value_format='{FORMAT}');",
        "CREATE STREAM INNER_JOIN as SELECT t.id as ID, name, value, f1, f2 FROM test t join TEST_STREAM tt WITHIN 11 SECONDS ON t.id = tt.id;"
      ],
      "inputs": [
        {"topic": "left_topic", "key": 0, "value": {"NAME": "zero", "VALUE": 0}, "timestamp": 0},
        {"topic": "right_topic", "key": 0, "value": {"F1": "blah", "F2": 50}, "timestamp": 10000},
        {"topic": "left_topic", "key": 10, "value": {"NAME": "100", "VALUE": 5}, "timestamp": 11000},
        {"topic": "left_topic", "key": 0, "value": {"NAME": "foo", "VALUE": 100}, "timestamp": 13000},
        {"topic": "right_topic", "key": 0, "value": {"F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "right_topic", "key": 100, "value": {"F1": "newblah", "F2": 150}, "timestamp": 16000},
        {"topic": "left_topic", "key": 90, "value": {"NAME": "ninety", "VALUE": 90}, "timestamp": 17000},
        {"topic": "left_topic", "key": 0, "value": {"NAME": "bar", "VALUE": 99}, "timestamp": 30000}
      ],
      "outputs": [
        {"topic": "INNER_JOIN", "key": 0, "value": {"NAME": "zero", "VALUE": 0, "F1": "blah", "F2": 50}, "timestamp": 10000},
        {"topic": "INNER_JOIN", "key": 0, "value": {"NAME": "foo", "VALUE": 100, "F1": "blah", "F2": 50}, "timestamp": 13000},
        {"topic": "INNER_JOIN", "key": 0, "value": {"NAME": "foo", "VALUE": 100, "F1": "a", "F2": 10}, "timestamp": 15000}
      ],
      "post": {
        "sources": [
          {"name": "INNER_JOIN", "type": "stream", "schema": "ID BIGINT KEY, NAME STRING, VALUE BIGINT, F1 STRING, F2 BIGINT"}
        ],
        "topics": {
          "blacklist": ".*-repartition"
        }
      }
    },
    {
      "name": "stream stream inner join all left fields some right",
      "format": ["AVRO", "JSON", "PROTOBUF", "PROTOBUF_NOSR"],
      "statements": [
        "CREATE STREAM TEST (ID BIGINT KEY, NAME varchar, VALUE bigint) WITH (kafka_topic='left_topic', value_format='{FORMAT}');",
        "CREATE STREAM TEST_STREAM (ID BIGINT KEY, F1 varchar, F2 bigint) WITH (kafka_topic='right_topic', value_format='{FORMAT}');",
        "CREATE STREAM INNER_JOIN as SELECT t.*, tt.f1 FROM test t inner join TEST_STREAM tt WITHIN 11 SECONDS ON t.id = tt.id;"
      ],
      "inputs": [
        {"topic": "left_topic", "key": 0, "value": {"NAME": "zero", "VALUE": 0}, "timestamp": 0},
        {"topic": "right_topic", "key": 0, "value": {"F1": "blah", "F2": 50}, "timestamp": 10000},
        {"topic": "left_topic", "key": 10, "value": {"NAME": "100", "VALUE": 5}, "timestamp": 11000},
        {"topic": "left_topic", "key": 0, "value": {"NAME": "foo", "VALUE": 100}, "timestamp": 13000},
        {"topic": "right_topic", "key": 0, "value": {"F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "right_topic", "key": 100, "value": {"F1": "newblah", "F2": 150}, "timestamp": 16000},
        {"topic": "left_topic", "key": 90, "value": {"NAME": "ninety", "VALUE": 90}, "timestamp": 17000},
        {"topic": "left_topic", "key": 0, "value": {"NAME": "bar", "VALUE": 99}, "timestamp": 30000}
      ],
      "outputs": [
        {"topic": "INNER_JOIN", "key": 0, "value": {"T_NAME": "zero", "T_VALUE": 0, "F1": "blah"}, "timestamp": 10000},
        {"topic": "INNER_JOIN", "key": 0, "value": {"T_NAME": "foo", "T_VALUE": 100, "F1": "blah"}, "timestamp": 13000},
        {"topic": "INNER_JOIN", "key": 0, "value": {"T_NAME": "foo", "T_VALUE": 100, "F1": "a"}, "timestamp": 15000}
      ],
      "post": {
        "sources": [
          {"name": "INNER_JOIN", "type": "stream", "schema": "T_ID BIGINT KEY, T_NAME STRING, T_VALUE BIGINT, F1 STRING"}
        ]
      }
    },
    {
      "name": "stream stream inner join all right fields some left",
      "format": ["AVRO", "JSON", "PROTOBUF", "PROTOBUF_NOSR"],
      "statements": [
        "CREATE STREAM TEST (ID BIGINT KEY, NAME varchar, VALUE bigint) WITH (kafka_topic='left_topic', value_format='{FORMAT}');",
        "CREATE STREAM TEST_STREAM (ID BIGINT KEY, F1 varchar, F2 bigint) WITH (kafka_topic='right_topic', value_format='{FORMAT}');",
        "CREATE STREAM INNER_JOIN as SELECT t.*, tt.name, tt.id FROM test tt inner join TEST_STREAM t WITHIN 11 SECONDS ON t.id = tt.id;"
      ],
      "inputs": [
        {"topic": "left_topic", "key": 0, "value": {"NAME": "zero", "VALUE": 0}, "timestamp": 0},
        {"topic": "right_topic", "key": 0, "value": {"F1": "blah", "F2": 50}, "timestamp": 10000},
        {"topic": "left_topic", "key": 10, "value": {"NAME": "100", "VALUE": 5}, "timestamp": 11000},
        {"topic": "left_topic", "key": 0, "value": {"NAME": "foo", "VALUE": 100}, "timestamp": 13000},
        {"topic": "right_topic", "key": 0, "value": {"F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "right_topic", "key": 100, "value": {"F1": "newblah", "F2": 150}, "timestamp": 16000},
        {"topic": "left_topic", "key": 90, "value": {"NAME": "ninety", "VALUE": 90}, "timestamp": 17000},
        {"topic": "left_topic", "key": 0, "value": {"NAME": "bar", "VALUE": 99}, "timestamp": 30000}
      ],
      "outputs": [
        {"topic": "INNER_JOIN", "key": 0, "value": {"T_ID": 0, "T_F1": "blah", "T_F2": 50, "NAME": "zero"}, "timestamp": 10000},
        {"topic": "INNER_JOIN", "key": 0, "value": {"T_ID": 0, "T_F1": "blah", "T_F2": 50, "NAME": "foo"}, "timestamp": 13000},
        {"topic": "INNER_JOIN", "key": 0, "value": {"T_ID": 0, "T_F1": "a", "T_F2": 10, "NAME": "foo"}, "timestamp": 15000}
      ],
      "post": {
        "sources": [
          {"name": "INNER_JOIN", "type": "stream", "schema": "TT_ID BIGINT KEY, T_ID BIGINT, T_F1 STRING, T_F2 BIGINT, NAME STRING"}
        ]
      }
    },
    {
      "name": "stream stream inner join with stars and duplicates",
      "statements": [
        "CREATE STREAM TEST (ID BIGINT KEY, NAME varchar, VALUE bigint) WITH (kafka_topic='left_topic', value_format='JSON');",
        "CREATE STREAM TEST_STREAM (ID BIGINT KEY, F1 varchar, F2 bigint) WITH (kafka_topic='right_topic', value_format='JSON');",
        "CREATE STREAM INNER_JOIN as SELECT t.*, t.F1 AS F1_2, tt.*, tt.NAME AS NAME_2 FROM test tt inner join TEST_STREAM t WITHIN 11 SECONDS ON t.id = tt.id;"
      ],
      "inputs": [
        {"topic": "left_topic", "key": 0, "value": {"NAME": "zero", "VALUE": 0}, "timestamp": 0},
        {"topic": "right_topic", "key": 0, "value": {"F1": "blah", "F2": 50}, "timestamp": 10000},
        {"topic": "left_topic", "key": 10, "value": {"NAME": "100", "VALUE": 5}, "timestamp": 11000},
        {"topic": "left_topic", "key": 0, "value": {"NAME": "foo", "VALUE": 100}, "timestamp": 13000},
        {"topic": "right_topic", "key": 0, "value": {"F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "right_topic", "key": 100, "value": {"F1": "newblah", "F2": 150}, "timestamp": 16000},
        {"topic": "left_topic", "key": 90, "value": {"NAME": "ninety", "VALUE": 90}, "timestamp": 17000},
        {"topic": "left_topic", "key": 0, "value": {"NAME": "bar", "VALUE": 99}, "timestamp": 30000}
      ],
      "outputs": [
        {"topic": "INNER_JOIN", "key": 0, "value": {"T_ID": 0, "T_F1": "blah", "T_F2": 50, "TT_NAME": "zero", "TT_VALUE": 0, "F1_2": "blah", "NAME_2": "zero"}, "timestamp": 10000},
        {"topic": "INNER_JOIN", "key": 0, "value": {"T_ID": 0, "T_F1": "blah", "T_F2": 50, "TT_NAME": "foo", "TT_VALUE": 100, "F1_2": "blah", "NAME_2": "foo"}, "timestamp": 13000},
        {"topic": "INNER_JOIN", "key": 0, "value": {"T_ID": 0, "T_F1": "a", "T_F2": 10, "TT_NAME": "foo", "TT_VALUE": 100, "F1_2": "a", "NAME_2": "foo"}, "timestamp": 15000}
      ],
      "post": {
        "sources": [
          {"name": "INNER_JOIN", "type": "stream", "schema": "TT_ID BIGINT KEY, T_ID BIGINT, T_F1 STRING, T_F2 BIGINT, F1_2 STRING, TT_NAME STRING, TT_VALUE BIGINT, NAME_2 STRING"}
        ]
      }
    },
    {
      "name": "stream stream inner join all fields",
      "format": ["AVRO", "JSON", "PROTOBUF", "PROTOBUF_NOSR"],
      "statements": [
        "CREATE STREAM TEST (ID BIGINT KEY, NAME varchar) WITH (kafka_topic='left_topic', value_format='{FORMAT}');",
        "CREATE STREAM TEST_STREAM (ID BIGINT KEY, F1 varchar) WITH (kafka_topic='right_topic', value_format='{FORMAT}');",
        "CREATE STREAM INNER_JOIN as SELECT * FROM test tt inner join TEST_STREAM t WITHIN 11 SECONDS ON t.id = tt.id;"
      ],
      "inputs": [
        {"topic": "left_topic", "key": 0, "value": {"NAME": "zero"}, "timestamp": 0},
        {"topic": "right_topic", "key": 0, "value": {"F1": "blah"}, "timestamp": 10000},
        {"topic": "left_topic", "key": 10, "value": {"NAME": "100"}, "timestamp": 11000},
        {"topic": "left_topic", "key": 0, "value": {"NAME": "foo"}, "timestamp": 13000},
        {"topic": "right_topic", "key": 0, "value": {"F1": "a"}, "timestamp": 15000},
        {"topic": "right_topic", "key": 100, "value": {"F1": "newblah"}, "timestamp": 16000},
        {"topic": "left_topic", "key": 90, "value": {"NAME": "ninety"}, "timestamp": 17000},
        {"topic": "left_topic", "key": 0, "value": {"NAME": "bar"}, "timestamp": 30000}
      ],
      "outputs": [
        {"topic": "INNER_JOIN", "key": 0, "value": {"T_ID": 0, "T_F1": "blah", "TT_NAME": "zero"}, "timestamp": 10000},
        {"topic": "INNER_JOIN", "key": 0, "value": {"T_ID": 0, "T_F1": "blah", "TT_NAME": "foo"}, "timestamp": 13000},
        {"topic": "INNER_JOIN", "key": 0, "value": {"T_ID": 0, "T_F1": "a", "TT_NAME": "foo"}, "timestamp": 15000}
      ],
      "post": {
        "sources": [
          {"name": "INNER_JOIN", "type": "stream", "schema": "TT_ID BIGINT KEY, TT_NAME STRING, T_ID BIGINT, T_F1 STRING"}
        ]
      }
    },
    {
      "name": "stream stream inner join with different before and after windows",
      "format": ["AVRO", "JSON", "PROTOBUF", "PROTOBUF_NOSR"],
      "statements": [
        "CREATE STREAM TEST (ID BIGINT KEY, NAME varchar, VALUE bigint) WITH (kafka_topic='left_topic', value_format='{FORMAT}');",
        "CREATE STREAM TEST_STREAM (ID BIGINT KEY, F1 varchar, F2 bigint) WITH (kafka_topic='right_topic', value_format='{FORMAT}');",
        "CREATE STREAM INNER_JOIN as SELECT t.id, name, value, f1, f2 FROM test t join TEST_STREAM tt WITHIN (11 seconds, 10 seconds) on t.id = tt.id;"
      ],
      "inputs": [
        {"topic": "left_topic", "key": 0, "value": {"NAME": "zero", "VALUE": 0}, "timestamp": 0},
        {"topic": "right_topic", "key": 0, "value": {"F1": "blah", "F2": 50}, "timestamp": 11000},
        {"topic": "left_topic", "key": 10, "value": {"NAME": "100", "VALUE": 5}, "timestamp": 12000},
        {"topic": "left_topic", "key": 0, "value": {"NAME": "foo", "VALUE": 100}, "timestamp": 13000},
        {"topic": "right_topic", "key": 0, "value": {"F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "right_topic", "key": 100, "value": {"F1": "newblah", "F2": 150}, "timestamp": 16000},
        {"topic": "left_topic", "key": 90, "value": {"NAME": "ninety", "VALUE": 90}, "timestamp": 17000},
        {"topic": "left_topic", "key": 0, "value": {"NAME": "bar", "VALUE": 99}, "timestamp": 30000}
      ],
      "outputs": [
        {"topic": "INNER_JOIN", "key": 0, "value": {"NAME": "foo", "VALUE": 100, "F1": "blah", "F2": 50}, "timestamp": 13000},
        {"topic": "INNER_JOIN", "key": 0, "value": {"NAME": "foo", "VALUE": 100, "F1": "a", "F2": 10}, "timestamp": 15000}
      ],
      "post": {
        "sources": [
          {"name": "INNER_JOIN", "type": "stream", "schema": "T_ID BIGINT KEY, NAME STRING, VALUE BIGINT, F1 STRING, F2 BIGINT"}
        ]
      }
    },
    {
      "name": "stream stream inner join with out of order messages",
      "format": ["AVRO", "JSON", "PROTOBUF", "PROTOBUF_NOSR"],
      "statements": [
        "CREATE STREAM TEST (ID BIGINT KEY, NAME varchar, VALUE bigint) WITH (kafka_topic='left_topic', value_format='{FORMAT}');",
        "CREATE STREAM TEST_STREAM (ID BIGINT KEY, F1 varchar, F2 bigint) WITH (kafka_topic='right_topic', value_format='{FORMAT}');",
        "CREATE STREAM INNER_JOIN as SELECT t.id, name, value, f1, f2 FROM test t join TEST_STREAM tt WITHIN 10 seconds on t.id = tt.id;"
      ],
      "inputs": [
        {"topic": "left_topic", "key": 0, "value": {"NAME": "zero", "VALUE": 0}, "timestamp": 0},
        {"topic": "right_topic", "key": 0, "value": {"F1": "blah", "F2": 50}, "timestamp": 9999},
        {"topic": "left_topic", "key": 10, "value": {"NAME": "100", "VALUE": 5}, "timestamp": 11000},
        {"topic": "left_topic", "key": 0, "value": {"NAME": "foo", "VALUE": 100}, "timestamp": 13000},
        {"topic": "right_topic", "key": 0, "value": {"F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "right_topic", "key": 100, "value": {"F1": "newblah", "F2": 150}, "timestamp": 16000},
        {"topic": "left_topic", "key": 90, "value": {"NAME": "ninety", "VALUE": 90}, "timestamp": 17000},
        {"topic": "left_topic", "key": 0, "value": {"NAME": "bar", "VALUE": 99}, "timestamp": 30000},
        {"topic": "left_topic", "key": 0, "value": {"NAME": "late-message", "VALUE": 10000}, "timestamp": 6000}
      ],
      "outputs": [
        {"topic": "INNER_JOIN", "key": 0, "value": {"NAME": "zero", "VALUE": 0, "F1": "blah", "F2": 50}, "timestamp": 9999},
        {"topic": "INNER_JOIN", "key": 0, "value": {"NAME": "foo", "VALUE": 100, "F1": "blah", "F2": 50}, "timestamp": 13000},
        {"topic": "INNER_JOIN", "key": 0, "value": {"NAME": "foo", "VALUE": 100, "F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "INNER_JOIN", "key": 0, "value": {"NAME": "late-message", "VALUE": 10000, "F1": "blah", "F2": 50}, "timestamp": 9999},
        {"topic": "INNER_JOIN", "key": 0, "value": {"NAME": "late-message", "VALUE": 10000, "F1": "a", "F2": 10}, "timestamp": 15000}
      ],
      "post": {
        "sources": [
          {"name": "INNER_JOIN", "type": "stream", "schema": "T_ID BIGINT KEY, NAME STRING, VALUE BIGINT, F1 STRING, F2 BIGINT"}
        ]
      }
    },
    {
      "name": "stream stream inner join with out of order and custom grace period",
      "format": ["AVRO", "JSON", "PROTOBUF", "PROTOBUF_NOSR"],
      "statements": [
        "CREATE STREAM LEFT_STREAM (id BIGINT KEY, l1 VARCHAR) WITH (kafka_topic='left_topic', value_format='{FORMAT}');",
        "CREATE STREAM RIGHT_STREAM (id BIGINT KEY, l2 VARCHAR) WITH (kafka_topic='right_topic', value_format='{FORMAT}');",
        "CREATE STREAM INNER_JOIN as SELECT t.id, l1, l2 FROM LEFT_STREAM t join RIGHT_STREAM tt WITHIN 1 minute GRACE PERIOD 1 minute on t.id = tt.id;"
      ],
      "inputs": [
        {"topic": "left_topic", "key": 0, "value": {"L1": "A"}, "timestamp": 0},
        {"topic": "right_topic", "key": 0, "value": {"L2": "a"}, "timestamp": 60000},
        {"topic": "left_topic", "key": 1, "value": {"L1": "B"}, "timestamp": 330000},
        {"topic": "left_topic", "key": 2, "value": {"L1": "C"}, "timestamp": 90000},
        {"topic": "right_topic", "key": 2, "value": {"L2": "c"}, "timestamp": 90000},
        {"topic": "left_topic", "key": 3, "value": {"L1": "D"}, "timestamp": 60000},
        {"topic": "right_topic", "key": 3, "value": {"L2": "d"}, "timestamp": 60000}
      ],
      "outputs": [
        {"topic": "INNER_JOIN", "key": 0, "value": {"L1": "A", "L2": "a"}, "timestamp": 60000},
        {"topic": "INNER_JOIN", "key": 2, "value": {"L1": "C", "L2": "c"}, "timestamp": 90000}
      ]
    },
    {
      "name": "stream stream left join with out of order and custom grace period",
      "format": ["AVRO", "JSON"],
      "statements": [
        "CREATE STREAM LEFT_STREAM (id BIGINT KEY, l1 VARCHAR) WITH (kafka_topic='left_topic', value_format='{FORMAT}');",
        "CREATE STREAM RIGHT_STREAM (id BIGINT KEY, l2 VARCHAR) WITH (kafka_topic='right_topic', value_format='{FORMAT}');",
        "CREATE STREAM LEFT_JOIN as SELECT t.id, l1, l2 FROM LEFT_STREAM t left join RIGHT_STREAM tt WITHIN 1 minute GRACE PERIOD 1 minute on t.id = tt.id;"
      ],
      "inputs": [
        {"topic": "left_topic", "key": 0, "value": {"L1": "A"}, "timestamp": 0},
        {"topic": "right_topic", "key": 0, "value": {"L2": "a"}, "timestamp": 60000},
        {"topic": "left_topic", "key": 1, "value": {"L1": "B"}, "timestamp": 330000},
        {"topic": "left_topic", "key": 2, "value": {"L1": "C"}, "timestamp": 90000},
        {"topic": "right_topic", "key": 2, "value": {"L2": "c"}, "timestamp": 90000},
        {"topic": "left_topic", "key": 3, "value": {"L1": "D"}, "timestamp": 60000},
        {"topic": "right_topic", "key": 3, "value": {"L2": "d"}, "timestamp": 60000}
      ],
      "outputs": [
        {"topic": "LEFT_JOIN", "key": 0, "value": {"L1": "A", "L2": "a"}, "timestamp": 60000},
        {"topic": "LEFT_JOIN", "key": 2, "value": {"L1": "C", "L2": null}, "timestamp": 90000},
        {"topic": "LEFT_JOIN", "key": 2, "value": {"L1": "C", "L2": "c"}, "timestamp": 90000},
        {"topic": "LEFT_JOIN", "key": 3, "value": {"L1": "D", "L2": null}, "timestamp": 60000}
      ]
    },
    {
      "name": "stream stream right join with out of order and custom grace period",
      "format": ["AVRO", "JSON"],
      "statements": [
        "CREATE STREAM LEFT_STREAM (id BIGINT KEY, l1 VARCHAR) WITH (kafka_topic='left_topic', value_format='{FORMAT}');",
        "CREATE STREAM RIGHT_STREAM (id BIGINT KEY, l2 VARCHAR) WITH (kafka_topic='right_topic', value_format='{FORMAT}');",
        "CREATE STREAM RIGHT_JOIN as SELECT t.id, l1, l2 FROM LEFT_STREAM t RIGHT JOIN RIGHT_STREAM tt WITHIN 1 minute GRACE PERIOD 1 minute on t.id = tt.id;"
      ],
      "inputs": [
        {"topic": "left_topic", "key": 0, "value": {"L1": "A"}, "timestamp": 0},
        {"topic": "right_topic", "key": 0, "value": {"L2": "a"}, "timestamp": 60000},
        {"topic": "left_topic", "key": 1, "value": {"L1": "B"}, "timestamp": 330000},
        {"topic": "left_topic", "key": 2, "value": {"L1": "C"}, "timestamp": 90000},
        {"topic": "right_topic", "key": 2, "value": {"L2": "c"}, "timestamp": 90000},
        {"topic": "right_topic", "key": 3, "value": {"L2": "d"}, "timestamp": 60000},
        {"topic": "left_topic", "key": 3, "value": {"L1": "D"}, "timestamp": 90000}
      ],
      "outputs": [
        {"topic": "RIGHT_JOIN", "key": 0, "value": {"L1": "A", "L2": "a"}, "timestamp": 60000},
        {"topic": "RIGHT_JOIN", "key": 2, "value": {"L1": "C", "L2": "c"}, "timestamp": 90000},
        {"topic": "RIGHT_JOIN", "key": 3, "value": {"L1": null, "L2": "d"}, "timestamp": 60000},
        {"topic": "RIGHT_JOIN", "key": 3, "value": {"L1": "D", "L2": "d"}, "timestamp": 90000}
      ]
    },
    {
      "name": "stream stream full outer join with out of order and custom grace period",
      "format": ["AVRO", "JSON"],
      "statements": [
        "CREATE STREAM LEFT_STREAM (id BIGINT KEY, l1 VARCHAR) WITH (kafka_topic='left_topic', value_format='{FORMAT}');",
        "CREATE STREAM RIGHT_STREAM (id BIGINT KEY, l2 VARCHAR) WITH (kafka_topic='right_topic', value_format='{FORMAT}');",
        "CREATE STREAM OUTER_JOIN as SELECT ROWKEY as ID, t.id, tt.id, l1, l2 FROM LEFT_STREAM t full outer join RIGHT_STREAM tt WITHIN 1 minute GRACE PERIOD 1 minute on t.id = tt.id;"
      ],
      "inputs": [
        {"topic": "left_topic", "key": 0, "value": {"L1": "A"}, "timestamp": 0},
        {"topic": "right_topic", "key": 0, "value": {"L2": "a"}, "timestamp": 60000},
        {"topic": "right_topic", "key": 1, "value": {"L2": "b"}, "timestamp": 330000},
        {"topic": "right_topic", "key": 2, "value": {"L2": "c"}, "timestamp": 90000},
        {"topic": "left_topic", "key": 2, "value": {"L1": "C"}, "timestamp": 90000},
        {"topic": "right_topic", "key": 3, "value": {"L2": "d"}, "timestamp": 60000},
        {"topic": "left_topic", "key": 3, "value": {"L1": "D"}, "timestamp": 60000}
      ],
      "outputs": [
        {"topic": "OUTER_JOIN", "key": 0, "value": {"T_ID": 0, "TT_ID": 0, "L1": "A", "L2": "a"}, "timestamp": 60000},
        {"topic": "OUTER_JOIN", "key": 2, "value": {"T_ID": null, "TT_ID": 2, "L1": null, "L2": "c"}, "timestamp": 90000},
        {"topic": "OUTER_JOIN", "key": 2, "value": {"T_ID": 2, "TT_ID": 2, "L1": "C", "L2": "c"}, "timestamp": 90000},
        {"topic": "OUTER_JOIN", "key": 3, "value": {"T_ID": null, "TT_ID": 3, "L1": null, "L2": "d"}, "timestamp": 60000},
        {"topic": "OUTER_JOIN", "key": 3, "value": {"T_ID": 3, "TT_ID": null, "L1": "D", "L2": null}, "timestamp": 60000}
      ]
    },
    {
      "name": "stream stream outer join",
      "format": ["AVRO", "JSON"],
      "statements": [
        "CREATE STREAM TEST (ID BIGINT KEY, NAME varchar, VALUE bigint) WITH (kafka_topic='left_topic', value_format='{FORMAT}');",
        "CREATE STREAM TEST_STREAM (ID BIGINT KEY, F1 varchar, F2 bigint) WITH (kafka_topic='right_topic', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT as SELECT * FROM test t FULL OUTER join TEST_STREAM tt WITHIN 11 seconds on t.id = tt.id;"
      ],
      "inputs": [
        {"topic": "left_topic", "key": 0, "value": {"NAME": "zero", "VALUE": 0}, "timestamp": 0},
        {"topic": "right_topic", "key": 0, "value": {"F1": "blah", "F2": 50}, "timestamp": 10000},
        {"topic": "left_topic", "key": 10, "value": {"NAME": "100", "VALUE": 5}, "timestamp": 11000},
        {"topic": "left_topic", "key": 0, "value": {"NAME": "foo", "VALUE": 100}, "timestamp": 13000},
        {"topic": "right_topic", "key": 0, "value": {"F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "left_topic", "key": 0, "value": {"NAME": "bar", "VALUE": 99}, "timestamp": 30000},
        {"topic": "left_topic", "key": 90, "value": {"NAME": "ninety", "VALUE": 90}, "timestamp": 17000},
        {"topic": "right_topic", "key": 100, "value": {"F1": "newblah", "F2": 150}, "timestamp": 20000}

      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 0, "value": {"T_ID": 0, "T_NAME": "zero", "T_VALUE": 0, "TT_ID": null, "TT_F1": null, "TT_F2": null}, "timestamp": 0},
        {"topic": "OUTPUT", "key": 0, "value": {"T_ID": 0, "T_NAME": "zero", "T_VALUE": 0, "TT_ID": 0, "TT_F1": "blah", "TT_F2": 50}, "timestamp": 10000},
        {"topic": "OUTPUT", "key": 10, "value": {"T_ID": 10, "T_NAME": "100", "T_VALUE": 5, "TT_ID": null, "TT_F1": null, "TT_F2": null}, "timestamp": 11000},
        {"topic": "OUTPUT", "key": 0, "value": {"T_ID": 0, "T_NAME": "foo", "T_VALUE": 100, "TT_ID": 0, "TT_F1": "blah", "TT_F2": 50}, "timestamp": 13000},
        {"topic": "OUTPUT", "key": 0, "value": {"T_ID": 0, "T_NAME": "foo", "T_VALUE": 100, "TT_ID": 0, "TT_F1": "a", "TT_F2": 10}, "timestamp": 15000},
        {"topic": "OUTPUT", "key": 0, "value": {"T_ID": 0, "T_NAME": "bar", "T_VALUE": 99, "TT_ID": null, "TT_F1": null, "TT_F2": null}, "timestamp": 30000},
        {"topic": "OUTPUT", "key": 90, "value": {"T_ID": 90, "T_NAME": "ninety", "T_VALUE": 90, "TT_ID": null, "TT_F1": null, "TT_F2": null}, "timestamp": 17000},
        {"topic": "OUTPUT", "key": 100, "value": {"T_ID": null, "T_NAME": null, "T_VALUE": null, "TT_ID": 100, "TT_F1": "newblah", "TT_F2": 150}, "timestamp": 20000}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "ROWKEY BIGINT KEY, T_ID BIGINT, T_NAME STRING, T_VALUE BIGINT, TT_ID BIGINT, TT_F1 STRING, TT_F2 BIGINT"}
        ],
        "topics": {
          "blacklist": ".*-repartition"
        }
      }
    },
    {
      "name": "stream stream outer join - PROTOBUF",
      "format": ["PROTOBUF", "PROTOBUF_NOSR"],
      "statements": [
        "CREATE STREAM TEST (ID BIGINT KEY, NAME varchar, VALUE bigint) WITH (kafka_topic='left_topic', value_format='{FORMAT}');",
        "CREATE STREAM TEST_STREAM (ID BIGINT KEY, F1 varchar, F2 bigint) WITH (kafka_topic='right_topic', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT as SELECT ROWKEY as ID, name, value, f1, f2 FROM test t FULL OUTER join TEST_STREAM tt WITHIN 11 seconds on t.id = tt.id;"
      ],
      "inputs": [
        {"topic": "left_topic", "key": 0, "value": {"NAME": "zero", "VALUE": 0}, "timestamp": 0},
        {"topic": "right_topic", "key": 0, "value": {"F1": "blah", "F2": 50}, "timestamp": 10000},
        {"topic": "left_topic", "key": 10, "value": {"NAME": "100", "VALUE": 5}, "timestamp": 11000},
        {"topic": "left_topic", "key": 0, "value": {"NAME": "foo", "VALUE": 100}, "timestamp": 13000},
        {"topic": "right_topic", "key": 0, "value": {"F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "left_topic", "key": 0, "value": {"NAME": "bar", "VALUE": 99}, "timestamp": 30000},
        {"topic": "left_topic", "key": 90, "value": {"NAME": "ninety", "VALUE": 90}, "timestamp": 17000},
        {"topic": "right_topic", "key": 100, "value": {"F1": "newblah", "F2": 150}, "timestamp": 20000}

      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "zero", "VALUE": 0, "F1": "", "F2": 0}, "timestamp": 0},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "zero", "VALUE": 0, "F1": "blah", "F2": 50}, "timestamp": 10000},
        {"topic": "OUTPUT", "key": 10, "value": {"NAME": "100", "VALUE": 5, "F1": "", "F2": 0}, "timestamp": 11000},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "foo", "VALUE": 100, "F1": "blah", "F2": 50}, "timestamp": 13000},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "foo", "VALUE": 100, "F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "bar", "VALUE": 99, "F1": "", "F2": 0}, "timestamp": 30000},
        {"topic": "OUTPUT", "key": 90, "value": {"NAME": "ninety", "VALUE": 90, "F1": "", "F2": 0}, "timestamp": 17000},
        {"topic": "OUTPUT", "key": 100, "value": {"NAME": "", "VALUE": 0, "F1": "newblah", "F2": 150}, "timestamp": 20000}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "ID BIGINT KEY, `NAME` STRING, `VALUE` BIGINT, `F1` STRING, `F2` BIGINT"}
        ],
        "topics": {
          "blacklist": ".*-repartition"
        }
      }
    },
    {
      "name": "table table left join",
      "format": ["AVRO", "JSON"],
      "statements": [
        "CREATE TABLE TEST (id BIGINT PRIMARY KEY, name VARCHAR, value BIGINT) WITH (kafka_topic='left_topic', value_format='{FORMAT}');",
        "CREATE TABLE TEST_TABLE (id BIGINT PRIMARY KEY, f1 VARCHAR, f2 BIGINT) WITH (kafka_topic='right_topic', value_format='{FORMAT}');",
        "CREATE TABLE OUTPUT as SELECT t.id, name, value, f1, f2 FROM test t left join TEST_TABLE tt on t.id = tt.id;"
      ],
      "inputs": [
        {"topic": "left_topic", "key": 0, "value": {"NAME": "zero", "VALUE": 0}, "timestamp": 0},
        {"topic": "right_topic", "key": 0, "value": {"F1": "blah", "F2": 50}, "timestamp": 10000},
        {"topic": "left_topic", "key": 10, "value": {"NAME": "100", "VALUE": 5}, "timestamp": 11000},
        {"topic": "left_topic", "key": 0, "value": {"NAME": "foo", "VALUE": 100}, "timestamp": 13000},
        {"topic": "right_topic", "key": 0, "value": {"F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "left_topic", "key": 0, "value": {"NAME": "bar", "VALUE": 99}, "timestamp": 16000},
        {"topic": "left_topic", "key": 90, "value": {"NAME": "ninety", "VALUE": 90}, "timestamp": 17000}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "zero", "VALUE": 0, "F1": null, "F2": null}, "timestamp": 0},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "zero", "VALUE": 0, "F1": "blah", "F2": 50}, "timestamp": 10000},
        {"topic": "OUTPUT", "key": 10, "value": {"NAME": "100", "VALUE": 5, "F1": null, "F2": null}, "timestamp": 11000},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "foo", "VALUE": 100, "F1": "blah", "F2": 50}, "timestamp": 13000},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "foo", "VALUE": 100, "F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "bar", "VALUE": 99, "F1": "a", "F2": 10}, "timestamp": 16000},
        {"topic": "OUTPUT", "key": 90, "value": {"NAME": "ninety", "VALUE": 90, "F1": null, "F2": null}, "timestamp": 17000}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "table", "schema": "`T_ID` BIGINT KEY, `NAME` STRING, `VALUE` BIGINT, `F1` STRING, `F2` BIGINT"}
        ],
        "topics": {
          "blacklist": ".*-repartition"
        }
      }
    },
    {
      "name": "table table left join - PROTOBUF",
      "format": ["PROTOBUF", "PROTOBUF_NOSR"],
      "statements": [
        "CREATE TABLE TEST (id BIGINT PRIMARY KEY, name VARCHAR, value BIGINT) WITH (kafka_topic='left_topic', value_format='{FORMAT}');",
        "CREATE TABLE TEST_TABLE (id BIGINT PRIMARY KEY, f1 VARCHAR, f2 BIGINT) WITH (kafka_topic='right_topic', value_format='{FORMAT}');",
        "CREATE TABLE OUTPUT as SELECT t.id, name, value, f1, f2 FROM test t left join TEST_TABLE tt on t.id = tt.id;"
      ],
      "inputs": [
        {"topic": "left_topic", "key": 0, "value": {"NAME": "zero", "VALUE": 0}, "timestamp": 0},
        {"topic": "right_topic", "key": 0, "value": {"F1": "blah", "F2": 50}, "timestamp": 10000},
        {"topic": "left_topic", "key": 10, "value": {"NAME": "100", "VALUE": 5}, "timestamp": 11000},
        {"topic": "left_topic", "key": 0, "value": {"NAME": "foo", "VALUE": 100}, "timestamp": 13000},
        {"topic": "right_topic", "key": 0, "value": {"F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "left_topic", "key": 0, "value": {"NAME": "bar", "VALUE": 99}, "timestamp": 16000},
        {"topic": "left_topic", "key": 90, "value": {"NAME": "ninety", "VALUE": 90}, "timestamp": 17000}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "zero", "VALUE": 0, "F1": "", "F2": 0}, "timestamp": 0},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "zero", "VALUE": 0, "F1": "blah", "F2": 50}, "timestamp": 10000},
        {"topic": "OUTPUT", "key": 10, "value": {"NAME": "100", "VALUE": 5, "F1": "", "F2": 0}, "timestamp": 11000},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "foo", "VALUE": 100, "F1": "blah", "F2": 50}, "timestamp": 13000},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "foo", "VALUE": 100, "F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "bar", "VALUE": 99, "F1": "a", "F2": 10}, "timestamp": 16000},
        {"topic": "OUTPUT", "key": 90, "value": {"NAME": "ninety", "VALUE": 90, "F1": "", "F2": 0}, "timestamp": 17000}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "table", "schema": "`T_ID` BIGINT KEY, `NAME` STRING, `VALUE` BIGINT, `F1` STRING, `F2` BIGINT"}
        ],
        "topics": {
          "blacklist": ".*-repartition"
        }
      }
    },
    {
      "name": "table table right join",
      "format": ["AVRO", "JSON"],
      "statements": [
        "CREATE TABLE TEST (id BIGINT PRIMARY KEY, name VARCHAR, value BIGINT) WITH (kafka_topic='left_topic', value_format='{FORMAT}');",
        "CREATE TABLE TEST_TABLE (id BIGINT PRIMARY KEY, f1 VARCHAR, f2 BIGINT) WITH (kafka_topic='right_topic', value_format='{FORMAT}');",
        "CREATE TABLE OUTPUT AS SELECT t.id, name, value, f1, f2 FROM test t RIGHT JOIN test_table tt ON t.id = tt.id;"
      ],
      "inputs": [
        {"topic": "left_topic", "key": 0, "value": {"NAME": "zero", "VALUE": 0}, "timestamp": 0},
        {"topic": "right_topic", "key": 0, "value": {"F1": "blah", "F2": 50}, "timestamp": 10000},
        {"topic": "left_topic", "key": 10, "value": {"NAME": "100", "VALUE": 5}, "timestamp": 11000},
        {"topic": "left_topic", "key": 0, "value": {"NAME": "foo", "VALUE": 100}, "timestamp": 13000},
        {"topic": "right_topic", "key": 0, "value": {"F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "left_topic", "key": 0, "value": {"NAME": "bar", "VALUE": 99}, "timestamp": 16000},
        {"topic": "left_topic", "key": 90, "value": {"NAME": "ninety", "VALUE": 90}, "timestamp": 17000},
        {"topic": "right_topic", "key": 7, "value": {"F1": "b", "F2": 20}, "timestamp": 18000}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "zero", "VALUE": 0, "F1": "blah", "F2": 50}, "timestamp": 10000},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "foo", "VALUE": 100, "F1": "blah", "F2": 50}, "timestamp": 13000},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "foo", "VALUE": 100, "F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "bar", "VALUE": 99, "F1": "a", "F2": 10}, "timestamp": 16000},
        {"topic": "OUTPUT", "key": 7, "value": {"NAME": null, "VALUE": null, "F1": "b", "F2": 20}, "timestamp": 18000}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "table", "schema": "`T_ID` BIGINT KEY, `NAME` STRING, `VALUE` BIGINT, `F1` STRING, `F2` BIGINT"}
        ],
        "topics": {
          "blacklist": ".*-repartition"
        }
      }
    },
    {
      "name": "table table right join - PROTOBUF",
      "format": ["PROTOBUF", "PROTOBUF_NOSR"],
      "statements": [
        "CREATE TABLE TEST (id BIGINT PRIMARY KEY, name VARCHAR, value BIGINT) WITH (kafka_topic='left_topic', value_format='{FORMAT}');",
        "CREATE TABLE TEST_TABLE (id BIGINT PRIMARY KEY, f1 VARCHAR, f2 BIGINT) WITH (kafka_topic='right_topic', value_format='{FORMAT}');",
        "CREATE TABLE OUTPUT AS SELECT t.id, name, value, f1, f2 FROM test t RIGHT JOIN test_table tt ON t.id = tt.id;"
      ],
      "inputs": [
        {"topic": "left_topic", "key": 0, "value": {"NAME": "zero", "VALUE": 0}, "timestamp": 0},
        {"topic": "right_topic", "key": 0, "value": {"F1": "blah", "F2": 50}, "timestamp": 10000},
        {"topic": "left_topic", "key": 10, "value": {"NAME": "100", "VALUE": 5}, "timestamp": 11000},
        {"topic": "left_topic", "key": 0, "value": {"NAME": "foo", "VALUE": 100}, "timestamp": 13000},
        {"topic": "right_topic", "key": 0, "value": {"F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "left_topic", "key": 0, "value": {"NAME": "bar", "VALUE": 99}, "timestamp": 16000},
        {"topic": "left_topic", "key": 90, "value": {"NAME": "ninety", "VALUE": 90}, "timestamp": 17000},
        {"topic": "right_topic", "key": 7, "value": {"F1": "b", "F2": 20}, "timestamp": 18000}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "zero", "VALUE": 0, "F1": "blah", "F2": 50}, "timestamp": 10000},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "foo", "VALUE": 100, "F1": "blah", "F2": 50}, "timestamp": 13000},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "foo", "VALUE": 100, "F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "bar", "VALUE": 99, "F1": "a", "F2": 10}, "timestamp": 16000},
        {"topic": "OUTPUT", "key": 7, "value": {"NAME": "", "VALUE": 0, "F1": "b", "F2": 20}, "timestamp": 18000}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "table", "schema": "`T_ID` BIGINT KEY, `NAME` STRING, `VALUE` BIGINT, `F1` STRING, `F2` BIGINT"}
        ],
        "topics": {
          "blacklist": ".*-repartition"
        }
      }
    },
    {
      "name": "table table right join all fields",
      "statements": [
        "CREATE TABLE TEST (id BIGINT PRIMARY KEY, name VARCHAR, value BIGINT) WITH (kafka_topic='left_topic', value_format='DELIMITED');",
        "CREATE TABLE TEST_TABLE (id BIGINT PRIMARY KEY, f1 VARCHAR, f2 BIGINT) WITH (kafka_topic='right_topic', value_format='DELIMITED');",
        "CREATE TABLE OUTPUT AS SELECT * FROM test t RIGHT JOIN test_table tt ON t.id = tt.id;"
      ],
      "inputs": [
        {"topic": "left_topic", "key": 0, "value": "zero,0", "timestamp": 0},
        {"topic": "right_topic", "key": 0, "value": "blah,50", "timestamp": 10000},
        {"topic": "left_topic", "key": 10, "value": "100,5", "timestamp": 11000},
        {"topic": "left_topic", "key": 0, "value": "foo,100", "timestamp": 13000},
        {"topic": "right_topic", "key": 0, "value": "a,10", "timestamp": 15000},
        {"topic": "right_topic", "key": 100, "value": "newblah,150", "timestamp": 16000},
        {"topic": "left_topic", "key": 90, "value": "ninety,90", "timestamp": 17000}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 0, "value": "zero,0,0,blah,50", "timestamp": 10000},
        {"topic": "OUTPUT", "key": 0, "value": "foo,100,0,blah,50", "timestamp": 13000},
        {"topic": "OUTPUT", "key": 0, "value": "foo,100,0,a,10", "timestamp": 15000},
        {"topic": "OUTPUT", "key": 100, "value": ",,100,newblah,150", "timestamp": 16000}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "table", "schema": "T_ID BIGINT KEY, T_NAME STRING, T_VALUE BIGINT, TT_ID BIGINT, TT_F1 STRING, TT_F2 BIGINT"}
        ],
        "topics": {
          "blacklist": ".*-repartition"
        }
      }
    },
    {
      "name": "table table inner join",
      "format": ["AVRO", "JSON", "PROTOBUF", "PROTOBUF_NOSR"],
      "statements": [
        "CREATE TABLE TEST (id BIGINT PRIMARY KEY, name VARCHAR, value BIGINT) WITH (kafka_topic='left_topic', value_format='{FORMAT}');",
        "CREATE TABLE TEST_TABLE (id BIGINT PRIMARY KEY, f1 VARCHAR, f2 BIGINT) WITH (kafka_topic='right_topic', value_format='{FORMAT}');",
        "CREATE TABLE INNER_JOIN as SELECT t.id, name, value, f1, f2 FROM test t join TEST_TABLE tt on t.id = tt.id;"
      ],
      "inputs": [
        {"topic": "left_topic", "key": 0, "value": {"NAME": "zero", "VALUE": 0}, "timestamp": 0},
        {"topic": "right_topic", "key": 0, "value": {"F1": "blah", "F2": 50}, "timestamp": 10000},
        {"topic": "left_topic", "key": 10, "value": {"NAME": "100", "VALUE": 5}, "timestamp": 11000},
        {"topic": "left_topic", "key": 0, "value": {"NAME": "foo", "VALUE": 100}, "timestamp": 13000},
        {"topic": "right_topic", "key": 0, "value": {"F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "right_topic", "key": 15, "value": {"F1": "c", "F2": 20}, "timestamp": 15500},
        {"topic": "left_topic", "key": 0, "value": {"NAME": "bar", "VALUE": 99}, "timestamp": 16000},
        {"topic": "left_topic", "key": 90, "value": {"NAME": "ninety", "VALUE": 90}, "timestamp": 17000}
      ],
      "outputs": [
        {"topic": "INNER_JOIN", "key": 0, "value": {"NAME": "zero", "VALUE": 0, "F1": "blah", "F2": 50}, "timestamp": 10000},
        {"topic": "INNER_JOIN", "key": 0, "value": {"NAME": "foo", "VALUE": 100, "F1": "blah", "F2": 50}, "timestamp": 13000},
        {"topic": "INNER_JOIN", "key": 0, "value": {"NAME": "foo", "VALUE": 100, "F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "INNER_JOIN", "key": 0, "value": {"NAME": "bar", "VALUE": 99, "F1": "a", "F2": 10}, "timestamp": 16000}
      ],
      "post": {
        "sources": [
          {"name": "INNER_JOIN", "type": "table", "schema": "`T_ID` BIGINT KEY, `NAME` STRING, `VALUE` BIGINT, `F1` STRING, `F2` BIGINT"}
        ],
        "topics": {
          "blacklist": ".*-repartition"
        }
      }
    },
    {
      "name": "table table outer join",
      "format": ["AVRO", "JSON"],
      "statements": [
        "CREATE TABLE TEST (id BIGINT PRIMARY KEY, name VARCHAR, value BIGINT) WITH (kafka_topic='left_topic', value_format='{FORMAT}');",
        "CREATE TABLE TEST_TABLE (id BIGINT PRIMARY KEY, f1 VARCHAR, f2 BIGINT) WITH (kafka_topic='right_topic', value_format='{FORMAT}');",
        "CREATE TABLE OUTER_JOIN as SELECT ROWKEY AS ID, name, value, f1, f2 FROM test t FULL OUTER join TEST_TABLE tt on t.id = tt.id;"
      ],
      "inputs": [
        {"topic": "left_topic", "key": 0, "value": {"NAME": "zero", "VALUE": 0}, "timestamp": 0},
        {"topic": "right_topic", "key": 0, "value": {"F1": "blah", "F2": 50}, "timestamp": 10000},
        {"topic": "left_topic", "key": 10, "value": {"NAME": "100", "VALUE": 5}, "timestamp": 11000},
        {"topic": "left_topic", "key": 0, "value": {"NAME": "foo", "VALUE": 100}, "timestamp": 13000},
        {"topic": "right_topic", "key": 0, "value": {"F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "right_topic", "key": 15, "value": {"F1": "c", "F2": 20}, "timestamp": 15500},
        {"topic": "left_topic", "key": 0, "value": {"NAME": "bar", "VALUE": 99}, "timestamp": 16000}
      ],
      "outputs": [
        {"topic": "OUTER_JOIN", "key": 0, "value": {"NAME": "zero", "VALUE": 0, "F1": null, "F2": null}, "timestamp": 0},
        {"topic": "OUTER_JOIN", "key": 0, "value": {"NAME": "zero", "VALUE": 0, "F1": "blah", "F2": 50}, "timestamp": 10000},
        {"topic": "OUTER_JOIN", "key": 10, "value": {"NAME": "100", "VALUE": 5, "F1": null, "F2": null}, "timestamp": 11000},
        {"topic": "OUTER_JOIN", "key": 0, "value": {"NAME": "foo", "VALUE": 100, "F1": "blah", "F2": 50}, "timestamp": 13000},
        {"topic": "OUTER_JOIN", "key": 0, "value": {"NAME": "foo", "VALUE": 100, "F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "OUTER_JOIN", "key": 15, "value": {"NAME": null, "VALUE": null, "F1": "c", "F2": 20}, "timestamp": 15500},
        {"topic": "OUTER_JOIN", "key": 0, "value": {"NAME": "bar", "VALUE": 99, "F1": "a", "F2": 10}, "timestamp": 16000}
      ],
      "post": {
        "sources": [
          {"name": "OUTER_JOIN", "type": "table", "schema": "ID BIGINT KEY, `NAME` STRING, `VALUE` BIGINT, `F1` STRING, `F2` BIGINT"}
        ],
        "topics": {
          "blacklist": ".*-repartition"
        }
      }
    },
    {
      "name": "table table outer join - PROTOBUF",
      "format": ["PROTOBUF", "PROTOBUF_NOSR"],
      "statements": [
        "CREATE TABLE TEST (id BIGINT PRIMARY KEY, name VARCHAR, value BIGINT) WITH (kafka_topic='left_topic', value_format='{FORMAT}');",
        "CREATE TABLE TEST_TABLE (id BIGINT PRIMARY KEY, f1 VARCHAR, f2 BIGINT) WITH (kafka_topic='right_topic', value_format='{FORMAT}');",
        "CREATE TABLE OUTER_JOIN as SELECT ROWKEY AS ID, t.id, tt.id, name, value, f1, f2 FROM test t FULL OUTER join TEST_TABLE tt on t.id = tt.id;"
      ],
      "inputs": [
        {"topic": "left_topic", "key": 1, "value": {"NAME": "zero", "VALUE": 0}, "timestamp": 0},
        {"topic": "right_topic", "key": 1, "value": {"F1": "blah", "F2": 50}, "timestamp": 10000},
        {"topic": "left_topic", "key": 10, "value": {"NAME": "100", "VALUE": 5}, "timestamp": 11000},
        {"topic": "left_topic", "key": 1, "value": {"NAME": "foo", "VALUE": 100}, "timestamp": 13000},
        {"topic": "right_topic", "key": 1, "value": {"F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "right_topic", "key": 15, "value": {"F1": "c", "F2": 20}, "timestamp": 15500},
        {"topic": "left_topic", "key": 1, "value": {"NAME": "bar", "VALUE": 99}, "timestamp": 16000}
      ],
      "outputs": [
        {"topic": "OUTER_JOIN", "key": 1, "value": {"T_ID": 1, "TT_ID": 0, "NAME": "zero", "VALUE": 0, "F1": "", "F2": 0}, "timestamp": 0},
        {"topic": "OUTER_JOIN", "key": 1, "value": {"T_ID": 1, "TT_ID": 1, "NAME": "zero", "VALUE": 0, "F1": "blah", "F2": 50}, "timestamp": 10000},
        {"topic": "OUTER_JOIN", "key": 10, "value": {"T_ID": 10, "TT_ID": 0, "NAME": "100", "VALUE": 5, "F1": "", "F2": 0}, "timestamp": 11000},
        {"topic": "OUTER_JOIN", "key": 1, "value": {"T_ID": 1, "TT_ID": 1, "NAME": "foo", "VALUE": 100, "F1": "blah", "F2": 50}, "timestamp": 13000},
        {"topic": "OUTER_JOIN", "key": 1, "value": {"T_ID": 1, "TT_ID": 1, "NAME": "foo", "VALUE": 100, "F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "OUTER_JOIN", "key": 15, "value": {"T_ID": 0, "TT_ID": 15, "NAME": "", "VALUE": 0, "F1": "c", "F2": 20}, "timestamp": 15500},
        {"topic": "OUTER_JOIN", "key": 1, "value": {"T_ID": 1, "TT_ID": 1, "NAME": "bar", "VALUE": 99, "F1": "a", "F2": 10}, "timestamp": 16000}
      ],
      "post": {
        "sources": [
          {"name": "OUTER_JOIN", "type": "table", "schema": "ID BIGINT KEY, T_ID BIGINT, TT_ID BIGINT, `NAME` STRING, `VALUE` BIGINT, `F1` STRING, `F2` BIGINT"}
        ],
        "topics": {
          "blacklist": ".*-repartition"
        }
      }
    },
    {
      "name": "stream table left join",
      "format": ["AVRO", "JSON"],
      "statements": [
        "CREATE STREAM TEST (ID BIGINT KEY, NAME varchar, VALUE bigint) WITH (kafka_topic='test_topic', value_format='{FORMAT}');",
        "CREATE TABLE TEST_TABLE (id BIGINT PRIMARY KEY, f1 VARCHAR, f2 BIGINT) WITH (kafka_topic='test_table', value_format='{FORMAT}');",
        "CREATE STREAM LEFT_JOIN as SELECT t.id, name, value, f1, f2 FROM test t left join test_table tt on t.id = tt.id;"
      ],
      "inputs": [
        {"topic": "test_table", "key": 0, "value": {"F1": "zero", "F2": 0}, "timestamp": 0},
        {"topic": "test_table", "key": 10, "value": {"F1": "100", "F2": 5}, "timestamp": 10000},
        {"topic": "test_topic", "key": 0, "value": {"NAME": "blah", "VALUE": 50}, "timestamp": 10000},
        {"topic": "test_topic", "key": 0, "value": {"NAME": "foo", "VALUE": 100}, "timestamp": 10000},
        {"topic": "test_table", "key": 0, "value": {"F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "test_topic", "key": 0, "value": {"NAME": "bar", "VALUE": 99}, "timestamp": 15000},
        {"topic": "test_topic", "key": 90, "value": {"NAME": "ninety", "VALUE": 90}, "timestamp": 15000}
      ],
      "outputs": [
        {"topic": "LEFT_JOIN", "key": 0, "value": {"NAME": "blah", "VALUE": 50, "F1": "zero", "F2": 0}, "timestamp": 10000},
        {"topic": "LEFT_JOIN", "key": 0, "value": {"NAME": "foo", "VALUE": 100, "F1": "zero", "F2": 0}, "timestamp": 10000},
        {"topic": "LEFT_JOIN", "key": 0, "value": {"NAME": "bar", "VALUE": 99, "F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "LEFT_JOIN", "key": 90, "value": {"NAME": "ninety", "VALUE": 90, "F1": null, "F2": null}, "timestamp": 15000}
      ],
      "post": {
        "sources": [
          {"name": "LEFT_JOIN", "type": "stream", "schema": "T_ID BIGINT KEY, `NAME` STRING, `VALUE` BIGINT, `F1` STRING, `F2` BIGINT"}
        ],
        "topics": {
          "blacklist": ".*-repartition"
        }
      }
    },
    {
      "name": "stream table left join - PROTOBUF",
      "format": ["PROTOBUF", "PROTOBUF_NOSR"],
      "statements": [
        "CREATE STREAM TEST (ID BIGINT KEY, NAME varchar, VALUE bigint) WITH (kafka_topic='test_topic', value_format='{FORMAT}');",
        "CREATE TABLE TEST_TABLE (id BIGINT PRIMARY KEY, f1 VARCHAR, f2 BIGINT) WITH (kafka_topic='test_table', value_format='{FORMAT}');",
        "CREATE STREAM LEFT_JOIN as SELECT t.id, name, value, f1, f2 FROM test t left join test_table tt on t.id = tt.id;"
      ],
      "inputs": [
        {"topic": "test_table", "key": 0, "value": {"F1": "zero", "F2": 0}, "timestamp": 0},
        {"topic": "test_table", "key": 10, "value": {"F1": "100", "F2": 5}, "timestamp": 10000},
        {"topic": "test_topic", "key": 0, "value": {"NAME": "blah", "VALUE": 50}, "timestamp": 10000},
        {"topic": "test_topic", "key": 0, "value": {"NAME": "foo", "VALUE": 100}, "timestamp": 10000},
        {"topic": "test_table", "key": 0, "value": {"F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "test_topic", "key": 0, "value": {"NAME": "bar", "VALUE": 99}, "timestamp": 15000},
        {"topic": "test_topic", "key": 90, "value": {"NAME": "ninety", "VALUE": 90}, "timestamp": 15000}
      ],
      "outputs": [
        {"topic": "LEFT_JOIN", "key": 0, "value": {"NAME": "blah", "VALUE": 50, "F1": "zero", "F2": 0}, "timestamp": 10000},
        {"topic": "LEFT_JOIN", "key": 0, "value": {"NAME": "foo", "VALUE": 100, "F1": "zero", "F2": 0}, "timestamp": 10000},
        {"topic": "LEFT_JOIN", "key": 0, "value": {"NAME": "bar", "VALUE": 99, "F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "LEFT_JOIN", "key": 90, "value": {"NAME": "ninety", "VALUE": 90, "F1": "", "F2": 0}, "timestamp": 15000}
      ],
      "post": {
        "sources": [
          {"name": "LEFT_JOIN", "type": "stream", "schema": "T_ID BIGINT KEY, `NAME` STRING, `VALUE` BIGINT, `F1` STRING, `F2` BIGINT"}
        ],
        "topics": {
          "blacklist": ".*-repartition"
        }
      }
    },
    {
      "name": "stream table inner join",
      "format": ["AVRO", "JSON", "PROTOBUF", "PROTOBUF_NOSR"],
      "statements": [
        "CREATE STREAM TEST (ID BIGINT KEY, NAME varchar, VALUE bigint) WITH (kafka_topic='test_topic', value_format='{FORMAT}');",
        "CREATE TABLE TEST_TABLE (id BIGINT PRIMARY KEY, f1 VARCHAR, f2 BIGINT) WITH (kafka_topic='test_table', value_format='{FORMAT}');",
        "CREATE STREAM INNER_JOIN as SELECT t.id, name, value, f1, f2 FROM test t join test_table tt on t.id = tt.id;"
      ],
      "inputs": [
        {"topic": "test_table", "key": 0, "value": {"F1": "zero", "F2": 0}, "timestamp": 0},
        {"topic": "test_table", "key": 10, "value": {"F1": "100", "F2": 5}, "timestamp": 10000},
        {"topic": "test_topic", "key": 0, "value": {"NAME": "blah", "VALUE": 50}, "timestamp": 10000},
        {"topic": "test_topic", "key": 0, "value": {"NAME": "foo", "VALUE": 100}, "timestamp": 10000},
        {"topic": "test_table", "key": 0, "value": {"F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "test_topic", "key": 0, "value": {"NAME": "bar", "VALUE": 99}, "timestamp": 15000},
        {"topic": "test_topic", "key": 90, "value": {"NAME": "ninety", "VALUE": 90}, "timestamp": 15000}
      ],
      "outputs": [
        {"topic": "INNER_JOIN", "key": 0, "value": {"NAME": "blah", "VALUE": 50, "F1": "zero", "F2": 0}, "timestamp": 10000},
        {"topic": "INNER_JOIN", "key": 0, "value": {"NAME": "foo", "VALUE": 100, "F1": "zero", "F2": 0}, "timestamp": 10000},
        {"topic": "INNER_JOIN", "key": 0, "value": {"NAME": "bar", "VALUE": 99, "F1": "a", "F2": 10}, "timestamp": 15000}
      ],
      "post": {
        "sources": [
          {"name": "INNER_JOIN", "type": "stream", "schema": "T_ID BIGINT KEY, `NAME` STRING, `VALUE` BIGINT, `F1` STRING, `F2` BIGINT"}
        ],
        "topics": {
          "blacklist": ".*-repartition"
        }
      }
    },
    {
      "name": "table join pipeline",
      "format": ["JSON"],
      "statements": [
        "CREATE TABLE TEST (id BIGINT PRIMARY KEY, name VARCHAR, value BIGINT) WITH (kafka_topic='left_topic', value_format='{FORMAT}');",
        "CREATE TABLE TEST_TABLE (id BIGINT PRIMARY KEY, f1 VARCHAR, f2 BIGINT) WITH (kafka_topic='right_topic', value_format='{FORMAT}');",
        "CREATE TABLE TEST_TABLE_2 (ID BIGINT PRIMARY KEY, F3 varchar) WITH (kafka_topic='right_topic_2', value_format='{FORMAT}');",
        "CREATE TABLE INNER_JOIN WITH (PARTITIONS=4) as SELECT t.id AS ID, name, value, f1, f2 FROM test t join TEST_TABLE tt on t.id = tt.id;",
        "CREATE TABLE INNER_JOIN_2 AS SELECT tt.id, name, f1, f3 FROM inner_join tt join TEST_TABLE_2 t ON t.id = tt.id;"
      ],
      "topics": [
        {
          "name": "INNER_JOIN",
          "format": "JSON",
          "partitions": 4
        }
      ],
      "inputs": [
        {"topic": "INNER_JOIN", "key": 0, "value": {"NAME": "X", "VALUE": 0, "F1": "yo dawg", "F2": 50}, "timestamp": 0},
        {"topic": "right_topic_2", "key": 0, "value": {"F3": "I heard you like joins"}, "timestamp": 10000},
        {"topic": "INNER_JOIN", "key": 100, "value": {"NAME": "X", "VALUE": 0, "F1": "KSQL has table-table joins", "F2": 50}, "timestamp": 15000},
        {"topic": "right_topic_2", "key": 100, "value": {"F3": "so now you can join your join"}, "timestamp": 20000}
      ],
      "outputs": [
        {"topic": "INNER_JOIN_2", "key": 0, "value": {"NAME": "X", "F1": "yo dawg", "F3": "I heard you like joins"}, "timestamp": 10000},
        {"topic": "INNER_JOIN_2", "key": 100, "value": {"NAME": "X", "F1": "KSQL has table-table joins", "F3": "so now you can join your join"}, "timestamp": 20000}
      ]
    },
    {
      "name": "table table join with where clause",
      "statements": [
        "CREATE TABLE TEST (id BIGINT PRIMARY KEY, name VARCHAR, value BIGINT) WITH (kafka_topic='left_topic', value_format='JSON');",
        "CREATE TABLE TEST_TABLE (id BIGINT PRIMARY KEY, f1 VARCHAR, f2 BIGINT) WITH (kafka_topic='right_topic', value_format='JSON');",
        "CREATE TABLE OUTPUT as SELECT t.id, name, tt.f1, f2 FROM test t JOIN test_table tt ON t.id = tt.id WHERE t.value > 10 AND tt.f2 > 5;"
      ],
      "inputs": [
        {"topic": "left_topic", "key": 0, "value": {"NAME": "zero", "VALUE": 0}, "timestamp": 0},
        {"topic": "right_topic", "key": 0, "value": {"F1": "blah", "F2": 4}, "timestamp": 10000},
        {"topic": "left_topic", "key": 0, "value": {"NAME": "foo", "VALUE": 100}, "timestamp": 13000},
        {"topic": "right_topic", "key": 0, "value": {"F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "left_topic", "key": 0, "value": {"NAME": "bar", "VALUE": 99}, "timestamp": 16000},
        {"topic": "left_topic", "key": 90, "value": {"NAME": "ninety", "VALUE": 90}, "timestamp": 17000},
        {"topic": "right_topic", "key": 90, "value": {"F1": "b", "F2": 10}, "timestamp": 18000},
        {"topic": "right_topic", "key": 90, "value": null, "timestamp": 19000}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "foo", "F1": "a", "F2": 10}, "timestamp": 15000},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "bar", "F1": "a", "F2": 10}, "timestamp": 16000},
        {"topic": "OUTPUT", "key": 90, "value": {"NAME": "ninety", "F1": "b", "F2": 10}, "timestamp": 18000},
        {"topic": "OUTPUT", "key": 90, "value": null, "timestamp": 19000}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "table", "schema": "T_ID BIGINT KEY, `NAME` STRING, `F1` STRING, `F2` BIGINT"}
        ]
      }
    },
    {
      "name": "stream to stream wrapped single field value schema on inputs",
      "statements": [
        "CREATE STREAM S1 (ID BIGINT KEY, NAME STRING) WITH (kafka_topic='S1', value_format='JSON');",
        "CREATE STREAM S2 (ID BIGINT KEY, NAME STRING) WITH (kafka_topic='S2', value_format='JSON');",
        "CREATE STREAM OUTPUT as SELECT s1.id, s1.name name1, s2.name name2 FROM S1 JOIN S2 WITHIN 1 second ON s1.id = s2.id;"
      ],
      "inputs": [
        {"topic": "S1", "key": 0, "value": {"NAME": "a"}, "timestamp": 0},
        {"topic": "S2", "key": 0, "value": {"NAME": "b"}, "timestamp": 10},
        {"topic": "S1", "key": 0, "value": {"ID": null}, "timestamp": 20},
        {"topic": "S2", "key": 0, "value": {"ID": null}, "timestamp": 30}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 0, "value": {"NAME1": "a", "NAME2": "b"}, "timestamp": 10},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME1": null, "NAME2": "b"}, "timestamp": 20},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME1": "a", "NAME2": null}, "timestamp": 30},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME1": null, "NAME2": null}, "timestamp": 30}
      ]
    },
    {
      "name": "stream to stream unwrapped single field value schema on inputs",
      "issues": [
        "With the current implementation the null values are ignored by KS.",
        "This is probably not what we want. We could treat null values as a null ID for streams.",
        "Though this would not make sense for tables, where null is a tombstone"
      ],
      "statements": [
        "CREATE STREAM S1 (ID BIGINT KEY, NAME STRING) WITH (WRAP_SINGLE_VALUE=false, kafka_topic='S1', value_format='JSON');",
        "CREATE STREAM S2 (ID BIGINT KEY, NAME STRING) WITH (WRAP_SINGLE_VALUE=false, kafka_topic='S2', value_format='JSON');",
        "CREATE STREAM OUTPUT as SELECT s1.id, s1.name name1, s2.name name2 FROM S1 JOIN S2 WITHIN 1 second ON s1.id = s2.id;"
      ],
      "inputs": [
        {"topic": "S1", "key": 0, "value": "a", "timestamp": 0},
        {"topic": "S2", "key": 0, "value": "b", "timestamp": 10},
        {"topic": "S1", "key": 0, "value": null, "timestamp": 20},
        {"topic": "S2", "key": 0, "value": null, "timestamp": 30}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 0, "value": {"NAME1": "a", "NAME2": "b"}, "timestamp": 10}
      ]
    },
    {
      "name": "stream to stream unwrapped single field value schema on inputs and output",
      "issues": [
        "With the current implementation the null values are ignored by KS.",
        "This is probably not what we want. We could treat null values as a null ID for streams.",
        "Though this would not make sense for tables, where null is a tombstone"
      ],
      "statements": [
        "CREATE STREAM S1 (ID BIGINT KEY, NAME STRING) WITH (WRAP_SINGLE_VALUE=false, kafka_topic='S1', value_format='JSON');",
        "CREATE STREAM S2 (ID BIGINT KEY, NAME STRING) WITH (WRAP_SINGLE_VALUE=false, kafka_topic='S2', value_format='JSON');",
        "CREATE STREAM OUTPUT WITH (WRAP_SINGLE_VALUE=false) AS SELECT s1.id, s1.name name FROM S1 JOIN S2 WITHIN 1 second ON s1.id = s2.id;"
      ],
      "inputs": [
        {"topic": "S1", "key": 0, "value": "a", "timestamp": 0},
        {"topic": "S2", "key": 0, "value": "b", "timestamp": 10},
        {"topic": "S1", "key": 0, "value": null, "timestamp": 20},
        {"topic": "S2", "key": 0, "value": null, "timestamp": 30}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 0, "value": "a", "timestamp": 10}
      ]
    },
    {
      "name": "stream to table wrapped single field value schema on inputs",
      "statements": [
        "CREATE STREAM S (ID BIGINT KEY, NAME STRING) WITH (kafka_topic='S', value_format='JSON');",
        "CREATE TABLE T (ID BIGINT PRIMARY KEY, NAME STRING) WITH (kafka_topic='T', value_format='JSON');",
        "CREATE STREAM OUTPUT as SELECT s.id, s.name name1, t.name name2 FROM S JOIN T ON S.id = T.id;"
      ],
      "inputs": [
        {"topic": "T", "key": 0, "value": {"NAME": "b"}, "timestamp": 0},
        {"topic": "S", "key": 0, "value": {"NAME": "a"}, "timestamp": 10},
        {"topic": "S", "key": 0, "value": {"NAME": null}, "timestamp": 20},
        {"topic": "T", "key": 0, "value": {"NAME": null}, "timestamp": 30},
        {"topic": "S", "key": 0, "value": {"NAME": null}, "timestamp": 40},
        {"topic": "T", "key": 0, "value": null, "timestamp": 50},
        {"topic": "S", "key": 0, "value": {"NAME": "a"}, "timestamp": 60}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 0, "value": {"NAME1": "a", "NAME2": "b"}, "timestamp": 10},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME1": null, "NAME2": "b"}, "timestamp": 20},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME1": null, "NAME2": null}, "timestamp": 40}
      ]
    },
    {
      "name": "stream to table unwrapped single field value schema on inputs",
      "issues": [
        "With the current implementation the null values of the stream are ignored by KS.",
        "This is probably not what we want. We could treat null values as a null ID for streams.",
        "Though this would not make sense for tables, where null is a tombstone"
      ],
      "statements": [
        "CREATE STREAM S (ID BIGINT KEY, NAME STRING) WITH (WRAP_SINGLE_VALUE=false, kafka_topic='S', value_format='JSON');",
        "CREATE TABLE T (ID BIGINT PRIMARY KEY, NAME STRING) WITH (WRAP_SINGLE_VALUE=false, kafka_topic='T', value_format='JSON');",
        "CREATE STREAM OUTPUT as SELECT s.id, s.name name1, t.name name2 FROM S JOIN T ON S.id = T.id;"
      ],
      "inputs": [
        {"topic": "T", "key": 0, "value": "b", "timestamp": 0},
        {"topic": "S", "key": 0, "value": "a", "timestamp": 10},
        {"topic": "S", "key": 0, "value": null, "timestamp": 20},
        {"topic": "T", "key": 0, "value": null, "timestamp": 30},
        {"topic": "S", "key": 0, "value": null, "timestamp": 40}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 0, "value": {"NAME1": "a", "NAME2": "b"}, "timestamp": 10}
      ]
    },
    {
      "name": "stream to table unwrapped single field value schema on inputs and output",
      "issues": [
        "With the current implementation the null values of the stream are ignored by KS.",
        "This is probably not what we want. We could treat null values as a null ID for streams.",
        "Though this would not make sense for tables, where null is a tombstone."
      ],
      "statements": [
        "CREATE STREAM S (ID BIGINT KEY, NAME STRING) WITH (WRAP_SINGLE_VALUE=false, kafka_topic='S', value_format='JSON');",
        "CREATE TABLE T (ID BIGINT PRIMARY KEY, NAME STRING) WITH (WRAP_SINGLE_VALUE=false, kafka_topic='T', value_format='JSON');",
        "CREATE STREAM OUTPUT WITH (WRAP_SINGLE_VALUE=false) AS SELECT s.id, s.name name FROM S JOIN T ON S.id = T.id;"
      ],
      "inputs": [
        {"topic": "T", "key": 0, "value": "b", "timestamp": 0},
        {"topic": "S", "key": 0, "value": "a", "timestamp": 10},
        {"topic": "S", "key": 0, "value": null, "timestamp": 20},
        {"topic": "T", "key": 0, "value": null, "timestamp": 30},
        {"topic": "S", "key": 0, "value": null, "timestamp": 40}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 0, "value": "a", "timestamp": 10}
      ]
    },
    {
      "name": "table to table wrapped single field value schema on inputs",
      "statements": [
        "CREATE TABLE T1 (ID BIGINT PRIMARY KEY, NAME STRING) WITH (kafka_topic='T1', value_format='JSON');",
        "CREATE TABLE T2 (ID BIGINT PRIMARY KEY, NAME STRING) WITH (kafka_topic='T2', value_format='JSON');",
        "CREATE TABLE OUTPUT as SELECT t1.id, t1.name name1, t2.name name2 FROM T1 JOIN T2 ON T1.id = T2.id;"
      ],
      "inputs": [
        {"topic": "T1", "key": 0, "value": {"NAME": "a"}, "timestamp": 0},
        {"topic": "T2", "key": 0, "value": {"NAME": "b"}, "timestamp": 10},
        {"topic": "T1", "key": 0, "value": {"NAME": null}, "timestamp": 20},
        {"topic": "T2", "key": 0, "value": {"NAME": null}, "timestamp": 30},
        {"topic": "T1", "key": 0, "value": {"NAME": null}, "timestamp": 40},
        {"topic": "T1", "key": 0, "value": null, "timestamp": 50},
        {"topic": "T2", "key": 0, "value": null, "timestamp": 60}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 0, "value": {"NAME1": "a", "NAME2": "b"}, "timestamp": 10},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME1": null, "NAME2": "b"}, "timestamp": 20},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME1": null, "NAME2": null}, "timestamp": 30},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME1": null, "NAME2": null}, "timestamp": 40},
        {"topic": "OUTPUT", "key": 0, "value": null, "timestamp": 50}
      ]
    },
    {
      "name": "table to table unwrapped single field value schema on inputs",
      "statements": [
        "CREATE TABLE T1 (ID BIGINT PRIMARY KEY, NAME STRING) WITH (WRAP_SINGLE_VALUE=false, kafka_topic='T1', value_format='JSON');",
        "CREATE TABLE T2 (ID BIGINT PRIMARY KEY, NAME STRING) WITH (WRAP_SINGLE_VALUE=false, kafka_topic='T2', value_format='JSON');",
        "CREATE TABLE OUTPUT as SELECT t1.id, t1.name name1, t2.name name2 FROM T1 JOIN T2 ON T1.id = T2.id;"
      ],
      "inputs": [
        {"topic": "T1", "key": 0, "value": "a", "timestamp": 0},
        {"topic": "T2", "key": 0, "value": "b", "timestamp": 10},
        {"topic": "T1", "key": 0, "value": null, "timestamp": 20},
        {"topic": "T2", "key": 0, "value": null, "timestamp": 30},
        {"topic": "T1", "key": 0, "value": null, "timestamp": 40}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 0, "value": {"NAME1": "a", "NAME2": "b"}, "timestamp": 10},
        {"topic": "OUTPUT", "key": 0, "value": null, "timestamp": 20}
      ]
    },
    {
      "name": "table to table unwrapped single field value schema on inputs and output",
      "statements": [
        "CREATE TABLE T1 (ID BIGINT PRIMARY KEY, NAME STRING) WITH (WRAP_SINGLE_VALUE=false, kafka_topic='T1', value_format='JSON');",
        "CREATE TABLE T2 (ID BIGINT PRIMARY KEY, NAME STRING) WITH (WRAP_SINGLE_VALUE=false, kafka_topic='T2', value_format='JSON');",
        "CREATE TABLE OUTPUT WITH (WRAP_SINGLE_VALUE=false) AS SELECT t1.id, t1.name name FROM T1 JOIN T2 ON T1.id = T2.id;"
      ],
      "inputs": [
        {"topic": "T1", "key": 0, "value": "a", "timestamp": 0},
        {"topic": "T2", "key": 0, "value": "b", "timestamp": 10},
        {"topic": "T1", "key": 0, "value": null, "timestamp": 20},
        {"topic": "T2", "key": 0, "value": null, "timestamp": 30},
        {"topic": "T1", "key": 0, "value": null, "timestamp": 40}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 0, "value": "a", "timestamp": 10},
        {"topic": "OUTPUT", "key": 0, "value": null, "timestamp": 20}
      ]
    },
    {
      "name": "stream stream left join - invalid join field - contains literal",
      "statements": [
        "CREATE STREAM TEST1 (ID BIGINT KEY, NAME STRING) WITH (kafka_topic='left_topic', value_format='JSON');",
        "CREATE STREAM TEST2 (ID BIGINT KEY, NAME STRING) WITH (kafka_topic='right_topic', value_format='JSON');",
        "CREATE STREAM OUTPUT as SELECT * FROM test1 t left join test2 tt ON t.id = 0;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlStatementException",
        "message": "Invalid comparison expression '0' in join '(T.ID = 0)'. Each side of the join comparision must contain references from exactly one source."
      }
    },
    {
      "name": "stream stream left join - invalid join field on lhs- contains literal",
      "statements": [
        "CREATE STREAM TEST1 (ID BIGINT KEY, NAME STRING) WITH (kafka_topic='left_topic', value_format='JSON');",
        "CREATE STREAM TEST2 (ID BIGINT KEY, NAME STRING) WITH (kafka_topic='right_topic', value_format='JSON');",
        "CREATE STREAM OUTPUT as SELECT * FROM test1 t left join test2 tt ON 0 = t.id;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlStatementException",
        "message": "Invalid comparison expression '0' in join '(0 = T.ID)'. Each side of the join comparision must contain references from exactly one source."
      }
    },
    {
      "name": "stream stream right join - invalid join field - contains literal",
      "statements": [
        "CREATE STREAM TEST1 (ID BIGINT KEY, NAME STRING) WITH (kafka_topic='left_topic', value_format='JSON');",
        "CREATE STREAM TEST2 (ID BIGINT KEY, NAME STRING) WITH (kafka_topic='right_topic', value_format='JSON');",
        "CREATE STREAM OUTPUT as SELECT * FROM test1 t RIGHT JOIN test2 tt ON t.id = 0;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlStatementException",
        "message": "Invalid comparison expression '0' in join '(T.ID = 0)'. Each side of the join comparision must contain references from exactly one source."
      }
    },
    {
      "name": "stream stream right join - invalid join field on lhs- contains literal",
      "statements": [
        "CREATE STREAM TEST1 (ID BIGINT KEY, NAME STRING) WITH (kafka_topic='left_topic', value_format='JSON');",
        "CREATE STREAM TEST2 (ID BIGINT KEY, NAME STRING) WITH (kafka_topic='right_topic', value_format='JSON');",
        "CREATE STREAM OUTPUT as SELECT * FROM test1 t RIGHT JOIN test2 tt ON 0 = t.id;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlStatementException",
        "message": "Invalid comparison expression '0' in join '(0 = T.ID)'. Each side of the join comparision must contain references from exactly one source."
      }
    },
    {
      "name": "stream stream join - contains function",
      "statements": [
        "CREATE STREAM TEST1 (K STRING KEY, ID varchar) WITH (kafka_topic='left_topic', value_format='JSON');",
        "CREATE STREAM TEST2 (K STRING KEY, ID varchar) WITH (kafka_topic='right_topic', value_format='JSON');",
        "CREATE STREAM OUTPUT as SELECT T.ID, tt.ID FROM test1 t join test2 tt WITHIN 30 SECONDS ON t.id = SUBSTRING(tt.id, 2);"
      ],
      "inputs": [
        {"topic": "left_topic", "key": "foo", "value": {"id": "foo"}, "timestamp": 0},
        {"topic": "right_topic", "key": "!foo", "value": {"id": "!foo"}, "timestamp": 10}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": "foo", "value": {"TT_ID":  "!foo"}, "timestamp": 10}
      ]
    },
    {
      "name": "stream stream join - contains CAST",
      "statements": [
        "CREATE STREAM TEST1 (ID bigint KEY, x bigint) WITH (kafka_topic='left_topic', value_format='JSON');",
        "CREATE STREAM TEST2 (ID int KEY, x int) WITH (kafka_topic='right_topic', value_format='JSON');",
        "CREATE STREAM OUTPUT as SELECT t.id, t.x FROM test1 t JOIN test2 tt WITHIN 30 seconds ON t.id = CAST(tt.id AS BIGINT);"
      ],
      "inputs": [
        {"topic": "left_topic", "key": 1, "value": {"x": 2}, "timestamp": 10},
        {"topic": "right_topic", "key": 1, "value": {"x": 3}, "timestamp": 10}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 1, "value": {"T_X": 2}, "timestamp": 10}
      ]
    },
    {
      "name": "stream stream join - contains CAST double to int",
      "statements": [
        "CREATE STREAM L (ID INT KEY, x bigint) WITH (kafka_topic='left_topic', value_format='JSON');",
        "CREATE STREAM R (ID DOUBLE KEY, x bigint) WITH (kafka_topic='right_topic', value_format='JSON');",
        "CREATE STREAM OUTPUT as SELECT l.id, L.x FROM L JOIN R WITHIN 30 seconds ON L.id = CAST(R.id AS INT);"
      ],
      "inputs": [
        {"topic": "left_topic", "key": 1, "value": {"x": 2}, "timestamp": 10},
        {"topic": "right_topic", "key": 1.0, "value": {"x": 3}, "timestamp": 11}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 1, "value": {"L_X": 2}, "timestamp": 11}
      ]
    },
    {
      "name": "stream stream join on expression where schema contains ROWKEY_xx column names",
      "statements": [
        "CREATE STREAM TEST1 (ROWKEY bigint KEY, ROWKEY_2 bigint) WITH (kafka_topic='left_topic', value_format='JSON');",
        "CREATE STREAM TEST2 (ROWKEY_1 int KEY, ROWKEY_3 int) WITH (kafka_topic='right_topic', value_format='JSON');",
        "CREATE STREAM OUTPUT as SELECT t.ROWKEY, t.ROWKEY_2 FROM test1 t JOIN test2 tt WITHIN 30 seconds ON t.ROWKEY = CAST(tt.ROWKEY_1 AS BIGINT);"
      ],
      "inputs": [
        {"topic": "left_topic", "key": 1, "value": {"ROWKEY_2": 2}, "timestamp": 10},
        {"topic": "right_topic", "key": 1, "value": {"ROWKEY_3": 3}, "timestamp": 10}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 1, "value": {"ROWKEY_2": 2}, "timestamp": 10}
      ]
    },
    {
      "name": "with generated column name clashes",
      "statements": [
        "CREATE TABLE L (ROWKEY INT PRIMARY KEY, ROWKEY_1 INT, ROWKEY_2 INT) WITH (kafka_topic='left_topic', value_format='JSON');",
        "CREATE TABLE R (ROWKEY_3 INT PRIMARY KEY, ROWKEY_4 INT, ROWKEY_5 INT) WITH (kafka_topic='right_topic', value_format='JSON');",
        "CREATE TABLE OUTPUT as SELECT ROWKEY_6, L.ROWKEY, R.ROWKEY_3, L.ROWKEY_1, R.ROWKEY_5 FROM L FULL OUTER JOIN R on L.ROWKEY = R.ROWKEY_3;"
      ],
      "inputs": [
        {"topic": "left_topic", "key": 1, "value": {"ROWKEY_1": 2, "ROWKEY_2": 3}, "timestamp": 0},
        {"topic": "right_topic", "key": 1, "value": {"ROWKEY_4": 4, "ROWKEY_5": 5}, "timestamp": 100}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 1, "value": {"ROWKEY": 1, "ROWKEY_3": null, "ROWKEY_1": 2, "ROWKEY_5": null}, "timestamp": 0},
        {"topic": "OUTPUT", "key": 1, "value": {"ROWKEY": 1, "ROWKEY_3": 1, "ROWKEY_1": 2, "ROWKEY_5": 5}, "timestamp": 100}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "table", "schema": "ROWKEY_6 INT KEY, ROWKEY INT, ROWKEY_3 INT, ROWKEY_1 INT, ROWKEY_5 INT"}
        ]
      }
    },
    {
      "name": "stream stream join - contains subscript",
      "statements": [
        "CREATE STREAM TEST1 (ID INT KEY, NAME STRING) WITH (kafka_topic='left_topic', value_format='JSON');",
        "CREATE STREAM TEST2 (K STRING KEY, ID ARRAY<INT>) WITH (kafka_topic='right_topic', value_format='JSON');",
        "CREATE STREAM OUTPUT as SELECT T.ID, TT.K FROM test1 t JOIN test2 tt WITHIN 30 SECONDS ON t.id = tt.id[1];"
      ],
      "inputs": [
        {"topic": "left_topic", "key": 1, "value": {"name": "-"}, "timestamp": 0},
        {"topic": "left_topic", "key": 2, "value": {"name": "-"}, "timestamp": 5},
        {"topic": "right_topic", "key": "k", "value": {"id": [1,2,3]}, "timestamp": 10}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 1, "value": {"K": "k"}, "timestamp": 10}
      ]
    },
    {
      "name": "stream stream join - contains arithmetic binary expression",
      "statements": [
        "CREATE STREAM TEST1 (ID INT KEY, NAME STRING) WITH (kafka_topic='left_topic', value_format='JSON');",
        "CREATE STREAM TEST2 (ID INT KEY, NAME STRING) WITH (kafka_topic='right_topic', value_format='JSON');",
        "CREATE STREAM OUTPUT as SELECT T.ID, TT.ID FROM test1 t join test2 tt WITHIN 30 seconds ON t.id = tt.id + 1;"
      ],
      "inputs": [
        {"topic": "left_topic", "key": 1, "value": {"name": "-"}, "timestamp": 0},
        {"topic": "right_topic", "key": 0, "value": {"name": "-"}, "timestamp": 10}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 1, "value": {"TT_ID": 0}, "timestamp": 10}
      ]
    },
    {
      "name": "stream stream join - contains arithmetic unary expression",
      "statements": [
        "CREATE STREAM TEST1 (ID INT KEY, NAME STRING) WITH (kafka_topic='left_topic', value_format='JSON');",
        "CREATE STREAM TEST2 (ID INT KEY, NAME STRING) WITH (kafka_topic='right_topic', value_format='JSON');",
        "CREATE STREAM OUTPUT as SELECT T.ID, T.NAME, TT.NAME FROM test1 t join test2 tt WITHIN 30 seconds ON t.id = -tt.id;"
      ],
      "inputs": [
        {"topic": "left_topic", "key": 1, "value": {"name": "a"}, "timestamp": 0},
        {"topic": "right_topic", "key": -1, "value": {"name":  "b"}, "timestamp": 10}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 1, "value": {"T_NAME": "a", "TT_NAME": "b"}, "timestamp": 10}
      ]
    },
    {
      "name": "stream stream join - contains CASE expression",
      "statements": [
        "CREATE STREAM TEST1 (ID INT KEY, IGNORED STRING) WITH (kafka_topic='left_topic', value_format='JSON');",
        "CREATE STREAM TEST2 (ID INT KEY, IGNORED STRING) WITH (kafka_topic='right_topic', value_format='JSON');",
        "CREATE STREAM OUTPUT as SELECT T.ID, TT.ID FROM test1 t join test2 tt WITHIN 30 SECONDS ON t.id = (CASE WHEN tt.id = 2 THEN 1 ELSE 3 END);"
      ],
      "inputs": [
        {"topic": "left_topic", "key": 1, "value": {}, "timestamp": 0},
        {"topic": "left_topic", "key": 3, "value": {}, "timestamp": 5},
        {"topic": "right_topic", "key": 2, "value": {}, "timestamp": 10}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 1, "value": {"TT_ID": 2}, "timestamp": 10}
      ]
    },
    {
      "name": "stream stream join - contains arithmetic unary expression flipped sides",
      "statements": [
        "CREATE STREAM TEST1 (ID INT KEY, IGNORED STRING) WITH (kafka_topic='left_topic', value_format='JSON');",
        "CREATE STREAM TEST2 (ID INT KEY, IGNORED STRING) WITH (kafka_topic='right_topic', value_format='JSON');",
        "CREATE STREAM OUTPUT as SELECT T.ID, TT.ID FROM test1 t join test2 tt WITHIN 30 seconds ON -tt.id = t.id;"
      ],
      "inputs": [
        {"topic": "left_topic", "key": 1, "value": {}, "timestamp": 0},
        {"topic": "right_topic", "key": -1, "value": {}, "timestamp": 10}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 1, "value": {"TT_ID": -1}, "timestamp": 10}
      ]
    },
    {
      "name": "stream stream left join - invalid left join expression - field does not exist",
      "statements": [
        "CREATE STREAM TEST1 (ID INT KEY, IGNORED STRING) WITH (kafka_topic='left_topic', value_format='JSON');",
        "CREATE STREAM TEST2 (ID INT KEY, IGNORED STRING) WITH (kafka_topic='right_topic', value_format='JSON');",
        "CREATE STREAM OUTPUT as SELECT * FROM test1 t left join test2 tt ON t.iid= tt.id;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlStatementException",
        "message": "JOIN ON column 'T.IID' cannot be resolved."
      }
    },
    {
      "name": "stream stream left join - invalid right join expression - field does not exist",
      "statements": [
        "CREATE STREAM TEST1 (ID INT KEY, IGNORED STRING) WITH (kafka_topic='left_topic', value_format='JSON');",
        "CREATE STREAM TEST2 (ID INT KEY, IGNORED STRING) WITH (kafka_topic='right_topic', value_format='JSON');",
        "CREATE STREAM OUTPUT as SELECT * FROM test1 t left join test2 tt ON t.id= tt.iid;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlStatementException",
        "message": "JOIN ON column 'TT.IID' cannot be resolved."
      }
    },
    {
      "name": "stream stream right join - invalid left join expression - field does not exist",
      "statements": [
        "CREATE STREAM TEST1 (ID INT KEY, IGNORED STRING) WITH (kafka_topic='left_topic', value_format='JSON');",
        "CREATE STREAM TEST2 (ID INT KEY, IGNORED STRING) WITH (kafka_topic='right_topic', value_format='JSON');",
        "CREATE STREAM OUTPUT as SELECT * FROM test1 t RIGHT JOIN test2 tt ON t.iid = tt.id;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlStatementException",
        "message": "Line: 3, Col: 70: JOIN ON column 'T.IID' cannot be resolved."
      }
    },
    {
      "name": "stream stream right join - invalid right join expression - field does not exist",
      "statements": [
        "CREATE STREAM TEST1 (ID INT KEY, IGNORED STRING) WITH (kafka_topic='left_topic', value_format='JSON');",
        "CREATE STREAM TEST2 (ID INT KEY, IGNORED STRING) WITH (kafka_topic='right_topic', value_format='JSON');",
        "CREATE STREAM OUTPUT as SELECT * FROM test1 t RIGHT JOIN test2 tt ON t.id = tt.iid;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlStatementException",
        "message": "Line: 3, Col: 77: JOIN ON column 'TT.IID' cannot be resolved."
      }
    },
    {
      "name": "Should fail on ambiguous join attribute",
      "statements": [
        "CREATE TABLE left_table (id BIGINT PRIMARY KEY, f1 BIGINT) WITH (kafka_topic='left_topic', format='JSON');",
        "CREATE TABLE right_table (id BIGINT PRIMARY KEY, f2 BIGINT) WITH (kafka_topic='right_topic', format='JSON');",
        "CREATE TABLE output AS SELECT id1, id2, f1, f2 FROM left_table JOIN right_table ON id = id;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlStatementException",
        "message": "Exception while preparing statement: Line: 3, Col: 84: Column 'ID' is ambiguous. Could be LEFT_TABLE.ID or RIGHT_TABLE.ID."
      }
    },
    {
      "name": "Should fail on unknown qualifier -- left join attribute",
      "statements": [
        "CREATE TABLE left_table (id BIGINT PRIMARY KEY, f1 BIGINT) WITH (kafka_topic='left_topic', format='JSON');",
        "CREATE TABLE right_table (id BIGINT PRIMARY KEY, f2 BIGINT) WITH (kafka_topic='right_topic', format='JSON');",
        "CREATE TABLE output AS SELECT id1, id2, f1, f2 FROM left_table JOIN right_table ON unknown.id = id;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlStatementException",
        "message": "Failed to prepare statement: 'UNKNOWN' is not a valid stream/table name or alias."
      }
    },
    {
      "name": "Should fail on unknown qualifier -- right join attribute",
      "statements": [
        "CREATE TABLE left_table (id BIGINT PRIMARY KEY, f1 BIGINT) WITH (kafka_topic='left_topic', format='JSON');",
        "CREATE TABLE right_table (id BIGINT PRIMARY KEY, f2 BIGINT) WITH (kafka_topic='right_topic', format='JSON');",
        "CREATE TABLE output AS SELECT id1, id2, f1, f2 FROM left_table JOIN right_table ON id = unknown.id;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlStatementException",
        "message": "Failed to prepare statement: 'UNKNOWN' is not a valid stream/table name or alias."
      }
    },
    {
      "name": "should not allow complex join conditions",
      "statements": [
        "CREATE STREAM L (A INT KEY, B INT, C INT) WITH (kafka_topic='LEFT', value_format='JSON');",
        "CREATE STREAM R (A INT KEY, B INT, C INT) WITH (kafka_topic='RIGHT', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT * FROM L INNER JOIN R WITHIN 10 SECONDS ON L.A = R.A AND L.A = R.A;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlStatementException",
        "message": "Invalid join condition: joins on multiple conditions are not yet supported. Got ((L.A = R.A) AND (L.A = R.A))."
      }
    },
    {
      "name": "unqualified join criteria",
      "statements": [
        "CREATE STREAM TEST (LEFT_ID BIGINT KEY, NAME varchar) WITH (kafka_topic='left_topic', value_format='JSON');",
        "CREATE STREAM TEST_STREAM (RIGHT_ID BIGINT KEY, F1 varchar) WITH (kafka_topic='right_topic', value_format='JSON');",
        "CREATE STREAM OUTPUT as SELECT left_id, name, f1 FROM test t left join TEST_STREAM tt WITHIN 11 seconds ON left_id = right_id;"
      ],
      "inputs": [
        {"topic": "left_topic", "key": 0, "value": {"NAME": "zero"}, "timestamp": 0},
        {"topic": "right_topic", "key": 0, "value": {"F1": "blah"}, "timestamp": 10000},
        {"topic": "left_topic", "key": 10, "value": {"NAME": "100"}, "timestamp": 11000},
        {"topic": "left_topic", "key": 0, "value": {"NAME": "foo"}, "timestamp": 13000},
        {"topic": "right_topic", "key": 0, "value": {"F1": "a"}, "timestamp": 15000},
        {"topic": "right_topic", "key": 100, "value": {"F1": "newblah"}, "timestamp": 16000},
        {"topic": "left_topic", "key": 90, "value": {"NAME": "ninety"}, "timestamp": 17000},
        {"topic": "left_topic", "key": 0, "value": {"NAME": "bar"}, "timestamp": 30000}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "zero", "F1": null}, "timestamp": 0},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "zero", "F1": "blah"}, "timestamp": 10000},
        {"topic": "OUTPUT", "key": 10, "value": {"NAME": "100", "F1": null}, "timestamp": 11000},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "foo", "F1": "blah"}, "timestamp": 13000},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "foo", "F1": "a"}, "timestamp": 15000},
        {"topic": "OUTPUT", "key": 90, "value": {"NAME": "ninety", "F1": null}, "timestamp": 17000},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "bar", "F1": null}, "timestamp": 30000}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "LEFT_ID BIGINT KEY, NAME STRING, F1 STRING"}
        ]
      }
    },
    {
      "name": "on non-STRING value column",
      "statements": [
        "CREATE STREAM INPUT_STREAM (K STRING KEY, SF BIGINT) WITH (kafka_topic='stream_topic', value_format='JSON');",
        "CREATE TABLE INPUT_TABLE (ID BIGINT PRIMARY KEY, TF INT) WITH (kafka_topic='table_topic', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT *, S.ROWTIME, T.ROWTIME FROM INPUT_STREAM S JOIN INPUT_TABLE T on S.SF = T.ID;"
      ],
      "inputs": [
        {"topic": "table_topic", "key": 26589, "value": {"TF": 1}, "timestamp": 0},
        {"topic": "stream_topic", "key": "a", "value": {"SF": 12589}, "timestamp": 100},
        {"topic": "table_topic", "key": 12589, "value": {"TF": 12}, "timestamp": 200},
        {"topic": "stream_topic", "key": "b", "value": {"SF": 12589}, "timestamp": 300}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 12589, "value": {"S_K": "b", "S_ROWTIME": 300, "T_ROWTIME": 200, "T_ID": 12589, "T_TF": 12}, "timestamp": 300}
      ],
      "post": {
        "sources": [
          {
            "name": "OUTPUT",
            "type": "stream",
            "keyFormat": {"format": "KAFKA"},
            "schema": "S_SF BIGINT KEY, S_K STRING, T_ID BIGINT, T_TF INT, S_ROWTIME BIGINT, T_ROWTIME BIGINT"
          }
        ]
      }
    },
    {
      "name": "on INT column - KAFKA",
      "format": ["AVRO", "JSON", "PROTOBUF", "PROTOBUF_NOSR"],
      "statements": [
        "CREATE STREAM L (ID STRING KEY, l0 INT, l1 INT) WITH (kafka_topic='left_topic', value_format='{FORMAT}');",
        "CREATE STREAM R (ID STRING KEY, r0 INT, r1 INT) WITH (kafka_topic='right_topic', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT as SELECT L.l0, L.ID, L1, R1 FROM L join R WITHIN 11 SECONDS ON L.l0 = R.r0;"
      ],
      "inputs": [
        {"topic": "left_topic", "key": "a", "value": {"L0": 10, "L1": 1}, "timestamp": 0},
        {"topic": "right_topic", "key": "b" ,"value": {"R0": 10, "R1": 2}, "timestamp": 10000}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 10, "value": {"L_ID": "a", "L1": 1, "R1": 2}, "timestamp": 10000}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "L0 INT KEY, L_ID STRING, L1 INT, R1 INT"}
        ]
      }
    },
    {
      "name": "on BIGINT column - KAFKA",
      "format": ["AVRO", "JSON", "PROTOBUF", "PROTOBUF_NOSR"],
      "statements": [
        "CREATE STREAM L (ID STRING KEY, l0 BIGINT, l1 INT) WITH (kafka_topic='left_topic', value_format='{FORMAT}');",
        "CREATE STREAM R (ID STRING KEY, r0 BIGINT, r1 INT) WITH (kafka_topic='right_topic', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT as SELECT L.l0, L.ID, L1, R1 FROM L join R WITHIN 11 SECONDS ON L.l0 = R.r0;"
      ],
      "inputs": [
        {"topic": "left_topic", "key": "a", "value": {"L0": 1000000000, "L1": 1}, "timestamp": 0},
        {"topic": "right_topic", "key": "b" ,"value": {"R0": 1000000000, "R1": 2}, "timestamp": 10000}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 1000000000, "value": {"L_ID": "a", "L1": 1, "R1": 2}, "timestamp": 10000}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "L0 BIGINT KEY, L_ID STRING, L1 INT, R1 INT"}
        ]
      }
    },
    {
      "name": "on DOUBLE column = KAFKA",
      "format": ["AVRO", "JSON", "PROTOBUF", "PROTOBUF_NOSR"],
      "statements": [
        "CREATE STREAM L (ID STRING KEY, l0 DOUBLE, l1 INT) WITH (kafka_topic='left_topic', value_format='{FORMAT}');",
        "CREATE STREAM R (ID STRING KEY, r0 DOUBLE, r1 INT) WITH (kafka_topic='right_topic', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT as SELECT L.l0, L.ID, L1, R1 FROM L join R WITHIN 11 SECONDS ON L.l0 = R.r0;"
      ],
      "inputs": [
        {"topic": "left_topic", "key": "a", "value": {"L0": 1.23, "L1": 1}, "timestamp": 0},
        {"topic": "right_topic", "key": "b" ,"value": {"R0": 1.23, "R1": 2}, "timestamp": 10000}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 1.23, "value": {"L_ID": "a", "L1": 1, "R1": 2}, "timestamp": 10000}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "L0 DOUBLE KEY, L_ID STRING, L1 INT, R1 INT"}
        ]
      }
    },
    {
      "name": "on STRING column - KAFKA",
      "format": ["AVRO", "JSON", "PROTOBUF", "PROTOBUF_NOSR"],
      "statements": [
        "CREATE STREAM L (ID STRING KEY, l0 STRING, l1 INT) WITH (kafka_topic='left_topic', value_format='{FORMAT}');",
        "CREATE STREAM R (ID STRING KEY, r0 STRING, r1 INT) WITH (kafka_topic='right_topic', value_format='{FORMAT}');",
        "CREATE STREAM OUTPUT as SELECT L.l0, L.ID, L1, R1 FROM L join R WITHIN 11 SECONDS ON L.l0 = R.r0;"
      ],
      "inputs": [
        {"topic": "left_topic", "key": "a", "value": {"L0": "x", "L1": 1}, "timestamp": 0},
        {"topic": "right_topic", "key": "b" ,"value": {"R0": "x", "R1": 2}, "timestamp": 10000}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": "x", "value": {"L_ID": "a", "L1": 1, "R1": 2}, "timestamp": 10000}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "L0 STRING KEY, L_ID STRING, L1 INT, R1 INT"}
        ]
      }
    },
    {
      "name": "on ARRAY column",
      "format": ["AVRO", "JSON"],
      "statements": [
        "CREATE STREAM L (ID STRING KEY, l0 ARRAY<INT>, l1 INT) WITH (kafka_topic='left_topic', format='{FORMAT}');",
        "CREATE STREAM R (ID STRING KEY, r0 ARRAY<INT>, r1 INT) WITH (kafka_topic='right_topic', format='{FORMAT}');",
        "CREATE STREAM OUTPUT as SELECT L.l0, L.ID, L1, R1 FROM L join R WITHIN 11 SECONDS ON L.l0 = R.r0;"
      ],
      "inputs": [
        {"topic": "left_topic", "key": "a", "value": {"L0": [3, 1], "L1": 1}, "timestamp": 0},
        {"topic": "right_topic", "key": "b" ,"value": {"R0": [3, 1], "R1": 2}, "timestamp": 10000}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": [3, 1], "value": {"L_ID": "a", "L1": 1, "R1": 2}, "timestamp": 10000}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "L0 ARRAY<INT> KEY, L_ID STRING, L1 INT, R1 INT"}
        ]
      }
    },
    {
      "name": "on STRUCT column",
      "format": ["AVRO", "JSON"],
      "statements": [
        "CREATE STREAM L (ID STRING KEY, l0 STRUCT<F1 INT, F2 STRING>, l1 INT) WITH (kafka_topic='left_topic', format='{FORMAT}');",
        "CREATE STREAM R (ID STRING KEY, r0 STRUCT<F1 INT, F2 STRING>, r1 INT) WITH (kafka_topic='right_topic', format='{FORMAT}');",
        "CREATE STREAM OUTPUT as SELECT L.l0, L.ID, L1, R1 FROM L join R WITHIN 11 SECONDS ON L.l0 = R.r0;"
      ],
      "inputs": [
        {"topic": "left_topic", "key": "a", "value": {"L0": {"F1": 2, "F2": "foo"}, "L1": 1}, "timestamp": 0},
        {"topic": "right_topic", "key": "b" ,"value": {"R0": {"F1": 2, "F2": "foo"}, "R1": 2}, "timestamp": 10000}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": {"F1": 2, "F2": "foo"}, "value": {"L_ID": "a", "L1": 1, "R1": 2}, "timestamp": 10000}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "L0 STRUCT<F1 INT, F2 STRING> KEY, L_ID STRING, L1 INT, R1 INT"}
        ]
      }
    },
    {
      "name": "on MAP column",
      "statements": [
        "CREATE STREAM L (ID STRING KEY, l0 MAP<STRING, INT>, l1 INT) WITH (kafka_topic='left_topic', format='JSON');",
        "CREATE STREAM R (ID STRING KEY, r0 MAP<STRING, INT>, r1 INT) WITH (kafka_topic='right_topic', format='JSON');",
        "CREATE STREAM OUTPUT as SELECT L.l0, L.ID, L1, R1 FROM L join R WITHIN 11 SECONDS ON L.l0 = R.r0;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlStatementException",
        "message": "Map keys, including types that contain maps, are not supported as they may lead to unexpected behavior due to inconsistent serialization. Key column name: `L_L0`. Column type: MAP<STRING, INTEGER>. See https://github.com/confluentinc/ksql/issues/6621 for more."
      }
    },
    {
      "name": "on nested MAP column",
      "statements": [
        "CREATE STREAM L (ID STRING KEY, l0 STRUCT<F1 MAP<STRING, INT>>, l1 INT) WITH (kafka_topic='left_topic', format='JSON');",
        "CREATE STREAM R (ID STRING KEY, r0 STRUCT<F1 MAP<STRING, INT>>, r1 INT) WITH (kafka_topic='right_topic', format='JSON');",
        "CREATE STREAM OUTPUT as SELECT L.l0, L.ID, L1, R1 FROM L join R WITHIN 11 SECONDS ON L.l0 = R.r0;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlStatementException",
        "message": "Map keys, including types that contain maps, are not supported as they may lead to unexpected behavior due to inconsistent serialization. Key column name: `L_L0`. Column type: STRUCT<`F1` MAP<STRING, INTEGER>>. See https://github.com/confluentinc/ksql/issues/6621 for more."
      }
    },
    {
      "name": "self join",
      "statements": [
        "CREATE STREAM INPUT (K STRING KEY, ID bigint) WITH (kafka_topic='left_topic', value_format='JSON');",
        "CREATE STREAM OUTPUT as SELECT * FROM INPUT s1 JOIN INPUT s2 WITHIN 1 HOUR ON s1.id = s2.id;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlStatementException",
        "message": "Can not join 'INPUT' to 'INPUT': self joins are not yet supported."
      }
    },
    {
      "name": "matching session-windowed",
      "comments": [
        "Note: the first record on the right topic intersects with the session on the right side, but no row is output as keys must",
        "be an EXACT BINARY match"
      ],
      "statements": [
        "CREATE STREAM S1 (ID INT KEY, V bigint) WITH (kafka_topic='left_topic', value_format='JSON', WINDOW_TYPE='SESSION');",
        "CREATE STREAM S2 (ID INT KEY, V bigint) WITH (kafka_topic='right_topic', value_format='JSON', WINDOW_TYPE='SESSION');",
        "CREATE STREAM OUTPUT as SELECT S1.ID, S1.V, S2.V FROM S1 JOIN S2 WITHIN 1 MINUTE ON S1.ID = S2.ID;"
      ],
      "inputs": [
        {"topic": "left_topic", "key": 1, "value": {"V": 1}, "timestamp": 765, "window": {"start": 234, "end": 765, "type": "session"}},
        {"topic": "right_topic", "key": 1, "value": {"V": 2}, "timestamp": 567, "window": {"start": 234, "end": 567, "type": "session"}},
        {"topic": "right_topic", "key": 1, "value": {"V": 3}, "timestamp": 765, "window": {"start": 234, "end": 765, "type": "session"}}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 1, "value": {"S1_V": 1, "S2_V": 3}, "timestamp": 765, "window": {"start": 234, "end": 765, "type": "session"}}
      ],
      "post": {
        "sources": [
          {
            "name": "OUTPUT",
            "type": "stream",
            "keyFormat": {"format": "KAFKA", "windowType": "SESSION"},
            "schema": "S1_ID INT KEY, S1_V BIGINT, S2_V BIGINT"
          }
        ]
      }
    },
    {
      "name": "matching time-windowed join with different windows fails",
      "comments": [
        "Note: the two streams use a different window size. However, only the start of the window is serialized, so its possible to get a matching binary key",
        "This may meet users requirements, but KSQL does not support these joins... because it's crazy!"
      ],
      "statements": [
        "CREATE STREAM S1 (ID INT KEY, V bigint) WITH (kafka_topic='left_topic', value_format='JSON', WINDOW_TYPE='Hopping', WINDOW_SIZE='5 SECONDS');",
        "CREATE STREAM S2 (ID INT KEY, V bigint) WITH (kafka_topic='right_topic', value_format='JSON', WINDOW_TYPE='Tumbling', WINDOW_SIZE='2 SECOND');",
        "CREATE STREAM OUTPUT as SELECT *, S1.ROWTIME, S2.ROWTIME FROM S1 JOIN S2 WITHIN 1 MINUTE ON S1.ID = S2.ID;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlStatementException",
        "message": "Implicit repartitioning of windowed sources is not supported."
      }
    },
    {
      "name": "session - timed windowed",
      "comments": [
        "Session windows serialize both start and end window bounds, where as tumbling/hopping only serialize the start time.",
        "Keys will never be binary compatible, and hence KSQL should disallow such joins"
      ],
      "statements": [
        "CREATE STREAM S1 (ID INT KEY, V bigint) WITH (kafka_topic='left_topic', value_format='JSON', WINDOW_TYPE='Session');",
        "CREATE STREAM S2 (ID INT KEY, V bigint) WITH (kafka_topic='right_topic', value_format='JSON', WINDOW_TYPE='TUMBLING', WINDOW_SIZE='1 SECOND');",
        "CREATE STREAM OUTPUT as SELECT * FROM S1 JOIN S2 WITHIN 1 MINUTE ON S1.ID = S2.ID;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlStatementException",
        "message": "Incompatible windowed sources.\nLeft source: SESSION\nRight source: TUMBLING\nSession windowed sources can only be joined to other session windowed sources, and may still not result in expected behaviour as session bounds must be an exact match for the join to work\nHopping and tumbling windowed sources can only be joined to other hopping and tumbling windowed sources"
      }
    },
    {
      "name": "windowed - non-windowed - INT",
      "statements": [
        "CREATE STREAM S1 (ID INT KEY, V bigint) WITH (kafka_topic='left_topic', value_format='JSON', WINDOW_TYPE='SESSION');",
        "CREATE STREAM S2 (ID INT KEY, V bigint) WITH (kafka_topic='right_topic', value_format='JSON');",
        "CREATE STREAM OUTPUT as SELECT * FROM S1 JOIN S2 WITHIN 1 MINUTE ON S1.ID = S2.ID;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlStatementException",
        "message": "Can not join windowed source to non-windowed source.\n`S1` is SESSION windowed\n`S2` is not windowed"
      }
    },
    {
      "name": "windowed - non-windowed - STRING",
      "statements": [
        "CREATE STREAM S1 (ID STRING KEY, V bigint) WITH (kafka_topic='left_topic', value_format='JSON', WINDOW_TYPE='SESSION');",
        "CREATE STREAM S2 (ID STRING KEY, V bigint) WITH (kafka_topic='right_topic', value_format='JSON');",
        "CREATE STREAM OUTPUT as SELECT * FROM S1 JOIN S2 WITHIN 1 MINUTE ON S1.ID = S2.ID;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlStatementException",
        "message": "Can not join windowed source to non-windowed source.\n`S1` is SESSION windowed\n`S2` is not windowed"
      }
    },
    {
      "name": "join requiring repartition of windowed source",
      "statements": [
        "CREATE STREAM S1 (K INT KEY, ID INT, V bigint) WITH (kafka_topic='left_topic', value_format='JSON', WINDOW_TYPE='SESSION');",
        "CREATE STREAM S2 (K INT KEY, ID INT, V bigint) WITH (kafka_topic='right_topic', value_format='JSON', WINDOW_TYPE='SESSION');",
        "CREATE STREAM OUTPUT as SELECT * FROM S1 JOIN S2 WITHIN 1 MINUTE ON S1.ID = S2.ID;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlStatementException",
        "message": "Implicit repartitioning of windowed sources is not supported. See https://github.com/confluentinc/ksql/issues/4385."
      }
    },
    {
      "name": "on struct field",
      "statements": [
        "CREATE STREAM S1 (ID INT KEY, A bigint, B STRUCT<C INT>) WITH (kafka_topic='left_topic', value_format='JSON');",
        "CREATE STREAM S2 (ID INT KEY, X bigint, Y STRUCT<Z INT>) WITH (kafka_topic='right_topic', value_format='JSON');",
        "CREATE STREAM OUTPUT as SELECT *, S1.ROWTIME, S2.ROWTIME FROM S1 JOIN S2 WITHIN 1 MINUTE ON S1.B->C = S2.Y->Z;"
      ],
      "inputs": [
        {"topic": "left_topic", "key": 1, "value": {"A": 1, "B": {"C": 10}}, "timestamp": 20},
        {"topic": "right_topic", "key": 2, "value": {"X": 4, "Y": {"Z": 10}}, "timestamp": 100}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 10, "value": {"S1_ROWTIME": 20, "S1_ID": 1, "S1_A": 1, "S1_B": {"C": 10}, "S2_ROWTIME": 100, "S2_ID": 2, "S2_X": 4, "S2_Y": {"Z": 10}}, "timestamp": 100}
      ],
      "post": {
        "sources": [
          {
            "name": "OUTPUT",
            "type": "stream",
            "keyFormat": {"format": "KAFKA"},
            "schema": "ROWKEY INT KEY, S1_ID INT, S1_A BIGINT, S1_B STRUCT<C INT>, S2_ID INT, S2_X BIGINT, S2_Y STRUCT<Z INT>, S1_ROWTIME BIGINT, S2_ROWTIME BIGINT"
          }
        ]
      }
    },
    {
      "name": "with where",
      "statements": [
        "CREATE STREAM impressions (user VARCHAR KEY, impression_id BIGINT, url VARCHAR) WITH (kafka_topic='impressions', value_format='JSON');",
        "CREATE STREAM clicks (user VARCHAR KEY, url VARCHAR) WITH (kafka_topic='clicks', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT I.USER, IMPRESSION_ID, I.URL AS URL FROM impressions i JOIN clicks c WITHIN 1 minute ON i.user = c.user WHERE i.url = c.url;"
      ],
      "inputs": [
        {"topic": "impressions", "key": "user_0", "value": {"impression_id": 24, "url": "urlA"}, "timestamp": 10},
        {"topic": "clicks", "key": "user_0", "value": {"url": "urlX"}, "timestamp": 11},
        {"topic": "clicks", "key": "user_0", "value": {"url": "urlA"}, "timestamp": 12}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": "user_0", "value": {"IMPRESSION_ID": 24, "URL": "urlA"}, "timestamp":  12}
      ]
    },
    {
      "name": "streams with no key columns (stream->stream)",
      "statements": [
        "CREATE STREAM L (A INT, B INT, C INT) WITH (kafka_topic='LEFT', value_format='JSON');",
        "CREATE STREAM R (A INT, B INT, C INT) WITH (kafka_topic='RIGHT', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT * FROM L INNER JOIN R WITHIN 10 SECONDS ON L.A = R.A;"
      ],
      "inputs": [
        {"topic": "LEFT", "value": {"A": 0, "B": 1, "C": 2}, "timestamp": 10},
        {"topic": "RIGHT", "value": {"A": 0, "B": -1, "C": -2}, "timestamp": 11}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 0, "value": {"R_A": 0, "L_B": 1, "R_B": -1, "L_C": 2, "R_C": -2}, "timestamp":  11}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "L_A INT KEY, L_B INT, L_C INT, R_A INT, R_B INT, R_C INT"}
        ]
      }
    },
    {
      "name": "streams with no key columns (stream->table)",
      "statements": [
        "CREATE STREAM L (A INT, B INT, C INT) WITH (kafka_topic='LEFT', value_format='JSON');",
        "CREATE TABLE R (A INT PRIMARY KEY, B INT, C INT) WITH (kafka_topic='RIGHT', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT * FROM L INNER JOIN R ON L.A = R.A;"
      ],
      "inputs": [
        {"topic": "RIGHT", "key": 0, "value": {"B": -1, "C": -2}, "timestamp": 10},
        {"topic": "LEFT", "key": "ignored", "value": {"A": 0, "B": 1, "C": 2}, "timestamp": 11}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 0, "value": {"R_A": 0, "L_B": 1, "R_B": -1, "L_C": 2, "R_C": -2}, "timestamp":  11}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "schema": "L_A INT KEY, L_B INT, L_C INT, R_A INT, R_B INT, R_C INT"}
        ]
      }
    },
    {
      "name": "non-KAFKA key format",
      "statements": [
        "CREATE STREAM L (A INT KEY, B INT, C INT) WITH (kafka_topic='LEFT', format='JSON');",
        "CREATE TABLE R (A INT PRIMARY KEY, B INT, C INT) WITH (kafka_topic='RIGHT', format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT * FROM L INNER JOIN R ON L.A = R.A;"
      ],
      "inputs": [
        {"topic": "RIGHT", "key": 1, "value": {"B": -1, "C": -2}, "timestamp": 10},
        {"topic": "LEFT", "key": 1, "value": {"B": 1, "C": 2}, "timestamp": 11},
        {"topic": "LEFT", "key": 2, "value": {"B": 2, "C": 3}, "timestamp": 12}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 1, "value": {"R_A": 1, "L_B": 1, "R_B": -1, "L_C": 2, "R_C": -2}, "timestamp":  11}
      ]
    },
    {
      "name": "stream-stream key-to-key - key format mismatch",
      "statements": [
        "CREATE STREAM S1 (ID INT KEY, FOO INT) WITH (kafka_topic='s1', key_format='DELIMITED', value_format='JSON');",
        "CREATE STREAM S2 (ID INT KEY, VAL STRING) WITH (kafka_topic='s2', key_format='KAFKA', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT S1.ID, S2.VAL FROM S1 JOIN S2 WITHIN 10 SECONDS ON S1.ID = S2.ID;"
      ],
      "inputs": [
        {"topic": "s2", "key": 10, "value": {"VAL": "hello"}},
        {"topic": "s1", "key": "10", "value": {"foo": 22}}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": "10", "value": {"VAL": "hello"}}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "keyFormat": {"format": "DELIMITED"}}
        ],
        "topics" : {
          "topics" : [
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-Join-right-repartition",
              "keyFormat" : {"format" : "DELIMITED"},
              "valueFormat" : {"format" : "JSON"}
            },
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-KSTREAM-JOINTHIS-0000000012-store-changelog",
              "keyFormat" : {"format" : "DELIMITED"},
              "valueFormat" : {"format" : "JSON"}
            },
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-KSTREAM-JOINOTHER-0000000013-store-changelog",
              "keyFormat" : {"format" : "DELIMITED"},
              "valueFormat" : {"format" : "JSON"}
            }
          ]
        }
      }
    },
    {
      "name": "stream-stream key-to-key - key format and default feature mismatch",
      "statements": [
        "CREATE STREAM S1 (ID INT KEY, FOO INT) WITH (kafka_topic='s1', key_format='DELIMITED', value_format='JSON');",
        "CREATE STREAM S2 (ID INT KEY, VAL STRING) WITH (kafka_topic='s2', key_format='JSON', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT S1.ID, S2.VAL FROM S1 JOIN S2 WITHIN 10 SECONDS ON S1.ID = S2.ID;"
      ],
      "inputs": [
        {"topic": "s2", "key": 10, "value": {"VAL": "hello"}},
        {"topic": "s1", "key": "10", "value": {"foo": 22}}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": "10", "value": {"VAL": "hello"}}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "keyFormat": {"format": "DELIMITED"}}
        ],
        "topics" : {
          "topics" : [
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-Join-right-repartition",
              "keyFormat" : {"format" : "DELIMITED"},
              "valueFormat" : {"format" : "JSON"}
            },
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-KSTREAM-JOINTHIS-0000000012-store-changelog",
              "keyFormat" : {"format" : "DELIMITED"},
              "valueFormat" : {"format" : "JSON"}
            },
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-KSTREAM-JOINOTHER-0000000013-store-changelog",
              "keyFormat" : {"format" : "DELIMITED"},
              "valueFormat" : {"format" : "JSON"}
            }
          ]
        }
      }
    },
    {
      "name": "stream-stream key-to-key - protobuf on right key mismatch",
      "statements": [
        "CREATE STREAM S1 (ID INT KEY, FOO INT) WITH (kafka_topic='s1', key_format='DELIMITED', value_format='JSON');",
        "CREATE STREAM S2 (ID INT KEY, VAL STRING) WITH (kafka_topic='s2', key_format='PROTOBUF', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT S1.ID, S2.VAL FROM S1 JOIN S2 WITHIN 10 SECONDS ON S1.ID = S2.ID;"
      ],
      "inputs": [
        {"topic": "s2", "key": {"ID": 10}, "value": {"VAL": "hello"}},
        {"topic": "s1", "key": "10", "value": {"foo": 22}}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": "10", "value": {"VAL": "hello"}}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "keyFormat": {"format": "DELIMITED"}}
        ],
        "topics" : {
          "topics" : [
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-Join-right-repartition",
              "keyFormat" : {"format" : "DELIMITED"},
              "valueFormat" : {"format" : "JSON"}
            },
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-KSTREAM-JOINTHIS-0000000012-store-changelog",
              "keyFormat" : {"format" : "DELIMITED"},
              "valueFormat" : {"format" : "JSON"}
            },
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-KSTREAM-JOINOTHER-0000000013-store-changelog",
              "keyFormat" : {"format" : "DELIMITED"},
              "valueFormat" : {"format" : "JSON"}
            }
          ]
        }
      }
    },
    {
      "name": "stream-stream key-to-key - protobuf on left key mismatch",
      "statements": [
        "CREATE STREAM S1 (ID INT KEY, FOO INT) WITH (kafka_topic='s1', key_format='PROTOBUF', value_format='JSON');",
        "CREATE STREAM S2 (ID INT KEY, VAL STRING) WITH (kafka_topic='s2', key_format='JSON', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT S1.ID, S2.VAL FROM S1 JOIN S2 WITHIN 10 SECONDS ON S1.ID = S2.ID;"
      ],
      "inputs": [
        {"topic": "s2", "key": "10", "value": {"VAL": "hello"}},
        {"topic": "s1", "key": {"ID": 10}, "value": {"foo": 22}}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": {"S1_ID": 10}, "value": {"VAL": "hello"}}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "keyFormat": {"format": "PROTOBUF", "properties": {"unwrapPrimitives": "true"}}}
        ],
        "topics" : {
          "topics" : [
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-Join-right-repartition",
              "keyFormat" : {"format" : "PROTOBUF", "properties" : {"unwrapPrimitives" : "true"}},
              "valueFormat" : {"format" : "JSON"}
            },
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-KSTREAM-JOINTHIS-0000000016-store-changelog",
              "keyFormat" : {"format" : "PROTOBUF", "properties" : {"unwrapPrimitives" : "true"}},
              "valueFormat" : {"format" : "JSON"}
            },
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-KSTREAM-JOINOTHER-0000000017-store-changelog",
              "keyFormat" : {"format" : "PROTOBUF", "properties" : {"unwrapPrimitives" : "true"}},
              "valueFormat" : {"format" : "JSON"}
            }
          ]
        }
      }
    },
    {
      "name": "stream-stream value-to-key - key format mismatch",
      "statements": [
        "CREATE STREAM S1 (ID INT, FOO INT) WITH (kafka_topic='s1', key_format='NONE', value_format='JSON');",
        "CREATE STREAM S2 (ID INT KEY, VAL STRING) WITH (kafka_topic='s2', key_format='KAFKA', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT S1.ID, S2.VAL FROM S1 LEFT JOIN S2 WITHIN 10 SECONDS ON S1.ID = S2.ID;"
      ],
      "inputs": [
        {"topic": "s1", "value": {"id": 10, "foo": 22}},
        {"topic": "s2", "key": 10, "value": {"VAL": "hello"}}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 10, "value": {"VAL": null}},
        {"topic": "OUTPUT", "key": 10, "value": {"VAL": "hello"}}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "keyFormat": {"format": "KAFKA"}}
        ],
        "topics" : {
          "topics" : [
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-Join-left-repartition",
              "keyFormat" : {"format" : "KAFKA"},
              "valueFormat" : {"format" : "JSON"}
            },
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-KSTREAM-JOINTHIS-0000000012-store-changelog",
              "keyFormat" : {"format" : "KAFKA"},
              "valueFormat" : {"format" : "JSON"}
            },
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-KSTREAM-OUTEROTHER-0000000013-store-changelog",
              "keyFormat" : {"format" : "KAFKA"},
              "valueFormat" : {"format" : "JSON"}
            }
          ]
        }
      }
    },
    {
      "name": "stream-stream key-to-value - key format mismatch",
      "statements": [
        "CREATE STREAM S1 (ID INT KEY, FOO INT) WITH (kafka_topic='s1', key_format='DELIMITED', value_format='JSON');",
        "CREATE STREAM S2 (ID INT, VAL STRING) WITH (kafka_topic='s2', key_format='NONE', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT S1.ID, S2.VAL FROM S1 LEFT OUTER JOIN S2 WITHIN 10 SECONDS ON S1.ID = S2.ID;"
      ],
      "inputs": [
        {"topic": "s1", "key": "10", "value": {"foo": 22}},
        {"topic": "s2", "value": {"ID": 10, "VAL": "hello"}}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": "10", "value": {"VAL": null}},
        {"topic": "OUTPUT", "key": "10", "value": {"VAL": "hello"}}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "keyFormat": {"format": "DELIMITED"}}
        ],
        "topics" : {
          "topics" : [
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-Join-right-repartition",
              "keyFormat" : {"format" : "DELIMITED"},
              "valueFormat" : {"format" : "JSON"}
            },
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-KSTREAM-JOINTHIS-0000000012-store-changelog",
              "keyFormat" : {"format" : "DELIMITED"},
              "valueFormat" : {"format" : "JSON"}
            },
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-KSTREAM-OUTEROTHER-0000000013-store-changelog",
              "keyFormat" : {"format" : "DELIMITED"},
              "valueFormat" : {"format" : "JSON"}
            }
          ]
        }
      }
    },
    {
      "name": "stream-stream value-to-value - keyless",
      "statements": [
        "CREATE STREAM S1 (ID INT, FOO INT) WITH (kafka_topic='s1', key_format='NONE', value_format='JSON');",
        "CREATE STREAM S2 (ID INT, VAL STRING) WITH (kafka_topic='s2', key_format='NONE', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT S1.ID, S2.VAL FROM S1 LEFT OUTER JOIN S2 WITHIN 10 SECONDS ON S1.ID = S2.ID;"
      ],
      "properties": {
        "ksql.persistence.default.format.key": "DELIMITED"
      },
      "inputs": [
        {"topic": "s1", "value": {"ID": 10, "foo": 22}},
        {"topic": "s2", "value": {"ID": 10, "VAL": "hello"}}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": "10", "value": {"VAL": null}},
        {"topic": "OUTPUT", "key": "10", "value": {"VAL": "hello"}}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "keyFormat": {"format": "DELIMITED"}}
        ],
        "topics" : {
          "topics" : [
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-Join-left-repartition",
              "keyFormat" : {"format" : "DELIMITED"},
              "valueFormat" : {"format" : "JSON"}
            },
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-Join-right-repartition",
              "keyFormat" : {"format" : "DELIMITED"},
              "valueFormat" : {"format" : "JSON"}
            },
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-KSTREAM-JOINTHIS-0000000016-store-changelog",
              "keyFormat" : {"format" : "DELIMITED"},
              "valueFormat" : {"format" : "JSON"}
            },
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-KSTREAM-OUTEROTHER-0000000017-store-changelog",
              "keyFormat" : {"format" : "DELIMITED"},
              "valueFormat" : {"format" : "JSON"}
            }
          ]
        }
      }
    },
    {
      "name": "stream-table key-to-key - key format mismatch",
      "statements": [
        "CREATE TABLE T (ID INT PRIMARY KEY, VAL STRING) WITH (kafka_topic='t', key_format='KAFKA', value_format='JSON');",
        "CREATE STREAM S (ID INT KEY, FOO INT) WITH (kafka_topic='s', key_format='DELIMITED', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT S.ID, VAL FROM S JOIN T ON S.ID = T.ID;"
      ],
      "inputs": [
        {"topic": "t", "key": 10, "value": {"VAL": "hello"}},
        {"topic": "s", "key": "10", "value": {"foo": 22}}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": "10", "value": {"VAL": "hello"}}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "keyFormat": {"format": "DELIMITED"}}
        ],
        "topics" : {
          "topics" : [
            {
              "name": "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-RightSourceKeyed-SelectKey-repartition",
              "keyFormat": { "format": "DELIMITED" },
              "valueFormat": { "format": "JSON" }
            },
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-RightSourceKeyed-Materialize-changelog",
              "keyFormat" : {"format" : "DELIMITED"},
              "valueFormat" : {"format" : "JSON"}
            }
          ]
        }
      }
    },
    {
      "name": "stream-table value-to-key - key format mismatch",
      "statements": [
        "CREATE TABLE T (ID INT PRIMARY KEY, VAL STRING) WITH (kafka_topic='t', key_format='KAFKA', value_format='JSON');",
        "CREATE STREAM S (ID INT KEY, FOO INT) WITH (kafka_topic='s', key_format='DELIMITED', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT S.FOO, VAL FROM S LEFT JOIN T ON S.FOO = T.ID;"
      ],
      "inputs": [
        {"topic": "t", "key": 10, "value": {"VAL": "hello"}},
        {"topic": "s", "key": "22", "value": {"foo": 10}}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": "10", "value": {"VAL": "hello"}}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "keyFormat": {"format": "DELIMITED"}}
        ],
        "topics" : {
          "topics" : [
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-Join-repartition",
              "keyFormat" : {"format" : "KAFKA"},
              "valueFormat" : {"format" : "JSON"}
            },
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-KafkaTopic_Right-Reduce-changelog",
              "keyFormat" : {"format" : "KAFKA"},
              "valueFormat" : {"format" : "JSON"}
            }
          ]
        }
      }
    },
    {
      "name": "stream-table val-to-key - keyless",
      "statements": [
        "CREATE TABLE T (ID INT PRIMARY KEY, VAL STRING) WITH (kafka_topic='t', key_format='KAFKA', value_format='JSON');",
        "CREATE STREAM S (ID INT, FOO INT) WITH (kafka_topic='s', key_format='NONE', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT S.ID, VAL FROM S LEFT JOIN T ON S.ID = T.ID;"
      ],
      "inputs": [
        {"topic": "t", "key": 10, "value": {"VAL": "hello"}},
        {"topic": "s", "value": {"ID": 10, "foo": "22"}}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 10, "value": {"VAL": "hello"}}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "keyFormat": {"format": "KAFKA"}}
        ],
        "topics" : {
          "topics": [
            {
              "name": "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-KafkaTopic_Right-Reduce-changelog",
              "keyFormat": {"format": "KAFKA"},
              "valueFormat": {"format": "JSON"}
            },
            {
              "name": "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-Join-repartition",
              "keyFormat": {"format": "KAFKA"},
              "valueFormat": {"format": "JSON"}
            }
          ]
        }
      }
    },
    {
      "name": "table-table key-to-key - key format mismatch",
      "statements": [
        "CREATE TABLE T1 (ID INT PRIMARY KEY, VAL STRING) WITH (kafka_topic='t1', key_format='KAFKA', value_format='JSON');",
        "CREATE TABLE T2 (ID INT PRIMARY KEY, FOO INT) WITH (kafka_topic='t2', key_format='DELIMITED', value_format='JSON');",
        "CREATE TABLE OUTPUT AS SELECT * FROM T1 JOIN T2 ON T1.ID = T2.ID;"
      ],
      "inputs": [
        {"topic": "t1", "key": 10, "value": {"VAL": "hello"}},
        {"topic": "t2", "key": "10", "value": {"FOO": 1}}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 10, "value": {"T1_VAL": "hello", "T2_ID": 10, "T2_FOO": 1}}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "table", "keyFormat": {"format": "KAFKA"}}
        ],
        "topics" : {
          "topics": [
            {
              "name": "_confluent-ksql-some.ksql.service.idquery_CTAS_OUTPUT_0-RightSourceKeyed-Materialize-changelog",
              "keyFormat": { "format": "KAFKA" },
              "valueFormat": { "format": "JSON" }
            },
            {
              "name": "_confluent-ksql-some.ksql.service.idquery_CTAS_OUTPUT_0-RightSourceKeyed-SelectKey-repartition",
              "keyFormat": { "format": "KAFKA" },
              "valueFormat": { "format": "JSON" }
            }
          ]
        }
      }
    },
    {
      "name": "stream-stream key-to-key - SR-enabled key format",
      "statements": [
        "CREATE STREAM S1 (ID INT KEY, FOO INT) WITH (kafka_topic='s1', key_format='AVRO', value_format='JSON');",
        "CREATE STREAM S2 (ID INT KEY, VAL STRING) WITH (kafka_topic='s2', key_format='AVRO', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT S1.ID, S2.VAL FROM S1 LEFT OUTER JOIN S2 WITHIN 10 SECONDS ON S1.ID = S2.ID;"
      ],
      "inputs": [
        {"topic": "s1", "key": 10, "value": {"foo": 22}},
        {"topic": "s2", "key": 10, "value": {"VAL": "hello"}}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 10, "value": {"VAL": null}},
        {"topic": "OUTPUT", "key": 10, "value": {"VAL": "hello"}}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "keyFormat": {"format": "AVRO"}}
        ],
        "topics" : {
          "topics" : [
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-Join-left-repartition",
              "keyFormat" : {
                "format" : "AVRO",
                "features": ["UNWRAP_SINGLES"],
                "properties": {"fullSchemaName": "io.confluent.ksql.avro_schemas.S1Key"}
              },
              "valueFormat" : {"format" : "JSON"}
            },
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-Join-right-repartition",
              "keyFormat" : {
                "format" : "AVRO",
                "features": ["UNWRAP_SINGLES"],
                "properties": {"fullSchemaName": "io.confluent.ksql.avro_schemas.S1Key"}
              },
              "valueFormat" : {"format" : "JSON"}
            },
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-KSTREAM-JOINTHIS-0000000016-store-changelog",
              "keyFormat" : {
                "format" : "AVRO",
                "features": ["UNWRAP_SINGLES"],
                "properties": {"fullSchemaName": "io.confluent.ksql.avro_schemas.S1Key"}
              },
              "valueFormat" : {"format" : "JSON"}
            },
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-KSTREAM-OUTEROTHER-0000000017-store-changelog",
              "keyFormat" : {
                "format" : "AVRO",
                "features": ["UNWRAP_SINGLES"],
                "properties": {"fullSchemaName": "io.confluent.ksql.avro_schemas.S1Key"}
              },
              "valueFormat" : {"format" : "JSON"}
            }
          ]
        }
      }
    },
    {
      "name": "stream-table key-to-key - SR-enabled key format",
      "statements": [
        "CREATE TABLE T (ID INT PRIMARY KEY, VAL STRING) WITH (kafka_topic='t', key_format='AVRO', value_format='JSON');",
        "CREATE STREAM S (ID INT KEY, FOO INT) WITH (kafka_topic='s', key_format='AVRO', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT S.ID, VAL FROM S JOIN T ON S.ID = T.ID;"
      ],
      "inputs": [
        {"topic": "t", "key": 10, "value": {"VAL": "hello"}},
        {"topic": "s", "key": 10, "value": {"foo": 22}}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 10, "value": {"VAL": "hello"}}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "keyFormat": {"format": "AVRO"}}
        ],
        "topics" : {
          "topics" : [
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-Join-repartition",
              "keyFormat" : {
                "format" : "AVRO",
                "features": ["UNWRAP_SINGLES"],
                "properties": {"fullSchemaName": "io.confluent.ksql.avro_schemas.SKey"}
              },
              "valueFormat" : {"format" : "JSON"}
            },
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-RightSourceKeyed-SelectKey-repartition",
              "keyFormat" : {
                "format" : "AVRO",
                "features": ["UNWRAP_SINGLES"],
                "properties": {"fullSchemaName": "io.confluent.ksql.avro_schemas.SKey"}
              },
              "valueFormat" : {"format" : "JSON"}
            },
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-RightSourceKeyed-Materialize-changelog",
              "keyFormat" : {
                "format" : "AVRO",
                "features": ["UNWRAP_SINGLES"],
                "properties": {"fullSchemaName": "io.confluent.ksql.avro_schemas.SKey"}
              },
              "valueFormat" : {"format" : "JSON"}
            }
          ]
        }
      }
    },
    {
      "name": "table-table - SR-enabled key format",
      "statements": [
        "CREATE TABLE T1 (ID BIGINT PRIMARY KEY, NAME varchar) WITH (kafka_topic='t1', key_format='AVRO', value_format='JSON');",
        "CREATE TABLE T2 (ID BIGINT PRIMARY KEY, F1 varchar) WITH (kafka_topic='t2', key_format='AVRO', value_format='JSON');",
        "CREATE TABLE OUTPUT as SELECT T1.id, name, f1 FROM T1 left join T2 on T1.id = T2.id;"
      ],
      "inputs": [
        {"topic": "t1", "key": 0, "value": {"NAME": "zero"}},
        {"topic": "t2", "key": 0, "value": {"F1": "blah"}}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "zero", "F1": null}},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "zero", "F1": "blah"}}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "table", "keyFormat": {"format": "AVRO"}}
        ],
        "topics" : {
          "topics" : [
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CTAS_OUTPUT_0-LeftSourceKeyed-SelectKey-repartition",
              "keyFormat" : {
                "format" : "AVRO",
                "features": ["UNWRAP_SINGLES"],
                "properties": {"fullSchemaName": "io.confluent.ksql.avro_schemas.T1Key"}
              },
              "valueFormat" : {"format" : "JSON"}
            },
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CTAS_OUTPUT_0-RightSourceKeyed-SelectKey-repartition",
              "keyFormat" : {
                "format" : "AVRO",
                "features": ["UNWRAP_SINGLES"],
                "properties": {"fullSchemaName": "io.confluent.ksql.avro_schemas.T1Key"}
              },
              "valueFormat" : {"format" : "JSON"}
            },
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CTAS_OUTPUT_0-LeftSourceKeyed-Materialize-changelog",
              "keyFormat" : {
                "format" : "AVRO",
                "features": ["UNWRAP_SINGLES"],
                "properties": {"fullSchemaName": "io.confluent.ksql.avro_schemas.T1Key"}
              },
              "valueFormat" : {"format" : "JSON"}
            },
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CTAS_OUTPUT_0-RightSourceKeyed-Materialize-changelog",
              "keyFormat" : {
                "format" : "AVRO",
                "features": ["UNWRAP_SINGLES"],
                "properties": {"fullSchemaName": "io.confluent.ksql.avro_schemas.T1Key"}
              },
              "valueFormat" : {"format" : "JSON"}
            }
          ]
        }
      }
    },
    {
      "name": "table-table - SR-enabled key format - with nulls",
      "statements": [
        "CREATE TABLE T1 (ID BIGINT PRIMARY KEY, NAME varchar) WITH (kafka_topic='t1', key_format='AVRO', value_format='JSON');",
        "CREATE TABLE T2 (ID BIGINT PRIMARY KEY, F1 varchar) WITH (kafka_topic='t2', key_format='AVRO', value_format='JSON');",
        "CREATE TABLE OUTPUT as SELECT T1.id, name, f1 FROM T1 left join T2 on T1.id = T2.id;"
      ],
      "inputs": [
        {"topic": "t1", "key": 0, "value": {"NAME": "zero"}},
        {"topic": "t2", "key": 0, "value": {"F1": "blah"}},
        {"topic": "t2", "key": 0, "value": null},
        {"topic": "t1", "key": 0, "value": null},
        {"topic": "t2", "key": 0, "value": {"F1": "foo"}},
        {"topic": "t1", "key": 0, "value": {"NAME": "goo"}}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "zero", "F1": null}},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "zero", "F1": "blah"}},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "zero", "F1": null}},
        {"topic": "OUTPUT", "key": 0, "value": null},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "goo", "F1": "foo"}}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "table", "keyFormat": {"format": "AVRO"}}
        ],
        "topics" : {
          "topics" : [
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CTAS_OUTPUT_0-LeftSourceKeyed-SelectKey-repartition",
              "keyFormat" : {
                "format" : "AVRO",
                "features": ["UNWRAP_SINGLES"],
                "properties": {"fullSchemaName": "io.confluent.ksql.avro_schemas.T1Key"}
              },
              "valueFormat" : {"format" : "JSON"}
            },
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CTAS_OUTPUT_0-RightSourceKeyed-SelectKey-repartition",
              "keyFormat" : {
                "format" : "AVRO",
                "features": ["UNWRAP_SINGLES"],
                "properties": {"fullSchemaName": "io.confluent.ksql.avro_schemas.T1Key"}
              },
              "valueFormat" : {"format" : "JSON"}
            },
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CTAS_OUTPUT_0-LeftSourceKeyed-Materialize-changelog",
              "keyFormat" : {
                "format" : "AVRO",
                "features": ["UNWRAP_SINGLES"],
                "properties": {"fullSchemaName": "io.confluent.ksql.avro_schemas.T1Key"}
              },
              "valueFormat" : {"format" : "JSON"}
            },
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CTAS_OUTPUT_0-RightSourceKeyed-Materialize-changelog",
              "keyFormat" : {
                "format" : "AVRO",
                "features": ["UNWRAP_SINGLES"],
                "properties": {"fullSchemaName": "io.confluent.ksql.avro_schemas.T1Key"}
              },
              "valueFormat" : {"format" : "JSON"}
            }
          ]
        }
      }
    },
    {
      "name": "stream-stream key-to-key - SR-enabled key format - with inference",
      "statements": [
        "CREATE STREAM S1 (FOO INT) WITH (kafka_topic='s1', key_format='JSON_SR', value_format='JSON');",
        "CREATE STREAM S2 (VAL STRING) WITH (kafka_topic='s2', key_format='JSON_SR', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT S1.ROWKEY, S2.VAL FROM S1 LEFT OUTER JOIN S2 WITHIN 10 SECONDS ON S1.ROWKEY = S2.ROWKEY;"
      ],
      "topics": [
        {
          "name": "s1",
          "keyFormat": "JSON_SR",
          "keySchema": {"oneOf":[{"type":"null"},{"type":"integer","connect.type":"int32"}]}
        },
        {
          "name": "s2",
          "keyFormat": "JSON_SR",
          "keySchema": {"oneOf":[{"type":"null"},{"type":"integer","connect.type":"int32"}]}
        }
      ],
      "inputs": [
        {"topic": "s1", "key": 10, "value": {"foo": 22}},
        {"topic": "s2", "key": 10, "value": {"VAL": "hello"}}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 10, "value": {"VAL": null}},
        {"topic": "OUTPUT", "key": 10, "value": {"VAL": "hello"}}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "keyFormat": {"format": "JSON_SR"}}
        ],
        "topics" : {
          "topics" : [
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-Join-left-repartition",
              "keyFormat" : {"format" : "JSON_SR", "features": ["UNWRAP_SINGLES"]},
              "valueFormat" : {"format" : "JSON"}
            },
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-Join-right-repartition",
              "keyFormat" : {"format" : "JSON_SR", "features": ["UNWRAP_SINGLES"]},
              "valueFormat" : {"format" : "JSON"}
            },
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-KSTREAM-JOINTHIS-0000000016-store-changelog",
              "keyFormat" : {"format" : "JSON_SR", "features": ["UNWRAP_SINGLES"]},
              "valueFormat" : {"format" : "JSON"}
            },
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-KSTREAM-OUTEROTHER-0000000017-store-changelog",
              "keyFormat" : {"format" : "JSON_SR", "features": ["UNWRAP_SINGLES"]},
              "valueFormat" : {"format" : "JSON"}
            }
          ]
        }
      }
    },
    {
      "name": "stream-stream key-to-key - SR-enabled key format - with inference - different schemas",
      "statements": [
        "CREATE STREAM S1 (FOO INT) WITH (kafka_topic='s1', key_format='JSON_SR', value_format='JSON');",
        "CREATE STREAM S2 (VAL STRING) WITH (kafka_topic='s2', key_format='JSON_SR', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT S1.ROWKEY, S2.VAL FROM S1 LEFT OUTER JOIN S2 WITHIN 10 SECONDS ON S1.ROWKEY = S2.ROWKEY;"
      ],
      "topics": [
        {
          "name": "s1",
          "keyFormat": "JSON_SR",
          "keySchema": {"type":"integer","connect.type":"int32"}
        },
        {
          "name": "s2",
          "keyFormat": "JSON_SR",
          "keySchema": {"oneOf":[{"type":"null"},{"type":"integer","connect.type":"int32"}]}
        }
      ],
      "inputs": [
        {"topic": "s1", "key": 10, "value": {"foo": 22}},
        {"topic": "s2", "key": 10, "value": {"VAL": "hello"}}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 10, "value": {"VAL": null}},
        {"topic": "OUTPUT", "key": 10, "value": {"VAL": "hello"}}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "keyFormat": {"format": "JSON_SR"}}
        ],
        "topics" : {
          "topics" : [
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-Join-left-repartition",
              "keyFormat" : {"format" : "JSON_SR", "features": ["UNWRAP_SINGLES"]},
              "keySchema" : {"oneOf":[{"type":"null"},{"type":"integer","connect.type":"int32"}]},
              "valueFormat" : {"format" : "JSON"}
            },
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-Join-right-repartition",
              "keyFormat" : {"format" : "JSON_SR", "features": ["UNWRAP_SINGLES"]},
              "keySchema" : {"oneOf":[{"type":"null"},{"type":"integer","connect.type":"int32"}]},
              "valueFormat" : {"format" : "JSON"}
            },
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-KSTREAM-JOINTHIS-0000000016-store-changelog",
              "keyFormat" : {"format" : "JSON_SR", "features": ["UNWRAP_SINGLES"]},
              "keySchema" : {"oneOf":[{"type":"null"},{"type":"integer","connect.type":"int32"}]},
              "valueFormat" : {"format" : "JSON"}
            },
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-KSTREAM-OUTEROTHER-0000000017-store-changelog",
              "keyFormat" : {"format" : "JSON_SR", "features": ["UNWRAP_SINGLES"]},
              "keySchema" : {"oneOf":[{"type":"null"},{"type":"integer","connect.type":"int32"}]},
              "valueFormat" : {"format" : "JSON"}
            }
          ]
        }
      }
    },
    {
      "name": "stream-table key-to-key - SR-enabled key format - with inference - different schemas",
      "statements": [
        "CREATE TABLE T (VAL STRING) WITH (kafka_topic='t', key_format='JSON_SR', value_format='JSON');",
        "CREATE STREAM S (FOO INT) WITH (kafka_topic='s', key_format='JSON_SR', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT S.ROWKEY, VAL FROM S JOIN T ON S.ROWKEY = T.ROWKEY;"
      ],
      "topics": [
        {
          "name": "t",
          "keyFormat": "JSON_SR",
          "keySchema": {"type":"integer","connect.type":"int32"}
        },
        {
          "name": "s",
          "keyFormat": "JSON_SR",
          "keySchema": {"oneOf":[{"type":"null"},{"type":"integer","connect.type":"int32"}]}
        }
      ],
      "inputs": [
        {"topic": "t", "key": 10, "value": {"VAL": "hello"}},
        {"topic": "s", "key": 10, "value": {"foo": 22}}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 10, "value": {"VAL": "hello"}}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "keyFormat": {"format": "JSON_SR"}}
        ],
        "topics" : {
          "topics" : [
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-Join-repartition",
              "keyFormat" : {"format" : "JSON_SR", "features": ["UNWRAP_SINGLES"]},
              "keySchema" : {"oneOf":[{"type":"null"},{"type":"integer","connect.type":"int32"}]},
              "valueFormat" : {"format" : "JSON"}
            },
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-RightSourceKeyed-SelectKey-repartition",
              "keyFormat" : {"format" : "JSON_SR", "features": ["UNWRAP_SINGLES"]},
              "keySchema" : {"oneOf":[{"type":"null"},{"type":"integer","connect.type":"int32"}]},
              "valueFormat" : {"format" : "JSON"}
            },
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-RightSourceKeyed-Materialize-changelog",
              "keyFormat" : {"format" : "JSON_SR", "features": ["UNWRAP_SINGLES"]},
              "keySchema" : {"oneOf":[{"type":"null"},{"type":"integer","connect.type":"int32"}]},
              "valueFormat" : {"format" : "JSON"}
            }
          ]
        }
      }
    },
    {
      "name": "table-table - SR-enabled key format - with inference - different schemas",
      "statements": [
        "CREATE TABLE T1 (NAME varchar) WITH (kafka_topic='t1', key_format='JSON_SR', value_format='JSON');",
        "CREATE TABLE T2 (F1 varchar) WITH (kafka_topic='t2', key_format='JSON_SR', value_format='JSON');",
        "CREATE TABLE OUTPUT as SELECT T1.ROWKEY, name, f1 FROM T1 left join T2 on T1.ROWKEY = T2.ROWKEY;"
      ],
      "topics": [
        {
          "name": "t1",
          "keyFormat": "JSON_SR",
          "keySchema": {"type":"integer","connect.type":"int32"}
        },
        {
          "name": "t2",
          "keyFormat": "JSON_SR",
          "keySchema": {"oneOf":[{"type":"null"},{"type":"integer","connect.type":"int32"}]}
        }
      ],
      "inputs": [
        {"topic": "t1", "key": 0, "value": {"NAME": "zero"}},
        {"topic": "t2", "key": 0, "value": {"F1": "blah"}}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "zero", "F1": null}},
        {"topic": "OUTPUT", "key": 0, "value": {"NAME": "zero", "F1": "blah"}}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "table", "keyFormat": {"format": "JSON_SR"}}
        ],
        "topics" : {
          "topics" : [
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CTAS_OUTPUT_0-LeftSourceKeyed-SelectKey-repartition",
              "keyFormat" : {"format" : "JSON_SR", "features": ["UNWRAP_SINGLES"]},
              "keySchema" : {"oneOf":[{"type":"null"},{"type":"integer","connect.type":"int32"}]},
              "valueFormat" : {"format" : "JSON"}
            },
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CTAS_OUTPUT_0-RightSourceKeyed-SelectKey-repartition",
              "keyFormat" : {"format" : "JSON_SR", "features": ["UNWRAP_SINGLES"]},
              "keySchema" : {"oneOf":[{"type":"null"},{"type":"integer","connect.type":"int32"}]},
              "valueFormat" : {"format" : "JSON"}
            },
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CTAS_OUTPUT_0-LeftSourceKeyed-Materialize-changelog",
              "keyFormat" : {"format" : "JSON_SR", "features": ["UNWRAP_SINGLES"]},
              "keySchema" : {"oneOf":[{"type":"null"},{"type":"integer","connect.type":"int32"}]},
              "valueFormat" : {"format" : "JSON"}
            },
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CTAS_OUTPUT_0-RightSourceKeyed-Materialize-changelog",
              "keyFormat" : {"format" : "JSON_SR", "features": ["UNWRAP_SINGLES"]},
              "keySchema" : {"oneOf":[{"type":"null"},{"type":"integer","connect.type":"int32"}]},
              "valueFormat" : {"format" : "JSON"}
            }
          ]
        }
      }
    },
    {
      "name": "stream-stream key-to-key - SR-enabled key and value format - with inference - different key schemas",
      "statements": [
        "CREATE STREAM S1 WITH (kafka_topic='s1', format='JSON_SR');",
        "CREATE STREAM S2 WITH (kafka_topic='s2', format='JSON_SR');",
        "CREATE STREAM OUTPUT AS SELECT S1.ROWKEY, S2.VAL FROM S1 LEFT OUTER JOIN S2 WITHIN 10 SECONDS ON S1.ROWKEY = S2.ROWKEY;"
      ],
      "topics": [
        {
          "name": "s1",
          "keyFormat": "JSON_SR",
          "keySchema": {"type":"integer","connect.type":"int32"},
          "valueFormat": "JSON_SR",
          "valueSchema": {"type":"object","properties":{"FOO":{"connect.index":0,"oneOf":[{"type":"null"},{"type":"integer","connect.type":"int32"}]}}}
        },
        {
          "name": "s2",
          "keyFormat": "JSON_SR",
          "keySchema": {"oneOf":[{"type":"null"},{"type":"integer","connect.type":"int32"}]},
          "valueFormat": "JSON_SR",
          "valueSchema": {"type":"object","properties":{"VAL":{"connect.index":0,"oneOf":[{"type":"null"},{"type":"string","connect.type":"int32"}]}}}
        }
      ],
      "inputs": [
        {"topic": "s1", "key": 10, "value": {"foo": 22}},
        {"topic": "s2", "key": 10, "value": {"VAL": "hello"}}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 10, "value": {"VAL": null}},
        {"topic": "OUTPUT", "key": 10, "value": {"VAL": "hello"}}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "keyFormat": {"format": "JSON_SR"}}
        ],
        "topics" : {
          "topics" : [
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-Join-left-repartition",
              "keyFormat" : {"format" : "JSON_SR", "features": ["UNWRAP_SINGLES"]},
              "keySchema" : {"oneOf":[{"type":"null"},{"type":"integer","connect.type":"int32"}]},
              "valueFormat" : {"format" : "JSON_SR"}
            },
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-Join-right-repartition",
              "keyFormat" : {"format" : "JSON_SR", "features": ["UNWRAP_SINGLES"]},
              "keySchema" : {"oneOf":[{"type":"null"},{"type":"integer","connect.type":"int32"}]},
              "valueFormat" : {"format" : "JSON_SR"}
            },
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-KSTREAM-JOINTHIS-0000000016-store-changelog",
              "keyFormat" : {"format" : "JSON_SR", "features": ["UNWRAP_SINGLES"]},
              "keySchema" : {"oneOf":[{"type":"null"},{"type":"integer","connect.type":"int32"}]},
              "valueFormat" : {"format" : "JSON_SR"}
            },
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-KSTREAM-OUTEROTHER-0000000017-store-changelog",
              "keyFormat" : {"format" : "JSON_SR", "features": ["UNWRAP_SINGLES"]},
              "keySchema" : {"oneOf":[{"type":"null"},{"type":"integer","connect.type":"int32"}]},
              "valueFormat" : {"format" : "JSON_SR"}
            }
          ]
        }
      }
    },
    {
      "name": "stream-stream key-to-key - SR-enabled key format - with inference - different schemas - outer join",
      "statements": [
        "CREATE STREAM S1 (FOO INT) WITH (kafka_topic='s1', key_format='JSON_SR', value_format='JSON');",
        "CREATE STREAM S2 (VAL STRING) WITH (kafka_topic='s2', key_format='JSON_SR', value_format='JSON');",
        "CREATE STREAM OUTPUT AS SELECT ROWKEY_1, AS_VALUE(S1.ROWKEY) AS S1_KEY, AS_VALUE(S2.ROWKEY) AS S2_KEY, S2.VAL FROM S1 FULL OUTER JOIN S2 WITHIN 10 SECONDS ON S1.ROWKEY = S2.ROWKEY;"
      ],
      "topics": [
        {
          "name": "s1",
          "keyFormat": "JSON_SR",
          "keySchema": {"type":"integer","connect.type":"int32"}
        },
        {
          "name": "s2",
          "keyFormat": "JSON_SR",
          "keySchema": {"oneOf":[{"type":"null"},{"type":"integer","connect.type":"int32"}]}
        }
      ],
      "inputs": [
        {"topic": "s1", "key": 10, "value": {"foo": 22}},
        {"topic": "s2", "key": 10, "value": {"VAL": "hello"}}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 10, "value": {"S1_KEY": 10, "S2_KEY": null, "VAL": null}},
        {"topic": "OUTPUT", "key": 10, "value": {"S1_KEY": 10, "S2_KEY": 10, "VAL": "hello"}}
      ],
      "post": {
        "sources": [
          {"name": "OUTPUT", "type": "stream", "keyFormat": {"format": "JSON_SR"}}
        ],
        "topics" : {
          "topics" : [
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-Join-left-repartition",
              "keyFormat" : {"format" : "JSON_SR", "features": ["UNWRAP_SINGLES"]},
              "keySchema" : {"oneOf":[{"type":"null"},{"type":"integer","connect.type":"int32"}]},
              "valueFormat" : {"format" : "JSON"}
            },
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-Join-right-repartition",
              "keyFormat" : {"format" : "JSON_SR", "features": ["UNWRAP_SINGLES"]},
              "keySchema" : {"oneOf":[{"type":"null"},{"type":"integer","connect.type":"int32"}]},
              "valueFormat" : {"format" : "JSON"}
            },
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-KSTREAM-OUTERTHIS-0000000016-store-changelog",
              "keyFormat" : {"format" : "JSON_SR", "features": ["UNWRAP_SINGLES"]},
              "keySchema" : {"oneOf":[{"type":"null"},{"type":"integer","connect.type":"int32"}]},
              "valueFormat" : {"format" : "JSON"}
            },
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-KSTREAM-OUTEROTHER-0000000017-store-changelog",
              "keyFormat" : {"format" : "JSON_SR", "features": ["UNWRAP_SINGLES"]},
              "keySchema" : {"oneOf":[{"type":"null"},{"type":"integer","connect.type":"int32"}]},
              "valueFormat" : {"format" : "JSON"}
            }
          ]
        }
      }
    },
    {
      "name": "table-table key-to-key - SR-enabled key format - incompatible schemas",
      "statements": [
        "CREATE TABLE T1 (ID INT PRIMARY KEY, VAL STRING) WITH (kafka_topic='t1', key_format='AVRO', value_format='JSON');",
        "CREATE TABLE T2 (ID BIGINT PRIMARY KEY, FOO INT) WITH (kafka_topic='t2', key_format='AVRO', value_format='JSON');",
        "CREATE TABLE OUTPUT AS SELECT T2.ID, T1.VAL FROM T1 JOIN T2 ON T1.ID = T2.ID;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlStatementException",
        "message": "Invalid join condition: types don't match. Got T1.ID{INTEGER} = T2.ID{BIGINT}."
      }
    },
    {
      "name": "matching session-windowed - SR-enabled key format",
      "comments": [
        "Note: the first record on the right topic intersects with the session on the right side, but no row is output as keys must",
        "be an EXACT BINARY match"
      ],
      "statements": [
        "CREATE STREAM S1 (ID INT KEY, V bigint) WITH (kafka_topic='left_topic', key_format='JSON_SR', value_format='JSON', WINDOW_TYPE='SESSION');",
        "CREATE STREAM S2 (ID INT KEY, V bigint) WITH (kafka_topic='right_topic', key_format='JSON_SR', value_format='JSON', WINDOW_TYPE='SESSION');",
        "CREATE STREAM OUTPUT as SELECT S1.ID, S1.V, S2.V FROM S1 JOIN S2 WITHIN 1 MINUTE ON S1.ID = S2.ID;"
      ],
      "inputs": [
        {"topic": "left_topic", "key": 1, "value": {"V": 1}, "timestamp": 765, "window": {"start": 234, "end": 765, "type": "session"}},
        {"topic": "right_topic", "key": 1, "value": {"V": 2}, "timestamp": 567, "window": {"start": 234, "end": 567, "type": "session"}},
        {"topic": "right_topic", "key": 1, "value": {"V": 3}, "timestamp": 765, "window": {"start": 234, "end": 765, "type": "session"}}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 1, "value": {"S1_V": 1, "S2_V": 3}, "timestamp": 765, "window": {"start": 234, "end": 765, "type": "session"}}
      ],
      "post": {
        "sources": [
          {
            "name": "OUTPUT",
            "type": "stream",
            "keyFormat": {"format": "JSON_SR", "windowType": "SESSION"},
            "schema": "S1_ID INT KEY, S1_V BIGINT, S2_V BIGINT"
          }
        ],
        "topics" : {
          "topics" : [
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-Join-left-repartition",
              "keyFormat" : {"format" : "JSON_SR", "features": ["UNWRAP_SINGLES"], "windowInfo": {"type": "SESSION"}},
              "keySchema" : {"oneOf":[{"type":"null"},{"type":"integer","connect.type":"int32"}]},
              "valueFormat" : {"format" : "JSON"}
            },
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-Join-right-repartition",
              "keyFormat" : {"format" : "JSON_SR", "features": ["UNWRAP_SINGLES"], "windowInfo": {"type": "SESSION"}},
              "keySchema" : {"oneOf":[{"type":"null"},{"type":"integer","connect.type":"int32"}]},
              "valueFormat" : {"format" : "JSON"}
            },
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-KSTREAM-JOINTHIS-0000000016-store-changelog",
              "keyFormat" : {"format" : "JSON_SR", "features": ["UNWRAP_SINGLES"], "windowInfo": {"type": "SESSION"}},
              "keySchema" : {"oneOf":[{"type":"null"},{"type":"integer","connect.type":"int32"}]},
              "valueFormat" : {"format" : "JSON"}
            },
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-KSTREAM-JOINOTHER-0000000017-store-changelog",
              "keyFormat" : {"format" : "JSON_SR", "features": ["UNWRAP_SINGLES"], "windowInfo": {"type": "SESSION"}},
              "keySchema" : {"oneOf":[{"type":"null"},{"type":"integer","connect.type":"int32"}]},
              "valueFormat" : {"format" : "JSON"}
            }
          ]
        }
      }
    },
    {
      "name": "matching time-windowed - SR-enabled key format",
      "comments": [
        "Note: the two streams use a different window size. However, only the start of the window is serialized, so its possible to get a matching binary key",
        "This may meet users requirements, hence KSQL allows such joins",
        "Note: the key format is currently taken from the left source."
      ],
      "statements": [
        "CREATE STREAM S1 (ID INT KEY, V bigint) WITH (kafka_topic='left_topic', key_format='JSON_SR', value_format='JSON', WINDOW_TYPE='Hopping', WINDOW_SIZE='5 SECONDS');",
        "CREATE STREAM S2 (ID INT KEY, V bigint) WITH (kafka_topic='right_topic', key_format='JSON_SR', value_format='JSON', WINDOW_TYPE='Tumbling', WINDOW_SIZE='2 SECOND');",
        "CREATE STREAM OUTPUT as SELECT *, S1.ROWTIME, S2.ROWTIME FROM S1 JOIN S2 WITHIN 1 MINUTE ON S1.ID = S2.ID;"
      ],
      "inputs": [
        {"topic": "left_topic", "key": 1, "value": {"V": 1}, "timestamp": 0, "window": {"start": 0, "end": 5000, "type": "time"}},
        {"topic": "left_topic", "key": 1, "value": {"V": 2}, "timestamp": 1000, "window": {"start": 1000, "end": 6000, "type": "time"}},
        {"topic": "left_topic", "key": 1, "value": {"V": 3}, "timestamp": 2000, "window": {"start": 2000, "end": 7000, "type": "time"}},
        {"topic": "right_topic", "key": 1, "value": {"V": 4}, "timestamp": 0, "window": {"start": 0, "end": 2000, "type": "time"}},
        {"topic": "right_topic", "key": 1, "value": {"V": 5}, "timestamp": 2000, "window": {"start": 2000, "end": 4000, "type": "time"}}
      ],
      "outputs": [
        {"topic": "OUTPUT", "key": 1, "value": {"S1_ROWTIME": 0, "S1_WINDOWSTART": 0, "S1_WINDOWEND": 5000, "S1_V": 1, "S2_ROWTIME": 0, "S2_WINDOWSTART": 0, "S2_WINDOWEND": 2000, "S2_ID": 1, "S2_V": 4}, "timestamp": 0, "window": {"start": 0, "end":5000, "type": "time"}},
        {"topic": "OUTPUT", "key": 1, "value": {"S1_ROWTIME": 2000, "S1_WINDOWSTART": 2000, "S1_WINDOWEND": 7000, "S1_V": 3, "S2_ROWTIME": 2000, "S2_WINDOWSTART": 2000, "S2_WINDOWEND": 4000, "S2_ID": 1, "S2_V": 5}, "timestamp": 2000, "window": {"start": 2000, "end":7000, "type": "time"}}
      ],
      "post": {
        "sources": [
          {
            "name": "OUTPUT",
            "type": "stream",
            "keyFormat": {"format": "JSON_SR", "windowType": "HOPPING", "windowSize": 5000},
            "schema": "S1_ID INT KEY, `S1_WINDOWSTART` BIGINT, `S1_WINDOWEND` BIGINT, `S1_V` BIGINT, S2_ID INTEGER, `S2_WINDOWSTART` BIGINT, `S2_WINDOWEND` BIGINT, `S2_V` BIGINT, S1_ROWTIME BIGINT, S2_ROWTIME BIGINT"
          }
        ],
        "topics" : {
          "topics" : [
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-Join-left-repartition",
              "keyFormat" : {"format" : "JSON_SR", "features": ["UNWRAP_SINGLES"], "windowInfo": {"type": "HOPPING", "size": 5}},
              "keySchema" : {"oneOf":[{"type":"null"},{"type":"integer","connect.type":"int32"}]},
              "valueFormat" : {"format" : "JSON"}
            },
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-Join-right-repartition",
              "keyFormat" : {"format" : "JSON_SR", "features": ["UNWRAP_SINGLES"], "windowInfo": {"type": "HOPPING", "size": 5}},
              "keySchema" : {"oneOf":[{"type":"null"},{"type":"integer","connect.type":"int32"}]},
              "valueFormat" : {"format" : "JSON"}
            },
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-KSTREAM-JOINTHIS-0000000016-store-changelog",
              "keyFormat" : {"format" : "JSON_SR", "features": ["UNWRAP_SINGLES"], "windowInfo": {"type": "HOPPING", "size": 5}},
              "keySchema" : {"oneOf":[{"type":"null"},{"type":"integer","connect.type":"int32"}]},
              "valueFormat" : {"format" : "JSON"}
            },
            {
              "name" : "_confluent-ksql-some.ksql.service.idquery_CSAS_OUTPUT_0-KSTREAM-JOINOTHER-0000000017-store-changelog",
              "keyFormat" : {"format" : "JSON_SR", "features": ["UNWRAP_SINGLES"], "windowInfo": {"type": "HOPPING", "size": 5}},
              "keySchema" : {"oneOf":[{"type":"null"},{"type":"integer","connect.type":"int32"}]},
              "valueFormat" : {"format" : "JSON"}
            }
          ]
        }
      }
    },
    {
      "name": "matching time-windowed - SR-enabled key format - fails if join on non-key",
      "statements": [
        "CREATE STREAM S1 (ID INT KEY, V int) WITH (kafka_topic='left_topic', key_format='JSON_SR', value_format='JSON', WINDOW_TYPE='Hopping', WINDOW_SIZE='5 SECONDS');",
        "CREATE STREAM S2 (ID INT KEY, V int) WITH (kafka_topic='right_topic', key_format='JSON_SR', value_format='JSON', WINDOW_TYPE='Tumbling', WINDOW_SIZE='2 SECOND');",
        "CREATE STREAM OUTPUT as SELECT *, S1.ROWTIME, S2.ROWTIME FROM S1 JOIN S2 WITHIN 1 MINUTE ON S1.ID = S2.V;"
      ],
      "expectedException": {
        "type": "io.confluent.ksql.util.KsqlStatementException",
        "message": "Implicit repartitioning of windowed sources is not supported. See https://github.com/confluentinc/ksql/issues/4385."
      }
    }
  ]
}
