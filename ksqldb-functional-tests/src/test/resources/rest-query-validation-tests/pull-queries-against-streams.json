  {
  "comments": [
    "Tests covering Pull queries of streams"
  ],
  "tests": [
    {
      "name": "empty response on empty stream",
      "statements": [
        "CREATE STREAM S1 (MYKEY INT KEY, MYVALUE INT) WITH (kafka_topic='test_topic', value_format='JSON');",
        "SELECT * FROM S1;"
      ],
      "responses": [
        {"admin": {"@type": "currentStatus"}},
        {"query": [
          {"header":{"schema":"`MYKEY` INTEGER, `MYVALUE` INTEGER"}},
          {"finalMessage":"Query Completed"}
        ]}
      ]
    },
    {
      "name": "error on GROUP BY",
      "statements": [
        "CREATE STREAM S1 (MYKEY INT KEY, MYVALUE INT) WITH (kafka_topic='test_topic', value_format='JSON');",
        "SELECT * FROM S1 GROUP BY MYKEY;"
      ],
      "expectedError": {
        "type": "io.confluent.ksql.rest.entity.KsqlStatementErrorMessage",
        "message": "Pull queries don't support GROUP BY clauses. See https://cnfl.io/queries for more info.\nAdd EMIT CHANGES if you intended to issue a push query.",
        "status": 400
      }
    },
    {
      "name": "error on ORDER BY",
      "statements": [
        "CREATE STREAM S1 (MYKEY INT KEY, MYVALUE INT) WITH (kafka_topic='test_topic', value_format='JSON');",
        "SELECT * FROM S1 ORDER BY MYKEY DESC;"
      ],
      "expectedError": {
        "type": "io.confluent.ksql.rest.entity.KsqlStatementErrorMessage",
        "message": "line 1:24: Syntax Error\n\nStatement: SELECT * FROM S1 ORDER BY MYKEY DESC;",
        "status": 400
      }
    },
    {
      "name": "error on WINDOW",
      "statements": [
        "CREATE STREAM S1 (MYKEY INT KEY, MYVALUE INT) WITH (kafka_topic='test_topic', value_format='JSON');",
        "SELECT * FROM S1 WINDOW TUMBLING(SIZE 1 SECOND);"
      ],
      "expectedError": {
        "type": "io.confluent.ksql.rest.entity.KsqlStatementErrorMessage",
        "message": "Pull queries don't support WINDOW clauses. See https://cnfl.io/queries for more info.\nAdd EMIT CHANGES if you intended to issue a push query.",
        "status": 400
      }
    },
    {
      "name": "error on JOIN",
      "statements": [
        "CREATE STREAM S1 (MYKEY1 INT KEY, MYVALUE1 INT) WITH (kafka_topic='test_topic1', value_format='JSON');",
        "CREATE STREAM S2 (MYKEY2 INT KEY, MYVALUE2 INT) WITH (kafka_topic='test_topic2', value_format='JSON');",
        "SELECT * FROM S1 JOIN S2 WITHIN 10 SECONDS ON MYKEY1 = MYKEY2;"
      ],
      "expectedError": {
        "type": "io.confluent.ksql.rest.entity.KsqlStatementErrorMessage",
        "message": "Pull queries don't support JOIN clauses. See https://cnfl.io/queries for more info.\nAdd EMIT CHANGES if you intended to issue a push query.",
        "status": 400
      }
    },
    {
      "name": "simple",
      "statements": [
        "CREATE STREAM S1 (MYKEY INT KEY, MYVALUE INT) WITH (kafka_topic='test_topic', value_format='JSON');",
        "SELECT * FROM S1;"
      ],
      "topics": [
        {"name": "test_topic", "partitions": 1} // to get a stable ordering
      ],
      "inputs": [
        {"topic": "test_topic", "timestamp": 12365, "key": 10, "value": {"myvalue": 1}},
        {"topic": "test_topic", "timestamp": 12366, "key": 11, "value": {"myvalue": 2}},
        {"topic": "test_topic", "timestamp": 12367, "key": 12, "value": {"myvalue": 3}},
        {"topic": "test_topic", "timestamp": 12368, "key": 13, "value": {"myvalue": 4}}
      ],
      "responses": [
        {"admin": {"@type": "currentStatus"}},
        {"query": [
          {"header":{"schema":"`MYKEY` INTEGER, `MYVALUE` INTEGER"}},
          {"row":{"columns":[10, 1]}},
          {"row":{"columns":[11, 2]}},
          {"row":{"columns":[12, 3]}},
          {"row":{"columns":[13, 4]}},
          {"finalMessage":"Query Completed"}
        ]}
      ]
    },
    {
      "name": "simple-source",
      "statements": [
        "CREATE SOURCE STREAM S1 (MYKEY INT KEY, MYVALUE INT) WITH (kafka_topic='test_topic', value_format='JSON');",
        "SELECT * FROM S1;"
      ],
      "topics": [
        {"name": "test_topic", "partitions": 1} // to get a stable ordering
      ],
      "inputs": [
        {"topic": "test_topic", "timestamp": 12365, "key": 10, "value": {"myvalue": 1}},
        {"topic": "test_topic", "timestamp": 12366, "key": 11, "value": {"myvalue": 2}},
        {"topic": "test_topic", "timestamp": 12367, "key": 12, "value": {"myvalue": 3}},
        {"topic": "test_topic", "timestamp": 12368, "key": 13, "value": {"myvalue": 4}}
      ],
      "responses": [
        {"admin": {"@type": "currentStatus"}},
        {"query": [
          {"header":{"schema":"`MYKEY` INTEGER, `MYVALUE` INTEGER"}},
          {"row":{"columns":[10, 1]}},
          {"row":{"columns":[11, 2]}},
          {"row":{"columns":[12, 3]}},
          {"row":{"columns":[13, 4]}},
          {"finalMessage":"Query Completed"}
        ]}
      ]
    },
    {
      "name": "select key",
      "statements": [
        "CREATE STREAM S1 (MYKEY INT KEY, MYVALUE INT) WITH (kafka_topic='test_topic', value_format='JSON');",
        "SELECT MYKEY FROM S1;"
      ],
      "topics": [
        {"name": "test_topic", "partitions": 1} // to get a stable ordering
      ],
      "inputs": [
        {"topic": "test_topic", "timestamp": 12365, "key": 10, "value": {"myvalue": 1}},
        {"topic": "test_topic", "timestamp": 12366, "key": 11, "value": {"myvalue": 2}},
        {"topic": "test_topic", "timestamp": 12367, "key": 12, "value": {"myvalue": 3}},
        {"topic": "test_topic", "timestamp": 12368, "key": 13, "value": {"myvalue": 4}}
      ],
      "responses": [
        {"admin": {"@type": "currentStatus"}},
        {"query": [
          {"header":{"schema":"`MYKEY` INTEGER"}},
          {"row":{"columns":[10]}},
          {"row":{"columns":[11]}},
          {"row":{"columns":[12]}},
          {"row":{"columns":[13]}},
          {"finalMessage":"Query Completed"}
        ]}
      ]
    },
    {
      "name": "select value",
      "statements": [
        "CREATE STREAM S1 (MYKEY INT KEY, MYVALUE INT) WITH (kafka_topic='test_topic', value_format='JSON');",
        "SELECT MYVALUE FROM S1;"
      ],
      "topics": [
        {"name": "test_topic", "partitions": 1} // to get a stable ordering
      ],
      "inputs": [
        {"topic": "test_topic", "timestamp": 12365, "key": 10, "value": {"myvalue": 1}},
        {"topic": "test_topic", "timestamp": 12366, "key": 11, "value": {"myvalue": 2}},
        {"topic": "test_topic", "timestamp": 12367, "key": 12, "value": {"myvalue": 3}},
        {"topic": "test_topic", "timestamp": 12368, "key": 13, "value": {"myvalue": 4}}
      ],
      "responses": [
        {"admin": {"@type": "currentStatus"}},
        {"query": [
          {"header":{"schema":"`MYVALUE` INTEGER"}},
          {"row":{"columns":[1]}},
          {"row":{"columns":[2]}},
          {"row":{"columns":[3]}},
          {"row":{"columns":[4]}},
          {"finalMessage":"Query Completed"}
        ]}
      ]
    },
    {
      "name": "project expression",
      "statements": [
        "CREATE STREAM S1 (MYKEY INT KEY, MYVALUE INT) WITH (kafka_topic='test_topic', value_format='JSON');",
        "SELECT MYKEY, MYVALUE * 2 AS DOUBLEVALUE FROM S1;"
      ],
      "topics": [
        {"name": "test_topic", "partitions": 1} // to get a stable ordering
      ],
      "inputs": [
        {"topic": "test_topic", "timestamp": 12365, "key": 10, "value": {"myvalue": 1}},
        {"topic": "test_topic", "timestamp": 12366, "key": 11, "value": {"myvalue": 2}},
        {"topic": "test_topic", "timestamp": 12367, "key": 12, "value": {"myvalue": 3}},
        {"topic": "test_topic", "timestamp": 12368, "key": 13, "value": {"myvalue": 4}}
      ],
      "responses": [
        {"admin": {"@type": "currentStatus"}},
        {"query": [
          {"header":{"schema":"`MYKEY` INTEGER, `DOUBLEVALUE` INTEGER"}},
          {"row":{"columns":[10, 2]}},
          {"row":{"columns":[11, 4]}},
          {"row":{"columns":[12, 6]}},
          {"row":{"columns":[13, 8]}},
          {"finalMessage":"Query Completed"}
        ]}
      ]
    },
    {
      "name": "where clause",
      "statements": [
        "CREATE STREAM S1 (MYKEY INT KEY, MYVALUE INT) WITH (kafka_topic='test_topic', value_format='JSON');",
        "SELECT * FROM S1 WHERE MYVALUE >= 2 AND MYVALUE < 4;"
      ],
      "topics": [
        {"name": "test_topic", "partitions": 1} // to get a stable ordering
      ],
      "inputs": [
        {"topic": "test_topic", "timestamp": 12365, "key": 10, "value": {"myvalue": 1}},
        {"topic": "test_topic", "timestamp": 12366, "key": 11, "value": {"myvalue": 2}},
        {"topic": "test_topic", "timestamp": 12367, "key": 12, "value": {"myvalue": 3}},
        {"topic": "test_topic", "timestamp": 12368, "key": 13, "value": {"myvalue": 4}}
      ],
      "responses": [
        {"admin": {"@type": "currentStatus"}},
        {"query": [
          {"header":{"schema":"`MYKEY` INTEGER, `MYVALUE` INTEGER"}},
          {"row":{"columns":[11, 2]}},
          {"row":{"columns":[12, 3]}},
          {"finalMessage":"Query Completed"}
        ]}
      ]
    },
    {
      "name": "should not allow pull query with disallowed pseudocolumn in SELECT clause",
      "statements": [
        "CREATE STREAM S1 (mykey INT KEY, myvalue INT) WITH (kafka_topic='test_topic', value_format='JSON');",
        "SELECT mykey, myvalue, ROWOFFSET FROM S1;"
      ],
      "expectedError": {
        "type": "io.confluent.ksql.rest.entity.KsqlStatementErrorMessage",
        "message": "Pull queries don't support the following columns in SELECT clauses: `ROWOFFSET`",
        "status": 400
      }
    },
    {
      "name": "should not allow pull query with disallowed pseudocolumn in WHERE clause",
      "statements": [
        "CREATE STREAM S1 (MYKEY INT KEY, MYVALUE INT) WITH (kafka_topic='test_topic', value_format='JSON');",
        "SELECT * FROM S1 WHERE mykey < 1 AND ROWPARTITION != 2;"
      ],
      "expectedError": {
        "type": "io.confluent.ksql.rest.entity.KsqlStatementErrorMessage",
        "message": "Pull queries don't support the following columns in WHERE clauses: `ROWPARTITION`",
        "status": 400
      }
    }
  ]
}